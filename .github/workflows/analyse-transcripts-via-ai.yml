name: Process Transcripts with AI

on:
  workflow_dispatch:
    inputs:
      batch_size:
        description: 'Number of branches to process in one batch'
        required: false
        default: '10'

permissions:
  contents: write

jobs:
  process-transcripts:
    runs-on: runner
    timeout-minutes: 360  # 6 hours
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GH_TOKEN }}

      - name: Set up Python environment
        run: |
          source /home/junfan/test/venv/bin/activate
          pip install python-dotenv llm_dialog_manager

      - name: Create .env file
        run: |
          # echo "OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }}" > .env
          # echo "ANTHROPIC_API_KEY=${{ secrets.ANTHROPIC_API_KEY }}" >> .env
          # echo "GROQ_API_KEY=${{ secrets.GROQ_API_KEY }}" >> .env
          echo "XAI_API_KEY=${{ secrets.XAI_API_KEY }}" >> .env
          cat .env  # Debug: print env file (without values)

      - name: Create and verify process_transcripts.py
        run: |
          # Create directory if it doesn't exist
          mkdir -p scripts
          
          # Create the Python script
          cat > scripts/process_transcripts.py << 'EOL'
          import os
          import re
          from llm_dialog_manager import Agent
          import logging
          from dotenv import load_dotenv

          # Configure logging
          logging.basicConfig(
              level=logging.INFO,
              format='%(asctime)s - %(levelname)s - %(message)s'
          )

          def clean_srt(srt_content):
              """Remove timestamps and line numbers from SRT content."""
              lines = srt_content.split('\n')
              clean_lines = []
              
              for line in lines:
                  # Skip empty lines, numbers, and timestamp lines
                  if not line.strip() or line.strip().isdigit() or '-->' in line:
                      continue
                  # Add non-empty content lines
                  if line.strip():
                      clean_lines.append(line.strip())
              
              return ' '.join(clean_lines)

          def process_transcript(srt_path):
              """Process an SRT file and generate AI response."""
              try:
                  # Read SRT file
                  with open(srt_path, 'r', encoding='utf-8') as f:
                      srt_content = f.read()
                  
                  # Clean the content
                  clean_content = clean_srt(srt_content)
                  logging.info(f"Cleaned content length: {len(clean_content)} characters")
                  
                  # Initialize AI agent
                  agent = Agent("grok-beta", memory_enabled=True)
                  
                  # Add system and user messages
                  system_message = '''You are an expert content analyzer specializing in interview transcripts. Please analyze the provided interview transcript and generate a structured response following these specific requirements:
                  
                  # Output Format
                  Please provide the analysis in the following JSON structure:
                  
                  ```json
                  {
                    "guest": {
                      "id": "<number>",
                      "name": "<guest_name>",
                      "role": "<professional_role>",
                      "category": "<category_key>",
                      "episodes": [
                        {
                          "title": "<episode_title>",
                          "views": <number>,
                          "url": "<video_url>",
                          "uploadTime": "<relative_time>"
                        }
                      ],
                      "totalViews": <number>,
                      "analysis": {
                        "summary": "<brief_summary>",
                        "keyInsights": [
                          "<insight_1>",
                          "<insight_2>",
                          ...
                        ],
                        "notableQuotes": [
                          {
                            "quote": "<quote_text>",
                            "context": "<context_description>"
                          }
                        ],
                        "topicsCovered": [
                          "<topic_1>",
                          "<topic_2>",
                          ...
                        ]
                      }
                    }
                  }
                  ```
                  
                  # Category Guidelines
                  Please categorize the content into one of these categories:
                  - career (职业发展): Content focused on career development, professional growth, and workplace dynamics
                  - tech (科技创新): Content about technology, innovation, and technical developments
                  - thinking (思维方法): Content about methodologies, mental models, and ways of thinking
                  - life (生活方式): Content about lifestyle, personal development, and life philosophy
                  - hobby (兴趣爱好): Content about personal interests and hobbies
                  
                  # Analysis Requirements
                  1. Guest Information:
                     - Identify the guest's name and professional role
                     - Determine the most appropriate category based on the primary focus of the discussion
                     - Extract or estimate view counts if available
                  
                  2. Content Analysis:
                     - Provide a concise summary (100-150 words)
                     - Identify 3-5 key insights or main points
                     - Extract 2-3 notable quotes with context
                     - List major topics covered in the discussion
                  
                  3. Episode Details:
                     - Extract or generate appropriate title
                     - Include video URL if available
                     - Note upload time in relative format (e.g., "X个月前")
                  
                  # Examples
                  Given transcript example:
                  "在这期访谈中，硅谷资深工程师张明分享了他对AI发展的见解。他强调了持续学习的重要性，并指出'在AI时代，最危险的是固守过时的知识'..."
                  
                  Example output:
                  ```json
                  {
                    "guest": {
                      "id": 7,
                      "name": "张明",
                      "role": "Senior Engineer",
                      "category": "tech",
                      "episodes": [
                        {
                          "title": "AI时代工程师如何持续进化？| 张明访谈",
                          "views": "",
                          "url": "",
                          "uploadTime": "2个月前"
                        }
                      ],
                      "analysis": {
                        "summary": "本期访谈聚焦AI时代工程师的发展路径...",
                        "keyInsights": [
                          "持续学习是在AI时代保持竞争力的关键",
                          "技术演进加速要求工程师具备快速适应能力",
                          "跨领域知识整合将成为未来核心竞争力"
                        ],
                        "notableQuotes": [
                          {
                            "quote": "在AI时代，最危险的是固守过时的知识",
                            "context": "讨论终身学习重要性时的核心观点"
                          }
                        ],
                        "topicsCovered": [
                          "AI发展趋势",
                          "工程师职业发展",
                          "技能更新迭代"
                        ]
                      }
                    }
                  }
                  ```
                  '''
                  agent.add_message("system", system_message)
                  agent.add_message("user", f"Here's the transcript for the video: {clean_content}")
                  
                  # Generate response
                  response = agent.generate_response()
                  
                  # Get directory path for response file
                  dir_path = os.path.dirname(srt_path)
                  base_name = os.path.basename(os.path.dirname(srt_path))
                  response_path = os.path.join(dir_path, f"response_{base_name}.txt")
                  
                  # Save response
                  with open(response_path, 'w', encoding='utf-8') as f:
                      f.write(response)
                  
                  logging.info(f"Successfully created response file: {response_path}")
                  return response_path
                  
              except Exception as e:
                  logging.error(f"Error processing {srt_path}: {str(e)}")
                  return None

          if __name__ == "__main__":
              try:
                  # Load environment variables
                  load_dotenv()
                  
                  # Verify environment variables
                  required_keys = ['XAI_API_KEY']
                  for key in required_keys:
                      if not os.getenv(key):
                          logging.warning(f"Warning: {key} not found in environment variables")
                  
                  # Process current directory
                  if os.path.exists('transcript.srt'):
                      logging.info("Found transcript.srt in current directory")
                      response_file = process_transcript('transcript.srt')
                      
                      if response_file:
                          # Create status file for GitHub Actions
                          with open('processed_files.txt', 'w', encoding='utf-8') as f:
                              f.write(response_file)
                          logging.info("Successfully completed processing")
                          exit(0)
                      else:
                          logging.error("Failed to process transcript")
                          exit(1)
                  else:
                      logging.error("No transcript.srt found in current directory")
                      exit(1)
                      
              except Exception as e:
                  logging.error(f"Fatal error: {str(e)}")
                  exit(1)
          EOL
          
          # Make the script executable
          chmod +x scripts/process_transcripts.py
          
          # Verify the script exists and is readable
          if [ -f scripts/process_transcripts.py ]; then
            echo "Script created successfully"
            ls -l scripts/process_transcripts.py
          else
            echo "Failed to create script"
            exit 1
          fi

      - name: Find and process branches
        run: |
          # Configure git
          git config --global user.name 'github-actions'
          git config --global user.email 'github-actions@github.com'
          git remote set-url origin https://${{ github.actor }}:${{ secrets.GH_TOKEN }}@github.com/${{ github.repository }}
          
          # Get all branches with transcript.srt
          BRANCHES=$(git branch -r | grep 'origin/process-' | sed 's|origin/||')
          
          for branch in $BRANCHES; do
            echo "Processing branch: $branch"
            
            # Checkout branch
            if ! git checkout "$branch"; then
              echo "Failed to checkout branch: $branch"
              continue
            fi
            
            git pull origin "$branch"
            
            # Check if branch has transcript.srt
            if [ -f "transcript.srt" ]; then
              echo "Found transcript.srt in $branch"
              
              # Process transcript
              if python3 scripts/process_transcripts.py; then
                # Check if response file was created
                if [ -f "processed_files.txt" ]; then
                  # Add and commit changes
                  git add response_*.txt processed_files.txt
                  if ! git diff --staged --quiet; then
                    git commit -m "Add AI analysis for $branch"
                    if git push origin "$branch"; then
                      echo "Successfully processed and pushed changes for $branch"
                    else
                      echo "Failed to push changes for $branch"
                    fi
                  else
                    echo "No changes to commit for $branch"
                  fi
                else
                  echo "No response files generated for $branch"
                fi
              else
                echo "Failed to process transcript for $branch"
              fi
            else
              echo "No transcript.srt found in $branch"
            fi
          done

      - name: Cleanup
        if: always()
        run: |
          rm -f .env
          rm -rf scripts/
