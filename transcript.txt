[00:00:00,000 -> 00:00:01,000] Hello 大家好
[00:00:01,000 -> 00:00:04,400] 欢迎来到课代表讲数据的第一期
[00:00:04,400 -> 00:00:07,519] 就像上期视频promise大家的那样子
[00:00:07,519 -> 00:00:10,240] 我从这期开始就会跟大家分享一下
[00:00:10,240 -> 00:00:12,679] 我跟数据打交道的这么多年
[00:00:12,679 -> 00:00:15,560] 这些工作里面积累的心得和体会
[00:00:15,560 -> 00:00:17,440] 今天的第一期
[00:00:17,440 -> 00:00:19,519] 我们就从上一期视频的留言里面
[00:00:19,519 -> 00:00:22,440] 选一个小伙伴来讲一下他感兴趣的话题
[00:00:22,440 -> 00:00:24,399] 是林洪山同学
[00:00:24,399 -> 00:00:27,399] 他问DS有很多不一样的方向
[00:00:27,399 -> 00:00:30,199] 想听听是怎么挖掘自己focus的方向
[00:00:30,199 -> 00:00:31,399] 自己的优势
[00:00:31,399 -> 00:00:34,399] 专精成某个方面的data expertise
[00:00:34,399 -> 00:00:36,799] 这个问题其实我觉得挺有趣的
[00:00:36,799 -> 00:00:39,600] 因为就是data science这件事情
[00:00:39,600 -> 00:00:42,200] 从来没有被准确的define过
[00:00:42,200 -> 00:00:45,240] 我之前在两期视频里边有讲这件事我今天就把它拎出来然后再单独讲一下
[00:00:45,240 -> 00:00:49,960] 因为尤其很多求职的小伙伴
[00:00:49,960 -> 00:00:53,039] 他们毕业了以后发现想去找一个DS的工作
[00:00:53,039 -> 00:00:54,079] 什么都要会
[00:00:54,079 -> 00:00:55,960] 就是统计概率不用说了
[00:00:55,960 -> 00:00:56,960] CSQL
[00:00:56,960 -> 00:00:58,759] 然后做Data Visualization
[00:00:58,759 -> 00:01:01,600] 各种各样的数据的Pipeline的Tool
[00:01:01,600 -> 00:01:03,880] 包括AWS的Refresh这些东西
[00:01:03,880 -> 00:01:06,439] 有的时候还要会做Machine Learning还要会一些基础的文字做data visualization各种各样的这个数据的pipeline的tool包括AWS的Reshift这些东西
[00:01:06,480 -> 00:01:08,719] 有的时候还要会做Machine Learning
[00:01:08,760 -> 00:01:10,560] 还要会一些基础的coding
[00:01:10,599 -> 00:01:14,319] 然后还要去学各种Product Science商业分析等等
[00:01:14,359 -> 00:01:16,280] 还要学会各种增长框架
[00:01:16,400 -> 00:01:19,760] 就是这么多东西你去学的话是学不完的
[00:01:19,760 -> 00:01:21,359] 也不可能每样都学得很精
[00:01:21,519 -> 00:01:23,239] 所以说找到自己喜欢什么
[00:01:23,239 -> 00:01:25,799] 然后觉得找到找清楚自己的方向
[00:01:25,799 -> 00:01:29,239] 从在学习的时候就从这个就为这个方向去努力
[00:01:29,239 -> 00:01:30,280] 是很重要的
[00:01:30,280 -> 00:01:32,239] 那我这些视频呢
[00:01:32,239 -> 00:01:35,719] 我就把数据相关的工作分成三个大类
[00:01:35,719 -> 00:01:37,560] 一个是data engineer
[00:01:37,560 -> 00:01:39,599] 一个是data analytics
[00:01:39,599 -> 00:01:41,480] 一个是data scientist
[00:01:41,480 -> 00:01:44,959] 当然了很多人都会用data scientist
[00:01:44,959 -> 00:01:45,000] 来指代这些所有的东西我会把这里边的data analytics和data scientist当然了很多人都会用data scientist
[00:01:45,000 -> 00:01:46,480] 来指代这些所有的东西
[00:01:46,480 -> 00:01:49,439] 我会把这里边的data analytics和data scientist
[00:01:49,439 -> 00:01:50,239] 做一个区分
[00:01:50,280 -> 00:01:51,640] 那么就从data engineer开始说
[00:01:51,640 -> 00:01:53,480] data engineer其实就很简单
[00:01:53,599 -> 00:01:55,280] 就是你把数据工程
[00:01:56,239 -> 00:01:58,879] 很多时候你在这个产品或者商业
[00:01:58,879 -> 00:02:00,040] 行为中产生了数据
[00:02:00,040 -> 00:02:01,840] 然后这些数据被存储起来了
[00:02:01,920 -> 00:02:03,640] 可是要利用它的话
[00:02:03,680 -> 00:02:05,719] 其实还是一个很复杂的过程
[00:02:05,719 -> 00:02:07,480] 因为现在都说大数据是吧
[00:02:07,480 -> 00:02:09,840] 然后要说这个人工智能
[00:02:10,319 -> 00:02:12,719] 你大数据就代表着数据量特别大
[00:02:12,719 -> 00:02:15,599] 然后人工智能很多时候它的模型
[00:02:15,599 -> 00:02:17,960] 是对速度要求是很快的
[00:02:17,960 -> 00:02:19,879] 比如说你去Google搜一个东西
[00:02:19,879 -> 00:02:21,560] 你都是要毫秒级对吧
[00:02:21,560 -> 00:02:22,840] 你或者说抖音也好
[00:02:23,000 -> 00:02:23,800] Facebook也好
[00:02:24,039 -> 00:02:26,039] 或者各种各样的广告系统也好它都要做到千人千面而且是一个毫秒级对吧你或者说抖音也好Facebook也好或者各种各样的广告系统也好
[00:02:26,039 -> 00:02:27,639] 它都要做到千人千面
[00:02:27,639 -> 00:02:29,680] 而且是一个毫秒级的推荐
[00:02:29,680 -> 00:02:30,800] 个性化的推荐
[00:02:31,039 -> 00:02:33,759] 这里边可以看到对速度的要求是很高的
[00:02:33,759 -> 00:02:37,840] 大家其实就可以用内存和硬盘来做一个理解
[00:02:38,159 -> 00:02:41,360] 内存就是相对它的存储空间少一点
[00:02:41,360 -> 00:02:42,719] 但是它的速度特别快
[00:02:42,960 -> 00:02:45,960] 硬盘就是它的存储空间大一点但是它的速度特别快硬盘就是它的存储空间大一点
[00:02:45,960 -> 00:02:47,560] 但是它的速度就会慢一些
[00:02:47,560 -> 00:02:50,000] 而且你机械硬盘和固态硬盘比的话
[00:02:50,000 -> 00:02:51,360] 固态硬盘更快更小
[00:02:51,360 -> 00:02:53,000] 然后机械硬盘更慢更大
[00:02:53,000 -> 00:02:55,240] 所以说这些东西都是有取舍的
[00:02:55,240 -> 00:02:56,759] 这样就可以看出来
[00:02:56,759 -> 00:02:58,560] 有一个好的data engineer
[00:02:58,560 -> 00:03:00,680] 你的数据才有可能发挥威力
[00:03:00,680 -> 00:03:03,639] 很多公司它的数据没有做好
[00:03:03,639 -> 00:03:06,000] 很多时候是缺乏好的data很多时候是缺乏好的Data Engineer
[00:03:06,000 -> 00:03:07,800] 而不是缺乏好的Data Scientist
[00:03:07,800 -> 00:03:10,080] 我之前就听说过一个故事
[00:03:10,080 -> 00:03:12,240] 就是一个著名的药厂也赚很多钱
[00:03:12,240 -> 00:03:14,520] 但是他的leadership对Data这个事不懂
[00:03:14,520 -> 00:03:17,680] 他一上来就想上那些deep learning这些东西
[00:03:17,680 -> 00:03:20,639] 可是招了很厉害的人过来一看
[00:03:20,639 -> 00:03:22,280] 发现基础的数据都没有
[00:03:22,280 -> 00:03:23,240] 都是不全的
[00:03:23,240 -> 00:03:25,400] 最后折腾了一段时间就走了
[00:03:25,400 -> 00:03:26,759] 巧妇难为无米之炊
[00:03:26,759 -> 00:03:29,240] 所以说Data Engineer本身很重要
[00:03:29,240 -> 00:03:30,840] 如果大家特别想了解的话
[00:03:30,840 -> 00:03:35,199] 我们以后也可以请嘉宾来帮我们单独讲一讲Data Engineer
[00:03:35,199 -> 00:03:36,560] 这就不展开了
[00:03:36,560 -> 00:03:39,319] 那我们就说Data Analytics和Data Scientist
[00:03:39,319 -> 00:03:41,680] 我在这里边也会举个例子
[00:03:41,680 -> 00:03:43,280] 就是说什么是好的什么是不好的
[00:03:43,280 -> 00:03:50,960] 我这里做的区分就是Data Analytics一般是不使用一些复杂的模型去解决问题
[00:03:51,159 -> 00:03:55,840] 然后Data Scientist一般会要使用一个复杂的数学模型去解决问题
[00:03:55,840 -> 00:03:58,280] 然后这其实大家有一个普遍的误区
[00:03:58,439 -> 00:04:00,080] 就是好像有一个鄙视链
[00:04:00,120 -> 00:04:03,560] 觉得就是做ML的看不起做DA的
[00:04:03,800 -> 00:04:05,560] 我觉得并不是这样子
[00:04:05,560 -> 00:04:08,520] 就是解决问题从解决问题的复杂程度
[00:04:08,520 -> 00:04:11,000] 和解决问题的价值来看
[00:04:11,000 -> 00:04:13,199] 两边都有它们很有价值的地方
[00:04:13,199 -> 00:04:15,000] 也都有它们很复杂的地方
[00:04:15,000 -> 00:04:17,240] 我们就从这个data scientist来说
[00:04:17,240 -> 00:04:19,839] 就是需要用模型来解决问题的
[00:04:19,839 -> 00:04:24,399] 其实之前用模型解决问题这件事情更普遍一些
[00:04:24,399 -> 00:04:27,399] 尤其很多做这个operation research的
[00:04:27,399 -> 00:04:28,959] 包括我们做经济的是吧
[00:04:28,959 -> 00:04:31,399] 有time series model或者所有的cost inference model
[00:04:31,399 -> 00:04:33,279] 我们都是在用模型解决问题
[00:04:33,279 -> 00:04:39,800] 但是现在市面上predominantly绝大多数的都是一个ML scientist
[00:04:39,800 -> 00:04:41,920] 就是用模式learning去解决问题
[00:04:41,920 -> 00:04:44,759] 这里边是因为首先模式learning确实发展的很快
[00:04:44,759 -> 00:04:48,000] 也有很多问题确实很适合被模式学习解决
[00:04:48,000 -> 00:04:51,480] 我在前面的人工智能在大厂应用里边也有说
[00:04:51,480 -> 00:04:54,079] 我觉得这个世界上还有很多
[00:04:54,079 -> 00:04:56,920] 值得被模式学习解决的问题还没有被解决
[00:04:56,920 -> 00:04:59,959] 所以我很看好在这里的应用场景
[00:04:59,959 -> 00:05:04,079] 但是不可否认的是很多地方的这个领导
[00:05:04,079 -> 00:05:05,839] 他听说这个Machine Learning
[00:05:05,839 -> 00:05:09,160] 听说AI就觉得这个东西是一个password
[00:05:09,160 -> 00:05:10,240] 我们也想用
[00:05:10,240 -> 00:05:12,360] 有的时候这个business未必适合
[00:05:12,360 -> 00:05:13,560] 或者未必ready
[00:05:13,560 -> 00:05:15,279] 去用Machine Learning解决
[00:05:15,279 -> 00:05:17,639] 他们就想上Machine Learning去解决问题
[00:05:17,639 -> 00:05:20,480] 我们也听说过很多这样的应用场景
[00:05:20,480 -> 00:05:22,120] 这个不光是在传统企业
[00:05:22,120 -> 00:05:23,560] 我有一个数据科学群
[00:05:23,560 -> 00:05:27,279] 然后我就会看到里边有一些大厂的同学会问
[00:05:27,279 -> 00:05:29,519] 我们的上了Machine Learning Model
[00:05:29,519 -> 00:05:31,839] 效果不如Rubix的System
[00:05:31,839 -> 00:05:32,560] 那怎么办
[00:05:32,560 -> 00:05:34,879] 那在我看来你就用Rubix的System好了
[00:05:34,879 -> 00:05:36,759] 你干嘛非要上Machine Learning Model
[00:05:36,759 -> 00:05:37,639] 对吧
[00:05:37,639 -> 00:05:39,439] 这是一种例子
[00:05:39,439 -> 00:05:41,120] 还有的一种例子就是说
[00:05:41,120 -> 00:05:43,519] 某大厂我就不说是哪个某大厂了
[00:05:43,519 -> 00:05:48,680] 他们有一整个team去做一个非常复杂的
[00:05:48,680 -> 00:05:50,800] 这个time series的forecasting
[00:05:50,800 -> 00:05:54,319] 后来有一个经济学家来了以后就说
[00:05:54,319 -> 00:05:58,240] guys你们这个data point只有几百个又不是几百万个
[00:05:58,240 -> 00:06:01,519] 你们用这么复杂的deep learning model去forecast
[00:06:01,519 -> 00:06:02,720] 真的能forecast准吗
[00:06:02,720 -> 00:06:03,839] 我给你出一个方法吧
[00:06:03,839 -> 00:06:07,319] 你用过去的6个observation的中位数
[00:06:07,319 -> 00:06:08,959] 这就是你们下一次的预测
[00:06:08,959 -> 00:06:12,959] 后来leadership还真的就把这两个模型放到一起比较了
[00:06:12,959 -> 00:06:17,360] 然后每次6个observation的中位数的prediction
[00:06:17,360 -> 00:06:19,800] 都比复杂的ML的prediction要准
[00:06:19,800 -> 00:06:23,040] 所以这个故事就是想告诉大家
[00:06:23,040 -> 00:06:26,139] ML不是适合所有的商业问题的
[00:06:26,139 -> 00:06:28,379] 然后大家也不要盲目ML的威力
[00:06:28,379 -> 00:06:30,500] 虽然它确实有很厉害
[00:06:30,500 -> 00:06:32,939] 然后确实用钱钱钱也很广阔
[00:06:32,939 -> 00:06:35,100] 这里就是好的例子
[00:06:35,100 -> 00:06:38,379] 好的例子就是说你这个科学家
[00:06:38,379 -> 00:06:41,180] 你一方面你知道ML怎么样子
[00:06:41,180 -> 00:06:44,579] 你知道什么样子的问题适合被ML解决
[00:06:44,579 -> 00:06:50,199] 你能把你的商业问题非常好的写成ML系统的objective function
[00:06:50,399 -> 00:06:52,319] 你能去优化你的问题
[00:06:52,360 -> 00:06:54,759] 你能去得到你需要的数据
[00:06:54,759 -> 00:06:57,720] 然后去把这个问题很好地用ML去解决
[00:06:57,759 -> 00:07:00,879] 更重要的是你要有工程能力
[00:07:01,639 -> 00:07:07,480] 我们发现很多如果不是在互联网大厂
[00:07:07,480 -> 00:07:08,959] 他们有专门的engineer
[00:07:08,959 -> 00:07:12,120] 很多数据科学家顶着数据科学家的title
[00:07:12,120 -> 00:07:13,879] 会说自己做ML
[00:07:13,879 -> 00:07:17,519] 但是其实就是把现有的模型带到包
[00:07:17,519 -> 00:07:19,920] 这个东西就是你拍像上调个scale
[00:07:19,920 -> 00:07:20,439] 是吧
[00:07:20,439 -> 00:07:23,079] 其实你学了一下午就学会了
[00:07:23,079 -> 00:07:24,680] 调个包解决一个问题
[00:07:24,680 -> 00:07:26,600] 似乎在用ML解决问题
[00:07:26,600 -> 00:07:29,600] 但是其实写出来的东西是不能被工程化
[00:07:29,600 -> 00:07:31,240] 不能被大规模应用的
[00:07:31,240 -> 00:07:33,959] 最后也导致这个东西就沦为一个噱头
[00:07:33,959 -> 00:07:35,519] 而不是真的去解决问题
[00:07:35,800 -> 00:07:39,360] 在我看来很多ML的问题更多是工程问题
[00:07:39,360 -> 00:07:41,199] 而不是科学问题
[00:07:41,360 -> 00:07:42,839] 但是这就是另外一个话题了
[00:07:42,839 -> 00:07:45,360] 总之我们就说数据科学家
[00:07:45,439 -> 00:07:48,800] 这一块主要是用复杂的模型
[00:07:48,800 -> 00:07:51,439] 相对复杂的模型去解决问题
[00:07:51,480 -> 00:07:52,800] 然后这里边绝大多数
[00:07:52,959 -> 00:07:54,720] 现在都是用Machine Learning的
[00:07:54,720 -> 00:07:56,079] Model去解决问题
[00:07:57,000 -> 00:07:58,560] Data Analytics是干什么的
[00:07:59,000 -> 00:08:02,000] Data Analytics一般不太用复杂的模型
[00:08:02,040 -> 00:08:04,720] 他们会去分析一个商业
[00:08:04,720 -> 00:08:05,240] 对吧你分析一个商业对吧
[00:08:05,240 -> 00:08:06,800] 你分析一个商业的时候
[00:08:06,800 -> 00:08:08,480] 比如说我在facebook
[00:08:08,480 -> 00:08:12,639] 我就是用SQL加Tableau去解决问题就好了
[00:08:12,639 -> 00:08:14,879] 有的时候用PPT有的时候用Document
[00:08:14,879 -> 00:08:18,680] 我在亚马逊其实是用很多ML model
[00:08:18,680 -> 00:08:21,120] 再加economic matrix model去做cosmol inference
[00:08:21,120 -> 00:08:22,959] 所以主要是用Python Scala
[00:08:22,959 -> 00:08:25,560] 但是来了facebook用Python的机会都很少
[00:08:25,920 -> 00:08:26,720] 为什么
[00:08:26,720 -> 00:08:28,279] 因为其实很多问题
[00:08:28,319 -> 00:08:31,600] 你的价值是在于你对商业的理解
[00:08:31,600 -> 00:08:34,039] 和你对一个复杂问题的理解
[00:08:34,320 -> 00:08:37,120] 你是frame这个question的能力
[00:08:37,120 -> 00:08:40,440] 和把frame出来的business question
[00:08:40,639 -> 00:08:43,720] 转化成一个数据的question
[00:08:43,759 -> 00:08:46,200] 或者说是一个数据可以被验证的
[00:08:46,200 -> 00:08:48,200] 这个hypothesis的能力
[00:08:48,200 -> 00:08:50,919] 而不是你去用模型解决问题的能力
[00:08:50,919 -> 00:08:53,559] 那刚才说的对商业的理解
[00:08:53,559 -> 00:08:56,000] 然后对复杂问题的理解能力
[00:08:56,000 -> 00:09:00,200] framing的能力和operationalization的能力
[00:09:00,200 -> 00:09:01,559] 都是一个商业分析
[00:09:01,559 -> 00:09:04,879] 都是一个data analytics非常需要的能力
[00:09:04,879 -> 00:09:08,039] 其实今天周四晚上就在我拍这个视频的时候
[00:09:08,039 -> 00:09:12,159] 我的数据科学群里边几位大佬们还正在讨论这件事情
[00:09:12,159 -> 00:09:15,320] 就是包括其中有快手的宋世君
[00:09:15,320 -> 00:09:19,480] 也算是我们数据科学界数据分析界的泰山北斗了
[00:09:19,480 -> 00:09:23,159] 他就说硬能力是好培养的
[00:09:23,159 -> 00:09:24,559] 软能力是很难培养的
[00:09:24,559 -> 00:09:26,200] 或者大家不知道怎么培养的软能力是很难培养的或者大家不知道怎么培养
[00:09:26,200 -> 00:09:29,480] 所以说比如说你在看Facebook的这个DS
[00:09:29,480 -> 00:09:31,240] Analytics的面试里边
[00:09:31,240 -> 00:09:35,000] 他就会非常着重考察于你思考问题的能力
[00:09:35,000 -> 00:09:36,679] 而不是说你C-Code写的怎么样
[00:09:36,679 -> 00:09:38,080] 我当时去Facebook的时候
[00:09:38,080 -> 00:09:40,440] 我是用Python过的那个Tek面试
[00:09:40,440 -> 00:09:41,840] 我都不怎么会写C-Code
[00:09:41,840 -> 00:09:44,240] 所以一个好的Data Analytics
[00:09:44,240 -> 00:09:46,320] 你会使用各种各样的工具
[00:09:46,320 -> 00:09:48,120] 从简单的到复杂
[00:09:48,120 -> 00:09:50,000] 去分析清楚一个商业问题
[00:09:50,000 -> 00:09:52,080] 然后帮助商业进行更好的决策
[00:09:52,080 -> 00:09:54,159] 这里边一个非常重要的武器
[00:09:54,159 -> 00:09:55,720] 就是Causal Inference
[00:09:55,720 -> 00:09:59,600] 所以说除了我刚刚说的那些软的能力以外
[00:09:59,600 -> 00:10:00,720] 非常硬的一个能力
[00:10:00,720 -> 00:10:02,639] 就是一定要知道Causal Inference
[00:10:02,639 -> 00:10:05,000] 你要能明白你做A会导致B
[00:10:05,000 -> 00:10:07,399] 而不只是Selection Bias而已
[00:10:07,399 -> 00:10:09,840] 这里我到时候也会细讲
[00:10:09,840 -> 00:10:12,919] 但是总之就是软能力加上Causal Inference的能力
[00:10:12,919 -> 00:10:15,000] 我觉得是Analytics的核心能力
[00:10:15,000 -> 00:10:17,679] 这里边不好的Analytics或者说
[00:10:17,679 -> 00:10:19,559] 就是做的不是很开心的Analytics
[00:10:19,559 -> 00:10:22,600] 很多时候就是沦为产品的取数工具
[00:10:22,600 -> 00:10:25,879] 就是它的能力建立在写C call拿数据上
[00:10:25,879 -> 00:10:29,120] 然后就是当你的business partner跟你要什么数据
[00:10:29,120 -> 00:10:30,519] 你给他提供什么数据
[00:10:30,519 -> 00:10:33,480] 也许你可以把这些数据visualize一下
[00:10:33,480 -> 00:10:35,200] 做成一个dashboard
[00:10:35,200 -> 00:10:36,519] 做成一些pipeline等等
[00:10:36,519 -> 00:10:38,320] 但是这里边你没有ownership
[00:10:38,320 -> 00:10:40,360] 这里边ownership分两点
[00:10:40,360 -> 00:10:45,000] 一个是你用这个数据去解释商业问题的ownership
[00:10:45,000 -> 00:10:49,000] 另外一个就是你去解释了这个商业问题
[00:10:49,000 -> 00:10:51,000] 产生impact ownership
[00:10:51,000 -> 00:10:53,000] 总之就是你数据分析做得好的话
[00:10:53,000 -> 00:10:57,000] 你应该是decision maker或者是decision maker中的关键一员
[00:10:57,000 -> 00:11:01,000] 而不只不过是给别人的决策提供一个参考而已
[00:11:01,000 -> 00:11:02,000] 好的
[00:11:02,000 -> 00:11:03,000] 这就是简单的分析
[00:11:03,000 -> 00:11:06,879] 回头说一下DE DA和DS对吧
[00:11:07,159 -> 00:11:09,919] 我接下来的这些视频的分享
[00:11:09,919 -> 00:11:13,840] 我也会着重的强调DS和DA的这些分享
[00:11:13,840 -> 00:11:15,279] 比如说我前面几期视频
[00:11:15,519 -> 00:11:16,159] 就会讲一些
[00:11:16,159 -> 00:11:18,720] 我对人工智能和Machine Learning的理解
[00:11:19,120 -> 00:11:20,159] 我们下期再见
[00:11:20,159 -> 00:11:20,679] 拜拜
