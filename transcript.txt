[00:00:00,000 -> 00:00:01,659] Hello 大家好
[00:00:01,659 -> 00:00:03,160] 这期视频的标题是
[00:00:03,160 -> 00:00:05,299] 为什么人工智能宛如人工智障
[00:00:05,299 -> 00:00:07,639] 在媒体提起人工智能的时候
[00:00:07,639 -> 00:00:09,099] 大家脑子里想的就是
[00:00:09,099 -> 00:00:11,039] 《终结者》里边天网的那样的画面
[00:00:11,039 -> 00:00:13,759] 人工智能可以更高效地完成很多工作
[00:00:13,759 -> 00:00:15,699] 甚至在未来人工智能会思考
[00:00:15,699 -> 00:00:18,039] 我是谁 我从哪里来的这样的本质问题
[00:00:18,039 -> 00:00:21,440] 最后去搞一个起义去取代人类的存在
[00:00:21,440 -> 00:00:24,359] 可是我们在日常生活中会看到
[00:00:24,359 -> 00:00:26,399] 就连最基本的语音智能助手
[00:00:26,399 -> 00:00:27,960] 经过了这么多年的发展
[00:00:27,960 -> 00:00:29,699] 他在完成开灯关灯
[00:00:00,000 -> 00:00:01,280] 今天天氣怎麼樣
[00:00:01,280 -> 00:00:02,560] 這種簡單的問題裡面
[00:00:02,560 -> 00:00:03,640] 可以完成得不錯
[00:00:03,640 -> 00:00:05,719] 但是稍稍複雜一點的問題
[00:00:05,719 -> 00:00:07,080] 它就怪了
[00:00:07,080 -> 00:00:09,199] 比如說有一個很有趣的測試
[00:00:09,199 -> 00:00:11,759] 你測任何一家語音智能助手
[00:00:11,759 -> 00:00:13,720] 你問他給我推薦餐館
[00:00:13,720 -> 00:00:14,640] 不要日本菜
[00:00:14,640 -> 00:00:16,359] 那他一定會給你推薦個日本菜
[00:00:16,359 -> 00:00:19,079] 那為什麼理想和現實有這麼大的差距
[00:00:19,079 -> 00:00:21,280] 和我們的現實繼續發展下去
[00:00:21,280 -> 00:00:23,280] 就是我們收集越來越多的數據
[00:00:23,280 -> 00:00:25,519] 我們應用越來越廣泛
[00:00:25,519 -> 00:00:28,120] 我們的算法經過不斷的更新迭代
[00:00:00,000 -> 00:00:02,480] 会不会达到强人工智能的理想呢
[00:00:02,480 -> 00:00:03,600] 答案是不会
[00:00:03,600 -> 00:00:04,679] 这个不是我说的
[00:00:04,679 -> 00:00:06,400] 这是绝大多数科技企业
[00:00:06,400 -> 00:00:07,679] AI研发的领头人
[00:00:07,679 -> 00:00:10,400] 或者说大学里面做人工智能的教授
[00:00:10,400 -> 00:00:12,000] 业界的普遍看法
[00:00:12,000 -> 00:00:14,119] 这期视频我就想利用这个例子
[00:00:14,119 -> 00:00:16,039] 就是语音智能的这个例子
[00:00:16,039 -> 00:00:18,679] 跟大家结合我前几期讲的
[00:00:18,679 -> 00:00:20,039] 深度学习的原理
[00:00:20,039 -> 00:00:22,440] 去看一下为什么理想和现实之间
[00:00:22,440 -> 00:00:23,519] 有这么大的差距
[00:00:23,519 -> 00:00:25,079] 以及从实用的程度上
[00:00:25,079 -> 00:00:27,480] 帮助大家更好的去理解人工智能
[00:00:27,480 -> 00:00:28,480] 也就是说
[00:00:00,000 -> 00:00:02,540] 当你看到了一个人工智能的应用
[00:00:02,540 -> 00:00:05,000] 你知道它的局限性和边界在哪里
[00:00:05,000 -> 00:00:06,400] 你知道什么是能做好的
[00:00:06,400 -> 00:00:07,500] 什么是做不好的
[00:00:07,700 -> 00:00:10,880] 比如说其实在现有的模型范式之下
[00:00:10,880 -> 00:00:13,480] 让人工智能去给你推荐一家餐馆
[00:00:13,480 -> 00:00:16,480] 要比让人工智能去赢一个围棋世界冠军
[00:00:16,480 -> 00:00:17,600] 要难得多得多
[00:00:17,800 -> 00:00:19,039] 希望看完这期视频
[00:00:19,039 -> 00:00:20,800] 你就知道为什么是这个样子
[00:00:20,879 -> 00:00:22,879] 在下一期视频我也会讲一下
[00:00:22,879 -> 00:00:25,839] 人工智能现在真正优秀的英雄是什么样子的
[00:00:25,940 -> 00:00:27,239] 在我讲这些内容之前
[00:00:27,239 -> 00:00:29,280] 我先要跟大家推荐一篇文章
[00:00:00,000 -> 00:00:03,000] 明科同学在2019年初的时候发布的
[00:00:03,000 -> 00:00:05,799] 这样一篇人工智能为什么像人工智障的文章
[00:00:05,799 -> 00:00:08,080] 这篇文章在刚出的时候我就读了好几遍
[00:00:08,080 -> 00:00:09,720] 而且我还拿这篇文章的观点
[00:00:09,720 -> 00:00:13,560] 去跟我身边很多做人工智能的朋友去进行探讨
[00:00:13,560 -> 00:00:15,640] 他们有在Alexa研发科学的
[00:00:15,640 -> 00:00:18,239] 有在Alexa shopping做场景应用的
[00:00:18,239 -> 00:00:20,039] 有做人工智能客服的等等
[00:00:20,039 -> 00:00:23,160] 我们的反馈都是这篇文章说的东西非常有见解
[00:00:23,160 -> 00:00:23,960] 非常深刻
[00:00:23,960 -> 00:00:25,719] 而且它是从引领出发来讲
[00:00:25,719 -> 00:00:27,960] 我这期视频也会借用里面的很多例子
[00:00:27,960 -> 00:00:29,600] 它的例子举得也都非常生动
[00:00:00,000 -> 00:00:02,439] 希望大家有时间的话可以阅读一下
[00:00:02,439 -> 00:00:04,480] 虽然是三文字但是写得很生动
[00:00:04,480 -> 00:00:05,400] 强烈推荐
[00:00:05,400 -> 00:00:06,120] 好
[00:00:06,120 -> 00:00:08,400] 我们讲到人工智能的时候
[00:00:08,400 -> 00:00:10,359] 我们讲到强人工智能的时候
[00:00:10,359 -> 00:00:12,199] 大家都会提起来图灵测试
[00:00:12,199 -> 00:00:15,480] 也就是说当你把一个人工智能放到一个真人面前
[00:00:15,480 -> 00:00:17,600] 然后你不告诉他这是人还是计算机
[00:00:17,600 -> 00:00:21,760] 如果他靠对话能让对面的人觉得他是一个真人
[00:00:21,760 -> 00:00:22,640] 而不是计算机
[00:00:22,640 -> 00:00:24,519] 他就通过了图灵测试
[00:00:24,519 -> 00:00:27,519] 他就是一个真正意义上的人工智能了
[00:00:00,000 -> 00:00:02,560] 可是在业界这件事情被吐槽得很厉害
[00:00:02,560 -> 00:00:05,280] 因为这其实是关于一个欺骗的测试
[00:00:05,280 -> 00:00:07,040] 而不是关于智能的测试
[00:00:07,040 -> 00:00:08,880] 于是在这基础之上就有一个
[00:00:08,880 -> 00:00:10,560] WinsorGrid Schema的补充
[00:00:10,560 -> 00:00:14,720] 在我看来其实这个是更直击智能这件事情的本质
[00:00:14,720 -> 00:00:16,960] 想多了解的话可以去看一下Wiki
[00:00:16,960 -> 00:00:18,559] 但是归根结底他又说
[00:00:18,559 -> 00:00:20,239] 你要用图灵测试没有问题
[00:00:20,239 -> 00:00:23,079] 但是你在这里边去问他一些特定的问题
[00:00:23,079 -> 00:00:25,600] 这些特定的问题可以帮助你更好看一下
[00:00:25,600 -> 00:00:27,000] 对面的这个是不是智能
[00:00:27,000 -> 00:00:27,800] 什么问题呢
[00:00:27,800 -> 00:00:29,399] 还是用文章的那个例子
[00:00:00,000 -> 00:00:02,720] 就是我现在给你两个推荐
[00:00:02,919 -> 00:00:06,280] 你来告诉我这两个问题里边都会有一个代词
[00:00:06,280 -> 00:00:06,919] 就是他
[00:00:06,919 -> 00:00:09,759] 你来告诉我这个他到底指代的是什么东西
[00:00:09,759 -> 00:00:12,480] 我推荐四川火锅而不是日料
[00:00:12,480 -> 00:00:13,800] 因为它更辣
[00:00:13,839 -> 00:00:16,120] 这里边的他是指代着什么
[00:00:16,120 -> 00:00:17,280] 火锅还是日料
[00:00:17,519 -> 00:00:18,399] 选项二
[00:00:18,440 -> 00:00:21,199] 我推荐四川火锅而不是日料
[00:00:21,239 -> 00:00:22,160] 因为它不辣
[00:00:22,640 -> 00:00:23,079] 好了
[00:00:23,079 -> 00:00:24,679] 这里边的他指代的是什么
[00:00:24,679 -> 00:00:25,519] 火锅还是日料
[00:00:25,559 -> 00:00:27,399] 这对于任何一个人来说就很清楚
[00:00:27,559 -> 00:00:28,600] 第一个是火锅
[00:00:28,600 -> 00:00:29,920] 第二个是日料
[00:00:00,000 -> 00:00:03,319] 但是对于现在所谓的人工智能是不可能回答这个问题的
[00:00:03,319 -> 00:00:04,839] 它永远回答不了这个问题
[00:00:04,839 -> 00:00:07,559] 你只有派一个人去把答案直接告诉他
[00:00:07,559 -> 00:00:10,279] 然后限定他被问到这个问题的时候这样回答
[00:00:10,279 -> 00:00:12,080] 他才有可能回答出来这个问题
[00:00:12,080 -> 00:00:14,359] 这其实就是人工智能本质的区别
[00:00:14,359 -> 00:00:18,160] 就是我们回到前几期讲深度学习的原理
[00:00:18,160 -> 00:00:22,359] 就是我们把一堆输入通过这个黑箱模型变成了一个分数
[00:00:22,359 -> 00:00:25,440] 然后最后把这个分数去对应一个相应的行动
[00:00:25,440 -> 00:00:29,559] 比如说我跟Alexa说你去帮我开个灯
[00:00:00,000 -> 00:00:03,799] Alexa首先他会有一部模型把我的语音转化成文字
[00:00:03,799 -> 00:00:06,240] 然后他去基于这个文字进行一个判断
[00:00:06,240 -> 00:00:08,519] 然后发现我是要开灯
[00:00:08,519 -> 00:00:10,800] 于是他就去把我的灯给打开了
[00:00:10,800 -> 00:00:13,480] 可是他并没有理解我说的这些话是什么意思
[00:00:13,480 -> 00:00:16,679] 在他后台的模型里边其实有很多If and condition
[00:00:16,679 -> 00:00:18,719] 但是理想中的Deep Learning模型
[00:00:18,719 -> 00:00:22,760] 就是他把我的每个字进行拆解
[00:00:22,760 -> 00:00:23,839] 然后组合
[00:00:23,839 -> 00:00:25,879] 然后会发现你的这些话输入进来了
[00:00:25,879 -> 00:00:28,920] 或者说你这句话的组合在绝大多数情况下
[00:00:00,000 -> 00:00:01,600] 对应的是一个开灯的动作
[00:00:01,600 -> 00:00:03,960] 当我听到这样的一堆音频的话
[00:00:03,960 -> 00:00:05,000] 我就去开个灯
[00:00:05,000 -> 00:00:07,480] 或者说我当我看到了这些字的话
[00:00:07,480 -> 00:00:08,400] 我就去开个灯
[00:00:08,400 -> 00:00:11,679] 那当然这里边还可以加上一些对语言的理解
[00:00:11,679 -> 00:00:14,039] 去把信息更好的从中提取出来
[00:00:14,039 -> 00:00:17,320] 然后去更好的进行精准的行动
[00:00:17,320 -> 00:00:19,960] 可是问题是我刚刚说的那两句话
[00:00:19,960 -> 00:00:23,359] 除了我的除了这个东西烂还是不烂
[00:00:23,719 -> 00:00:26,399] 其实它的语言的结构是一样的
[00:00:26,399 -> 00:00:29,000] 也就是说你没有办法从一个黑箱模型
[00:00:00,000 -> 00:00:01,199] 去判断这件事情
[00:00:01,199 -> 00:00:04,200] 必须要有一个智能的对这个事情的理解
[00:00:04,200 -> 00:00:08,519] 才可能去判断它到底对应的火锅还是日料
[00:00:08,519 -> 00:00:10,880] 在这种情况下模型就无能为力了
[00:00:10,880 -> 00:00:13,279] 除非你开发出来一个非常general的
[00:00:13,279 -> 00:00:14,439] 对世界有理解的模型
[00:00:14,439 -> 00:00:16,199] 但是这件事情没有人知道怎么做
[00:00:16,199 -> 00:00:20,000] 所以这就是一个懂行和不懂行的人之间的分水岭了
[00:00:20,000 -> 00:00:24,120] 如果你对这件事情有一个基于first principle
[00:00:24,120 -> 00:00:25,839] 基于原则上的理解的话
[00:00:25,839 -> 00:00:28,679] 你就会知道比如说智能客服这个事儿
[00:00:00,000 -> 00:00:03,080] 真正的理解客人要干什么的这种智能客服
[00:00:03,080 -> 00:00:04,080] 是做不出来的
[00:00:04,280 -> 00:00:07,040] 但是你智能客服有的时候还是有很多的意义
[00:00:07,040 -> 00:00:09,640] 比如说它可以取代一个拨号系统
[00:00:09,640 -> 00:00:11,119] 给大家带来更多的体验
[00:00:11,119 -> 00:00:11,880] 什么意思呢
[00:00:11,880 -> 00:00:13,359] 就是说你打电话
[00:00:13,359 -> 00:00:15,839] 然后一上来会有一个应答机接听你
[00:00:15,839 -> 00:00:18,160] 说你要干这个前一干那个前二
[00:00:18,359 -> 00:00:20,320] 其实智能客服干的也就是这件事情
[00:00:20,320 -> 00:00:21,559] 但是它在这个过程中
[00:00:21,719 -> 00:00:23,399] 给你有了一个更多的对话
[00:00:23,399 -> 00:00:25,480] 给你了一个更好的用户体验
[00:00:25,480 -> 00:00:26,800] 然后在生产端那边
[00:00:27,000 -> 00:00:29,039] 它也给了生产端更多的buffer
[00:00:00,000 -> 00:00:03,480] 就是他通过这些无意义的对话来浪费客人的时间
[00:00:03,480 -> 00:00:06,559] 反而可以让你真实客服人员的负载量有一个更好的平衡
[00:00:06,559 -> 00:00:09,480] 这是很多大厂在做智能客服的意图
[00:00:09,480 -> 00:00:10,679] 但是如果你不懂
[00:00:10,679 -> 00:00:12,199] 你被大厂带到沟里去了
[00:00:12,199 -> 00:00:17,679] 然后你期望说我开发一个智能客服来取代我真实人能回答的问题
[00:00:17,679 -> 00:00:19,960] 最后上线的结果也就是一个人工智障
[00:00:19,960 -> 00:00:22,760] 和你想要的真正的人工智能风马牛不相及
[00:00:22,760 -> 00:00:25,120] 所以回到我们这个系列的初衷
[00:00:25,120 -> 00:00:28,679] 帮助大家更好的理解深度学习的应用场景和它的局限性
[00:00:00,000 -> 00:00:02,359] 这个上面深度学习能干的事情
[00:00:02,359 -> 00:00:04,759] 就是把一堆输入和一个结果
[00:00:04,759 -> 00:00:07,000] 通过鹦鹉学习的方式联系起来
[00:00:07,360 -> 00:00:09,560] 这里边绝大多数的应用的价值
[00:00:09,560 -> 00:00:11,240] 是来自于自动化
[00:00:11,400 -> 00:00:12,880] 也就是说本来
[00:00:12,919 -> 00:00:14,480] 你可能是需要一个人
[00:00:14,480 -> 00:00:16,600] 去开发非常非常复杂的系统
[00:00:16,600 -> 00:00:17,879] 开发一堆一堆的场景
[00:00:17,879 -> 00:00:18,839] 写1万个if
[00:00:18,839 -> 00:00:20,920] 然后这里边有很多复杂的业务逻辑
[00:00:21,039 -> 00:00:23,120] 才能把他们很好的给联系起来
[00:00:23,199 -> 00:00:24,480] 但是深度学习
[00:00:24,519 -> 00:00:27,079] 把这个整个学习的过程给自动化了
[00:00:27,120 -> 00:00:28,519] 你只要给他一堆输入
[00:00:28,519 -> 00:00:29,359] 给他一堆输出
[00:00:00,000 -> 00:00:02,600] 他就能把这里的规律给你鹦鹉学舌出来
[00:00:02,600 -> 00:00:03,960] 然后给联系起来
[00:00:03,960 -> 00:00:06,320] 这个仍然是非常有价值的
[00:00:06,320 -> 00:00:07,799] 而且他在做这件事情
[00:00:07,799 -> 00:00:10,119] 很多时候他的精度是超过人类的
[00:00:10,119 -> 00:00:11,839] 怎么样子去得到这些数据
[00:00:11,839 -> 00:00:14,599] 很多时候就是深度学习应用的门槛了
[00:00:14,599 -> 00:00:15,839] 比如说图像识别
[00:00:15,839 -> 00:00:18,079] 它的大发展就是ImageNet
[00:00:18,079 -> 00:00:20,600] 它有一大堆标记好的数据
[00:00:20,600 -> 00:00:24,280] 可以让你把你的模型放到这上面上去测试
[00:00:24,280 -> 00:00:26,399] 看你的模型是不是能在这么多
[00:00:26,399 -> 00:00:27,679] 我已经标好的数据里边
[00:00:00,000 -> 00:00:03,359] 非常正确的去预测到这个图像里边都包含着什么物体
[00:00:03,359 -> 00:00:06,000] 然后图像识别这里就有一个大发展
[00:00:06,000 -> 00:00:08,839] 很多企业在做这些深度学习模型的时候
[00:00:08,839 -> 00:00:11,080] 他们会去花很多的钱
[00:00:11,080 -> 00:00:14,080] 去找很多的标注者去进行标注
[00:00:14,080 -> 00:00:16,399] 当然了这里边又是一个特别大的topic
[00:00:16,399 -> 00:00:18,719] 就是你怎么样子去激励这些标注者
[00:00:18,719 -> 00:00:20,679] 让他们给你产生高质量的label
[00:00:20,679 -> 00:00:21,800] 因为你是要给他们钱的
[00:00:21,800 -> 00:00:23,199] 这里边是有利可图的
[00:00:23,199 -> 00:00:24,839] 所以说很多人可能会偷懒
[00:00:24,839 -> 00:00:26,879] 有的人甚至会用机器人去进行标注
[00:00:26,879 -> 00:00:29,359] 你最后给你的数据也都是一堆垃圾
[00:00:00,000 -> 00:00:01,919] 那这里面也是一个斗智斗勇的过程
[00:00:01,919 -> 00:00:03,480] 而且不同质量的service
[00:00:03,480 -> 00:00:05,599] 它的价钱差的也特别特别大
[00:00:05,599 -> 00:00:08,439] 很多大厂每年是几十亿几百亿的经费
[00:00:08,439 -> 00:00:10,160] 花在标注数据上的
[00:00:10,160 -> 00:00:12,160] 还有一些是自己可以产生数据的
[00:00:12,160 -> 00:00:15,439] 像AlphaGo或者说像其他的对抗算法
[00:00:15,439 -> 00:00:18,519] 因为围棋它虽然它的计算空间非常广
[00:00:18,519 -> 00:00:20,440] 但是它本质上是一个competition
[00:00:20,440 -> 00:00:21,879] 它没有什么不确定性
[00:00:21,879 -> 00:00:23,879] 就是你这一步可以走得更好
[00:00:23,879 -> 00:00:24,640] 可以走得更不好
[00:00:24,640 -> 00:00:25,879] 然后你的结果要么是赢
[00:00:25,879 -> 00:00:26,600] 要么是输
[00:00:26,600 -> 00:00:29,359] 这样的事情对于机器来说一定是有解的
[00:00:00,000 -> 00:00:02,520] 所以說AlphaGo一出來了以後
[00:00:02,520 -> 00:00:03,640] 不懂非懂的人就說
[00:00:03,640 -> 00:00:07,200] 啊 圍棋是人類智慧的最後一塊高地
[00:00:07,200 -> 00:00:08,759] 現在被人工智能佔領了
[00:00:08,759 -> 00:00:11,359] 這也就證明了人工智能全方位的碾我們了
[00:00:11,359 -> 00:00:12,160] 我覺得屁咧
[00:00:12,160 -> 00:00:14,599] 就是你的象棋是可以被解的
[00:00:14,599 -> 00:00:16,079] 你的圍棋也是可以被解的
[00:00:16,079 -> 00:00:17,800] 圍棋雖然它的搜索空間大
[00:00:17,800 -> 00:00:20,239] 但是這就是機器擅長的東西嘛
[00:00:20,239 -> 00:00:23,320] 它就是在一個確定解裡面找出來一個最優解
[00:00:23,320 -> 00:00:26,239] 對 它的計算空間是大
[00:00:26,239 -> 00:00:29,199] 可是你通過這個深度學習的方法
[00:00:00,000 -> 00:00:01,760] 你就是可以把你的搜索空间
[00:00:01,760 -> 00:00:04,719] 搜索最优解的空间给极大的减小
[00:00:04,719 -> 00:00:08,000] 最后你是可以说我这一步走这应该走这
[00:00:08,000 -> 00:00:09,759] 比走那更好是可以被解决的
[00:00:09,759 -> 00:00:12,279] 这对于一个计算机来说
[00:00:12,279 -> 00:00:14,039] 它只不过是一个程度问题
[00:00:14,039 -> 00:00:15,880] 它不是一个范式突破的问题
[00:00:15,880 -> 00:00:17,199] 它也不是一个本质问题
[00:00:17,199 -> 00:00:18,079] 你解决了围棋
[00:00:18,079 -> 00:00:21,160] 你仍然是不能去解决那些不确定性很高的东西
[00:00:21,160 -> 00:00:24,519] 你也不能解决那些需要演绎的
[00:00:24,519 -> 00:00:26,120] 需要cost influence的东西
[00:00:26,120 -> 00:00:29,719] 你最后做的不过就是计算归纳和优化而已
[00:00:00,000 -> 00:00:01,800] 可是话说回来就是AlphaGo
[00:00:01,800 -> 00:00:03,919] 去在解决这个问题过程中
[00:00:03,919 -> 00:00:07,280] 所用的各种各样的方法都是非常有创新性
[00:00:07,280 -> 00:00:08,199] 非常有启发性的
[00:00:08,199 -> 00:00:09,439] 让大家看了眼前一亮
[00:00:09,439 -> 00:00:10,439] 也给我们指明了
[00:00:10,439 -> 00:00:13,160] 深度学习的更多的广泛应用的场景
[00:00:13,679 -> 00:00:17,440] 最后一类就是它的数据是在用户的
[00:00:17,440 -> 00:00:18,879] engagement中间产生的
[00:00:18,879 -> 00:00:21,320] 比如说广告各种各样的推荐算法
[00:00:21,320 -> 00:00:22,239] 只要你推荐的好
[00:00:22,239 -> 00:00:23,879] 用户就更愿意点更愿意听
[00:00:24,120 -> 00:00:27,160] 这些模型也是现在互联网企业最值钱
[00:00:27,160 -> 00:00:27,760] 最赚钱
[00:00:00,000 -> 00:00:04,799] 而且是遠遠提供了人類所提供不了的額外價值的模型
[00:00:04,799 -> 00:00:09,119] 那我們下期視頻就會針對這些模型進行一些深度講解
[00:00:09,119 -> 00:00:11,119] 我們下期再見 拜拜
