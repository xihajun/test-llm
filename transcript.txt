[00:00:00,000 -> 00:00:00,900] Hello 大家好
[00:00:00,900 -> 00:00:02,100] 歡迎回到《科代表力證》
[00:00:02,100 -> 00:00:03,399] 我是你們的《科代表》
[00:00:03,399 -> 00:00:06,799] 今天我們繼續《科代表聊數據》的系列節目
[00:00:06,799 -> 00:00:10,779] 我今天想聊的一個話題就是
[00:00:10,779 -> 00:00:12,779] 這裡不要依賴模型做決策
[00:00:12,779 -> 00:00:13,880] 大概就是這個
[00:00:13,880 -> 00:00:16,920] 過度依賴模型做決策的這件事情
[00:00:16,920 -> 00:00:18,280] 其實在Facebook的時候
[00:00:18,280 -> 00:00:20,019] 我覺得有一門特別特別好的課
[00:00:20,019 -> 00:00:21,679] 叫Better Decisions
[00:00:21,679 -> 00:00:24,359] 我5月份會參加DataFun的一個論壇
[00:00:24,359 -> 00:00:26,440] 我在那裡邊也會講到時候
[00:00:26,440 -> 00:00:27,239] 參加完那個論壇
[00:00:27,239 -> 00:00:28,300] 我也會把我的材料
[00:00:28,300 -> 00:00:30,780] 給大家在我的頻道裡面講一遍
[00:00:30,780 -> 00:00:35,579] 就是如何用數據提高戰略決策的質量
[00:00:35,579 -> 00:00:38,619] 我覺得做好數據以後
[00:00:38,619 -> 00:00:40,579] 是能很大程度地提高
[00:00:40,579 -> 00:00:42,479] 你不管是戰略決策 戰術決策
[00:00:42,479 -> 00:00:45,000] 總之你能很好的提高決策質量的
[00:00:45,000 -> 00:00:47,399] 但是危險就是
[00:00:47,399 -> 00:00:49,759] 很多人會依賴模型做決策
[00:00:49,759 -> 00:00:51,600] 我先把這個觀點放在前面
[00:00:51,600 -> 00:00:53,880] 就是很多人依賴模型做決策
[00:00:53,880 -> 00:00:56,159] 其實就是他自己不敢擔責任
[00:00:56,159 -> 00:00:58,520] 就是他們或者不是不一定是他不敢
[00:00:58,520 -> 00:01:03,399] 總之就是試圖把人做決策的這個責任
[00:01:03,399 -> 00:01:06,200] 給放到模型上
[00:01:06,200 -> 00:01:08,599] 因為你做了一個非常複雜的模型
[00:01:08,599 -> 00:01:10,099] 然後最後你依賴這個模型
[00:01:10,099 -> 00:01:11,299] 去做了一個決策
[00:01:11,299 -> 00:01:13,799] 哪怕這個決策的結果是錯的
[00:01:13,799 -> 00:01:15,299] 大家只能說OK
[00:01:15,299 -> 00:01:17,599] 就是它是允許做錯誤的或者怎麼樣
[00:01:17,599 -> 00:01:19,200] 就是大家很難去怪罪一個模型
[00:01:19,200 -> 00:01:20,500] 做出了錯誤的決策
[00:01:20,500 -> 00:01:22,099] 但是大家會怪罪一個人
[00:01:22,099 -> 00:01:23,400] 做出了錯誤的決策
[00:01:23,400 -> 00:01:26,000] 所以說就是在這個大厂的管理中
[00:01:26,000 -> 00:01:28,000] 只要你不小心这件事情
[00:01:28,000 -> 00:01:31,000] 你最后的企业一定会犯这个错误
[00:01:31,000 -> 00:01:35,000] 就是大家在明明该用人做决策的情况下
[00:01:35,000 -> 00:01:37,000] 去用了模型做决策
[00:01:37,000 -> 00:01:38,000] 那接下来我就讲一下
[00:01:38,000 -> 00:01:41,000] 第一就是什么是依赖模型做决策
[00:01:41,000 -> 00:01:43,000] 就是它的表现形式是什么样子的
[00:01:43,000 -> 00:01:44,000] 然后第二呢
[00:01:44,000 -> 00:01:47,799] 我讲一下就是为什么模型做決策
[00:01:47,799 -> 00:01:49,000] 是個不靠譜的事情
[00:01:49,000 -> 00:01:50,000] 在很多情況下
[00:01:50,000 -> 00:01:50,719] 那第三個呢
[00:01:50,719 -> 00:01:52,799] 就是knowhow的重要性
[00:01:52,799 -> 00:01:54,920] 就是我們如果不去依賴
[00:01:54,920 -> 00:01:56,040] 這個模型做決策
[00:01:56,040 -> 00:01:58,959] 那大家其實在這個做決策的時候
[00:01:58,959 -> 00:02:00,040] 缺的是什麼能力
[00:02:00,040 -> 00:02:01,200] 在我看來很多時候
[00:02:01,200 -> 00:02:02,959] 是這個真正knowhow的能力
[00:02:02,959 -> 00:02:04,319] 對一個行業knowhow的能力
[00:02:04,319 -> 00:02:06,120] 那麼就要這個分開說
[00:02:06,120 -> 00:02:09,280] 第一個就是什麼樣子叫做一兩模型做決策呢
[00:02:09,280 -> 00:02:12,280] 有的地方是做indexing
[00:02:12,280 -> 00:02:14,479] 當然它也叫不同的名字
[00:02:14,479 -> 00:02:17,560] 所謂indexing就是我做決策
[00:02:17,560 -> 00:02:19,400] 我是需要最後有一個yes or no
[00:02:19,400 -> 00:02:21,400] 或者做一二三的這個決策對吧
[00:02:21,400 -> 00:02:26,319] 那我可能是要根據一個打分是吧根據一個
[00:02:26,319 -> 00:02:28,000] index或者根據一個數
[00:02:28,199 -> 00:02:30,000] 這個數高於多少我就做a
[00:02:30,000 -> 00:02:31,520] 然後在什麼區間我就做b
[00:02:31,520 -> 00:02:33,120] 然後低於多少我就做c
[00:02:33,120 -> 00:02:34,000] 大概是這樣子
[00:02:34,280 -> 00:02:36,080] 那我接下來呢會有一堆
[00:02:36,199 -> 00:02:38,360] 跟這個決策有關的因素
[00:02:38,639 -> 00:02:40,199] 我如果做indexing呢
[00:02:40,199 -> 00:02:42,280] 就是我把這些因素全都去
[00:02:42,639 -> 00:02:44,240] 想辦法想方設法的
[00:02:44,360 -> 00:02:46,000] 去算出來一个权重
[00:02:46,000 -> 00:02:48,759] 然后把它加权到这个数字
[00:02:48,759 -> 00:02:50,159] 然后好
[00:02:50,159 -> 00:02:51,960] 比如说我的利润率超过多少
[00:02:51,960 -> 00:02:54,759] 且我的销售额超过多少
[00:02:54,759 -> 00:02:56,960] 反正经过一系列复杂计算
[00:02:56,960 -> 00:02:58,240] 那我就应该做什么
[00:03:00,240 -> 00:03:01,360] 如果不用indexing做
[00:03:01,360 -> 00:03:03,840] 我们也可以用各种各样的模型去做
[00:03:03,840 -> 00:03:04,319] 对吧
[00:03:04,319 -> 00:03:06,500] 但是其实模型最后所做的事情也就是也可以用各種各樣的模型去做對吧但是其實模型最後所做的事情
[00:03:06,500 -> 00:03:08,500] 也就是把你的各種各樣的factor
[00:03:08,500 -> 00:03:10,500] 跟你的這個行動結合起來
[00:03:10,500 -> 00:03:12,500] 其實幹的是一個類似的事情
[00:03:12,500 -> 00:03:15,500] 只不過右邊的這些factor和左邊的這個
[00:03:15,500 -> 00:03:18,500] decision它的關係未必是線性的
[00:03:18,500 -> 00:03:23,500] 也似乎看起來有了一個更科學的過程
[00:03:23,500 -> 00:03:25,680] 但是很不幸的是
[00:03:25,680 -> 00:03:27,680] 在绝大多数的场合下
[00:03:27,680 -> 00:03:29,680] 这个都是不成立的
[00:03:29,680 -> 00:03:30,680] 那就是第二个问题了
[00:03:30,680 -> 00:03:31,879] 就是为什么这样子做
[00:03:31,879 -> 00:03:33,479] 大多数情况下不靠谱
[00:03:33,479 -> 00:03:35,479] 我觉得不靠谱的最主要的原因
[00:03:35,479 -> 00:03:38,000] 就是我们所知太少了
[00:03:38,000 -> 00:03:39,599] 那这就是第二段
[00:03:39,599 -> 00:03:43,400] 就是你模型其实能capture的东西
[00:03:43,400 -> 00:03:45,719] 或者说你这个右边的这些factor你能measure你能用数据你能作为模型其实能capture的东西或者说你这个右边的这些factor
[00:03:45,719 -> 00:03:47,800] 你能measure你能用数据
[00:03:47,800 -> 00:03:51,520] 你能作为模型input所展示的那些信息
[00:03:51,520 -> 00:03:53,919] 很有可能是你这个问题所需要信息的
[00:03:53,919 -> 00:03:55,680] 一个非常小的subset
[00:03:55,680 -> 00:03:58,400] 可能它是10% 20% 50%的信息
[00:03:58,400 -> 00:03:59,520] 但是总之呢
[00:03:59,520 -> 00:04:02,719] 它不能帮你真的去做好这个决策
[00:04:02,719 -> 00:04:04,199] 或者换句话说
[00:04:04,199 -> 00:04:07,560] 假设你真的大家都能看到这些东西的话
[00:04:07,560 -> 00:04:09,439] 那这个决策本身就非常好做
[00:04:09,439 -> 00:04:09,879] 对吧
[00:04:09,879 -> 00:04:11,599] 如果这样一个非常好做的东西
[00:04:11,599 -> 00:04:12,840] 你其实也不需要模型
[00:04:12,840 -> 00:04:14,120] 只需要一个规则就行了
[00:04:14,120 -> 00:04:16,839] 就是说大家非常生搬运套的
[00:04:16,839 -> 00:04:18,399] 如果发生了什么情况
[00:04:18,399 -> 00:04:19,519] 我们就去做什么
[00:04:19,519 -> 00:04:21,759] 这个东西其实也不太需要一个模型
[00:04:21,759 -> 00:04:24,800] 很多时候之所以大家会去说一个模型
[00:04:24,800 -> 00:04:28,800] 就是因为你根据这个有限的能觀察到的信息
[00:04:28,800 -> 00:04:33,399] 很難直接得到那個指引你行動的結果
[00:04:33,399 -> 00:04:37,000] 所以說大家想用模型去彌補這個是彌補不了的
[00:04:37,000 -> 00:04:38,399] 它是信息的差
[00:04:38,399 -> 00:04:41,199] 就是如果大家對信息這件事一定了解
[00:04:41,199 -> 00:04:43,800] 任何模型都不能產生新信息
[00:04:43,800 -> 00:04:47,720] 任何模型都是把你的現有信息进行一些组合
[00:04:47,720 -> 00:04:50,639] 如果说你的信息只占了你这个决策
[00:04:50,639 -> 00:04:52,600] 所需要信息的20%
[00:04:52,600 -> 00:04:56,079] 你通过模型是不可能产生了80%的信息含量的
[00:04:56,079 -> 00:04:57,959] 你商业的本质是什么
[00:04:57,959 -> 00:05:00,319] 或者说是这个商业决策的本质是什么
[00:05:00,319 -> 00:05:04,879] 就是你要对这个80%没有的信息里边
[00:05:04,879 -> 00:05:06,399] 你要通过你的influence也好
[00:05:06,399 -> 00:05:07,899] 你要通過你的sense也好
[00:05:07,899 -> 00:05:09,899] 你要通過你的business acumen也好
[00:05:09,899 -> 00:05:11,399] 你要通過你的domain knowledge也好
[00:05:11,399 -> 00:05:12,899] 你要通過你的experience也好
[00:05:12,899 -> 00:05:14,899] 去用你的認知
[00:05:14,899 -> 00:05:17,899] 盡可能地符合真實世界的情況
[00:05:17,899 -> 00:05:19,899] 然後通過你的認知
[00:05:19,899 -> 00:05:21,899] 去在這麼多不確定性的情況下
[00:05:21,899 -> 00:05:25,600] 去做出一個你覺得最符合未來的決策
[00:05:25,600 -> 00:05:27,300] 或者說最有利的決策
[00:05:27,300 -> 00:05:28,600] 這個是商業的本質
[00:05:28,600 -> 00:05:30,899] 你想試圖用模型
[00:05:30,899 -> 00:05:32,600] 去取代這個商業的本質
[00:05:32,600 -> 00:05:33,899] 不好意思
[00:05:33,899 -> 00:05:34,899] 是做不到的
[00:05:34,899 -> 00:05:36,100] 然後人為什麼要做
[00:05:36,100 -> 00:05:38,000] 就像我一開始投射的那樣子
[00:05:38,000 -> 00:05:39,500] 因為人們怕擔責任
[00:05:39,500 -> 00:05:40,800] 因為你要在
[00:05:40,800 -> 00:05:43,300] 有80%不確定性的情況下
[00:05:43,300 -> 00:05:45,879] 去做一個會影響未来的决策
[00:05:45,879 -> 00:05:46,959] 这个时候做错了
[00:05:46,959 -> 00:05:49,680] 当然是有很大的责任的
[00:05:49,680 -> 00:05:52,120] 有的时候人们管理层们
[00:05:52,120 -> 00:05:54,720] 在大厂里面都会有agency problem
[00:05:54,720 -> 00:05:56,720] 就是这些做决定的这些人
[00:05:56,720 -> 00:05:58,040] 他未必想担这个责任
[00:05:58,040 -> 00:06:00,000] 他就会把这个事情交给模型
[00:06:00,000 -> 00:06:00,720] 好
[00:06:00,720 -> 00:06:05,839] 就是为什么模型不能做出一个好决策的原因
[00:06:05,839 -> 00:06:10,279] 就是如果你需要用模型做决策的这种问题
[00:06:10,279 -> 00:06:11,879] 大多数的情况下
[00:06:11,879 -> 00:06:15,519] 模型所in take的这些information是不够的
[00:06:15,879 -> 00:06:19,720] 那第三点就是那你这个时候想要做好这些决定
[00:06:19,720 -> 00:06:21,839] 你最需要的能力是什么
[00:06:22,120 -> 00:06:23,959] 我据我观察
[00:06:23,959 -> 00:06:27,160] 就是有一个东西是很難被measure
[00:06:27,160 -> 00:06:28,839] 但是又很欠缺的
[00:06:29,079 -> 00:06:30,560] 就是knowhow的能力
[00:06:31,000 -> 00:06:32,600] 比如說我們會經常吐槽
[00:06:32,600 -> 00:06:34,600] 就是大廠做不出好內容
[00:06:34,720 -> 00:06:35,160] 對吧
[00:06:35,360 -> 00:06:37,240] 然後一些我們
[00:06:37,240 -> 00:06:39,360] 騰訊經常被吐槽做不出好遊戲
[00:06:39,639 -> 00:06:40,839] 那這個時候是什麼
[00:06:40,839 -> 00:06:42,120] 就是有一些人
[00:06:42,120 -> 00:06:43,639] 像宮崎英高這樣的
[00:06:43,639 -> 00:06:44,959] 非常牛逼的製作人
[00:06:45,000 -> 00:06:48,000] 他有很強的這個knowhow的能力
[00:06:48,000 -> 00:06:50,000] 我記得之前好像有人說過
[00:06:50,000 -> 00:06:52,000] 就是想開發一款好遊戲需要什麼
[00:06:52,000 -> 00:06:54,000] 他們說其實就是需要一個
[00:06:54,000 -> 00:06:55,000] 牛逼的製作人
[00:06:55,000 -> 00:06:57,000] 但是世界上真正牛逼的製作人
[00:06:57,000 -> 00:06:59,000] 可能也就不超過五個
[00:06:59,000 -> 00:07:00,000] 你知道這些人是誰
[00:07:00,000 -> 00:07:02,000] 但是有絕大多數的人
[00:07:02,000 -> 00:07:04,000] 他有這個knowhow的能力
[00:07:04,000 -> 00:07:05,800] 但是這個東西沒有辦法去衡量
[00:07:05,800 -> 00:07:07,600] 所以說他就沒有辦法出頭
[00:07:07,600 -> 00:07:09,199] 組織也很難去
[00:07:09,199 -> 00:07:12,500] 給這些人一個出頭的機會
[00:07:12,500 -> 00:07:15,899] 因為你想要識別一個人有knowhow的能力
[00:07:15,899 -> 00:07:17,399] 你首先要有伯樂對吧
[00:07:17,399 -> 00:07:20,300] 你這個伯樂就是首先要知道knowhow
[00:07:20,300 -> 00:07:21,800] 你要知道什麼是好內容
[00:07:21,800 -> 00:07:24,500] 比如說你要去判斷一個想要製作好內容
[00:07:24,500 -> 00:07:27,879] 那你首先你這個導演和製作人要能有这个基本的审美
[00:07:27,879 -> 00:07:28,800] 知道什么是好内容
[00:07:28,800 -> 00:07:29,920] 什么是不好的内容
[00:07:29,920 -> 00:07:33,240] 但是非常可惜的是
[00:07:33,240 -> 00:07:36,839] 在这个资本和流量的挟持下
[00:07:36,839 -> 00:07:37,839] 我不想用这两个词
[00:07:37,839 -> 00:07:38,959] 但是确实是这样的
[00:07:38,959 -> 00:07:43,040] 就是商业的逻辑之下
[00:07:43,040 -> 00:07:46,439] 真正的那些decision maker他们很有可能是对商业这奻辑之下真正的那些decision maker
[00:07:46,439 -> 00:07:49,800] 他们很有可能是对商业这套玩得很溜
[00:07:49,800 -> 00:07:55,199] 但是他们对内容或者说是对一些事物本身
[00:07:55,199 -> 00:07:58,000] 缺乏这种know how
[00:07:58,000 -> 00:08:02,399] 或者说是缺乏这种基于quality的判断能力
[00:08:02,399 -> 00:08:04,399] 这个说的是creative的东西
[00:08:04,399 -> 00:08:06,300] 那你如果说是一个operational的东西
[00:08:06,300 -> 00:08:07,600] 就比如说你一个工厂
[00:08:07,600 -> 00:08:08,899] 你要不要添这个机器
[00:08:08,899 -> 00:08:12,199] 其实真正想要做好这个决策
[00:08:12,199 -> 00:08:14,800] 你就要去工厂的一线
[00:08:14,800 -> 00:08:17,199] 了解所有的这个生产的流程
[00:08:17,199 -> 00:08:19,100] 然后你要去市场的一线
[00:08:19,100 -> 00:08:22,000] 去了解用户对你产品的各种各样的反应
[00:08:22,000 -> 00:08:24,000] 你如果真的了解这些信息的话
[00:08:24,000 -> 00:08:26,800] 你自然而然可以做出一個好的決策
[00:08:26,800 -> 00:08:28,800] 但是也是很可惜
[00:08:28,800 -> 00:08:31,300] 就是大家都是通過抽象的方式去管理
[00:08:31,300 -> 00:08:33,299] 這個時候你所了解的世界
[00:08:33,299 -> 00:08:35,299] 已經和真實的世界差很大了
[00:08:35,299 -> 00:08:38,000] 這期視頻我回頭會單獨講吧
[00:08:38,000 -> 00:08:40,299] 就是一線經驗的重要
[00:08:40,299 -> 00:08:42,299] 和從定義出發
[00:08:42,299 -> 00:08:44,000] 或者從抽象概念出發
[00:08:44,000 -> 00:08:47,600] 去理解問題最後會導致什么非常危险的结果
[00:08:47,600 -> 00:08:51,399] 这也是我看到很多其实很不错的产品经理
[00:08:51,399 -> 00:08:52,899] 或者说很不错的leadership
[00:08:52,899 -> 00:08:55,000] 他们会陷入的一个误区
[00:08:55,000 -> 00:08:56,399] 从而犯的错误
[00:08:56,399 -> 00:08:57,100] 好的
[00:08:57,100 -> 00:08:58,799] 稍稍总结我今天的话题
[00:08:58,799 -> 00:09:01,600] 就是不要依赖模型做决策这件事情
[00:09:01,600 -> 00:09:04,299] 我刚刚讲的就是第一
[00:09:04,299 -> 00:09:06,080] 什么是用模型做决策这件事情我刚刚讲的第一什么是用模型做决策
[00:09:06,080 -> 00:09:10,000] 就是你把一堆你能看到的这些factor
[00:09:10,039 -> 00:09:12,120] 试图用不管什么样的模型
[00:09:12,120 -> 00:09:12,559] 是吧
[00:09:12,600 -> 00:09:17,639] 去自动化的去link到一些action上
[00:09:17,799 -> 00:09:20,399] 然后这件事情第二
[00:09:20,399 -> 00:09:22,480] 它大概率是不靠谱的
[00:09:22,480 -> 00:09:27,440] 因为你所知的信息其实是你需要做决策的信息的很少的一部分
[00:09:27,799 -> 00:09:31,679] 然后第三这里边缺的很大的一部分
[00:09:31,840 -> 00:09:37,200] 我觉得knowhow的能力或者说一线的精力是非常重要的
[00:09:37,600 -> 00:09:41,080] 大家应该去想方设法的去补足这里的精力
[00:09:41,080 -> 00:09:44,399] 就是想方设法的去给培养自己的感觉
[00:09:44,639 -> 00:09:46,799] 然后这里边如果有什么东可以沉澱成數據
[00:09:46,799 -> 00:09:48,000] 當然最好是吧
[00:09:48,000 -> 00:09:51,600] 只要沉澱出來的數據肯定是對你的這個決策有用
[00:09:51,600 -> 00:09:54,399] 肯定是對你的這個operation也是很有用的
[00:09:54,399 -> 00:09:58,600] 但是哪怕不能沉澱出這個數據的情況下
[00:09:58,600 -> 00:10:03,399] 大家也不要就是看到一個虛無飄渺的東西
[00:10:03,399 -> 00:10:05,559] 然後就不去理解它
[00:10:05,559 -> 00:10:07,120] 然後只盯著數字去看
[00:10:07,120 -> 00:10:10,639] 你要去培養你對這些虛無飄渺
[00:10:10,639 -> 00:10:13,080] 但是對結果非常重要的這些東西的一個sense
[00:10:13,080 -> 00:10:16,360] 起碼你要能培養出識別出專家
[00:10:16,360 -> 00:10:20,159] 並且給專家足夠話語權的這樣的能力
[00:10:20,919 -> 00:10:24,320] 最後大家一定要小心這件事情
[00:10:24,320 -> 00:10:27,340] 因為agency problem
[00:10:27,340 -> 00:10:29,340] 因为人们想摆脱责任
[00:10:29,340 -> 00:10:34,340] 因为人们会想用模型决策去取代人的决策
[00:10:34,340 -> 00:10:35,940] 从而让自己不担责任
[00:10:35,940 -> 00:10:39,259] 所以说只要你不小心这件事情就一定会发生的
[00:10:39,259 -> 00:10:42,419] 好的希望我这次把这件事情讲清楚了
[00:10:42,419 -> 00:10:44,419] 那我们下期再见拜拜
