[00:00:00,000 -> 00:00:04,480] 其实在GPT的大模型里面的知识是非常大的
[00:00:04,480 -> 00:00:07,799] 我们在现在只不过是activated其中一点点
[00:00:07,799 -> 00:00:11,880] 然后是通过这种instruct或者说是chat的方式
[00:00:11,880 -> 00:00:16,199] 去让这个模型的输出变得更palatable to human
[00:00:16,199 -> 00:00:17,679] 就是我们更容易理解
[00:00:17,679 -> 00:00:21,079] 它的思维模式可能远远在我们所能理解之上
[00:00:21,079 -> 00:00:23,239] 其实有一个问题就是你的prompt
[00:00:23,239 -> 00:00:26,359] 你要去让chat GPT完成各种各样的任务
[00:00:26,359 -> 00:00:30,399] 那到底是一个工程技巧还是一个PM技巧
[00:00:30,399 -> 00:00:33,119] 就是你是要教给拆GPT怎么用呢
[00:00:33,119 -> 00:00:35,799] 还是你是要告诉拆GPT做什么
[00:00:35,799 -> 00:00:38,359] 再说一些这个过往的历史
[00:00:38,520 -> 00:00:41,200] 就是拆GPT这件事不是一个真的prediction
[00:00:41,200 -> 00:00:44,759] 它只不过是历史很多颠覆科技的重复
[00:00:44,759 -> 00:00:45,600] Hello大家好之前我不是写过一个文章吗关是历史很多颠覆科技的重复哈喽大家好
[00:00:45,600 -> 00:00:46,920] 之前我不是写过一个文章吗
[00:00:46,920 -> 00:00:48,600] 关于TGPT的5个问题
[00:00:48,960 -> 00:00:50,719] 我发现我其实写了一个slides
[00:00:50,719 -> 00:00:51,920] 然后在去年3月份
[00:00:52,119 -> 00:00:55,520] 今天我就会结合这个slides里的内容
[00:00:55,759 -> 00:00:58,280] 然后和我们这一年的观察
[00:00:58,479 -> 00:01:00,320] 给大家重温一下这5个问题
[00:01:00,320 -> 00:01:02,320] 然后带来一些新的见解
[00:01:02,600 -> 00:01:04,200] 像大家看到的
[00:01:04,200 -> 00:01:06,000] 我现在其实是在一个狗公园旁边
[00:01:06,000 -> 00:01:10,000] 然后我就坐在狗公园旁边
[00:01:10,000 -> 00:01:11,000] 去给大家看
[00:01:11,000 -> 00:01:13,000] 我们可以先看一下它的
[00:01:14,000 -> 00:01:16,000] 一个immersive mode
[00:01:16,000 -> 00:01:17,000] 在狗公园里边
[00:01:17,000 -> 00:01:20,000] 我瞬间就来到了
[00:01:21,000 -> 00:01:23,000] 乔布斯发布会的现场
[00:01:23,000 -> 00:01:29,319] 然后我在这里就可以去给大家讲我的PPT
[00:01:29,319 -> 00:01:30,319] Lights Up
[00:01:30,319 -> 00:01:32,120] Oh
[00:01:32,120 -> 00:01:33,120] Lights Down
[00:01:39,799 -> 00:01:40,799] 第一个问题
[00:01:40,799 -> 00:01:42,159] 第一个问题
[00:01:42,159 -> 00:01:44,400] 好像这样还是不太好玩
[00:01:44,400 -> 00:01:47,120] 我们还是回到我们原來的模式吧
[00:01:53,560 -> 00:01:57,000] 這樣的話就給大家一邊看我們做的這個
[00:01:57,000 -> 00:02:00,599] 一邊看狗狗在那裡玩
[00:02:03,319 -> 00:02:04,120] 是哪五個問題
[00:02:04,120 -> 00:02:05,959] 然後為什麼這五個问题都很重要呢
[00:02:06,319 -> 00:02:07,719] 第一个就是
[00:02:07,719 -> 00:02:09,199] 拆GPD到底是什么
[00:02:09,199 -> 00:02:11,240] 它是一个范式突破吗
[00:02:11,560 -> 00:02:14,599] 我们在这个Vision Pro出来的时候
[00:02:14,599 -> 00:02:15,879] 在iPhone出来的时候
[00:02:15,879 -> 00:02:17,400] 在一个新科技出来的时候
[00:02:17,520 -> 00:02:20,159] 这都是一个我们最需要问的问题
[00:02:20,360 -> 00:02:21,759] 为什么这个问题重要
[00:02:21,759 -> 00:02:23,120] 因为它只有范式突破
[00:02:23,120 -> 00:02:25,439] 才能带来一个十倍百倍的机会
[00:02:25,439 -> 00:02:30,400] 如果你在原有的基础之上做一个小范围的突破
[00:02:30,400 -> 00:02:31,840] 而不是一个范式突破的话
[00:02:31,840 -> 00:02:34,319] 它其实能带来的机会是有限的
[00:02:34,319 -> 00:02:37,919] 因为范式突破才可以让你做到之前完全不可能做到的事情
[00:02:37,919 -> 00:02:40,560] 而不是在原有的基础之上降本增效
[00:02:40,560 -> 00:02:46,000] 第二个就是我们怎么样子去了解大圃远模型的impact到底是什么
[00:02:46,000 -> 00:02:49,000] 第三个就是我们如何去制造一个大跃远模型
[00:02:49,000 -> 00:02:53,000] 第四个问题是我们如何使用大跃远模型
[00:02:53,000 -> 00:02:57,000] 第五个是我们人类和大跃远模型有什么不一样
[00:02:57,000 -> 00:02:59,000] 这四个问题都是顺接的
[00:02:59,000 -> 00:03:02,000] 就是我们了解了它到底能产生什么样的影响
[00:03:02,000 -> 00:03:05,400] 尤其是站在这个技术刚刚出现的时候
[00:03:05,400 -> 00:03:08,319] 我们要去想象它5年后10年后的影响
[00:03:08,319 -> 00:03:11,000] 这样的话我们才可以知道
[00:03:11,000 -> 00:03:14,199] 它给我们带来的机会在哪里
[00:03:14,199 -> 00:03:17,599] 带来有影响之后我们想抓到这个机会
[00:03:17,599 -> 00:03:19,680] 接下来就是说它的难度是如何
[00:03:19,680 -> 00:03:22,759] 这样一方面我们可以了解它的发展速度
[00:03:22,759 -> 00:03:25,360] 另外一方面也能了解我们在这里边应该做什么
[00:03:25,360 -> 00:03:29,879] 现在说假设我们不是作为大模型的生产方的话
[00:03:29,879 -> 00:03:33,719] 我们应该怎么去使用它才能更好的让它去改变我们的生活
[00:03:33,719 -> 00:03:35,039] 抓住这里边的机会
[00:03:35,039 -> 00:03:37,759] 最后其实是一个究极问题了
[00:03:37,759 -> 00:03:43,159] 就是我们站到技术已经发展到完全非常成熟的时候
[00:03:43,159 -> 00:03:45,400] 人类和技术还有什么不一样
[00:03:45,400 -> 00:03:47,599] 就是说我们还应该去做什么
[00:03:47,599 -> 00:03:49,800] 才是不会被这个技术所改变的
[00:03:49,800 -> 00:03:52,500] 就是为什么这五个问题是这样的顺序
[00:03:52,500 -> 00:03:54,400] 和为什么这五个问题这么重要
[00:03:54,400 -> 00:03:56,199] 互联网上很多东西都是noise
[00:03:56,199 -> 00:03:57,300] 那在这个noise之外
[00:03:57,300 -> 00:03:59,400] 到底还有什么东西是重要的
[00:04:02,800 -> 00:04:04,900] 有一些技术细节是必须要知道的
[00:04:04,900 -> 00:04:05,000] 我们这就最进行一些最最最简单的技术细节是必须要知道的
[00:04:05,000 -> 00:04:08,639] 我们这就最进行一些最最最简单的技术普及
[00:04:08,639 -> 00:04:10,280] 最简单的就是
[00:04:10,280 -> 00:04:13,199] Chai GPT它其实是一个几个关键词
[00:04:13,199 -> 00:04:14,560] 我把它放大一点
[00:04:14,560 -> 00:04:16,639] 这样还可以再远一点吗
[00:04:16,639 -> 00:04:18,399] 再来一
[00:04:18,399 -> 00:04:21,480] 好像也就这么远了
[00:04:21,480 -> 00:04:25,279] Chai GPT它是一个叫做
[00:04:25,279 -> 00:04:28,079] Generative Autoregressive Large Language Models
[00:04:28,079 -> 00:04:29,120] 它是一个代元模型
[00:04:29,120 -> 00:04:32,920] 然后这个代元模型它的本质是一个生成式的
[00:04:32,920 -> 00:04:36,319] 然后它是一个Autoregressive就是自回归式的
[00:04:36,319 -> 00:04:38,800] 那这个具体怎么理解
[00:04:38,800 -> 00:04:44,759] 就是它是这个是一个就是Stefan Wolfram的一个图
[00:04:44,759 -> 00:04:45,839] 我觉得他讲的很好
[00:04:45,839 -> 00:04:48,079] 它的底层的模型GPT
[00:04:48,079 -> 00:04:51,920] 它要做的事情就是你去generate the next world
[00:04:51,920 -> 00:04:54,279] 这有一个好处就是
[00:04:54,279 -> 00:04:57,759] 它有人类有海量的文本去训练这个模型
[00:04:57,759 -> 00:04:59,920] 就是它在想方设法生成下一个次
[00:04:59,920 -> 00:05:02,439] 然后你这样自然而然就可以把人类已知的文本
[00:05:02,439 -> 00:05:04,040] 和它去进行一个匹配
[00:05:04,040 -> 00:05:05,439] 看它生成了对不对
[00:05:05,439 -> 00:05:08,079] 这样的话你就有海量的标签好的数据
[00:05:08,079 -> 00:05:10,519] 去帮助你这个模型去学习
[00:05:10,519 -> 00:05:13,759] 之后就是他们非常重要的
[00:05:13,759 -> 00:05:15,439] scaling law的observation
[00:05:15,439 -> 00:05:16,839] 我在这稍微再多解释
[00:05:16,839 -> 00:05:18,160] 就在这里就多解释一下
[00:05:19,279 -> 00:05:22,120] 为什么generative这个任务如此之重要
[00:05:22,120 -> 00:05:23,120] 有两个点
[00:05:23,120 -> 00:05:25,000] 第一个就是过去的machinery model它都不general它只能做一个非常简单的任务如此之重要有两个点第一个就是过去的Models
[00:05:25,000 -> 00:05:26,000] 它都不general
[00:05:26,000 -> 00:05:28,000] 它只能做一个非常简单的任务
[00:05:28,000 -> 00:05:30,000] 那它做一个简单的任务就是
[00:05:30,000 -> 00:05:31,000] 你告诉它一个目标
[00:05:31,000 -> 00:05:33,000] 然后你能告诉它做得好还是不好
[00:05:33,000 -> 00:05:35,000] 那它就可以去学习
[00:05:35,000 -> 00:05:36,000] 在这方面可以做得很好
[00:05:36,000 -> 00:05:40,000] 但是问题是你所有的告诉它做得好还是不好的
[00:05:40,000 -> 00:05:41,000] 这些数据都必须要标注
[00:05:41,000 -> 00:05:43,000] 都是所谓的labeled
[00:05:43,000 -> 00:05:46,079] 包括你的就是unsupervised learning其实你在一定程度上也必须要标注都是所谓的labeled包括你的unsupervised learning
[00:05:46,079 -> 00:05:49,680] 其实你在一定程度上也必须要告诉这个模型的做得好还是不好
[00:05:49,680 -> 00:05:52,879] 这样的数据其实是有限的和人需要去生成的
[00:05:52,879 -> 00:05:55,920] 也就是说你不能让模型去举一反三
[00:05:55,920 -> 00:06:00,240] 你只能让模型去做一个已经限定好的任务下去进行优化
[00:06:00,240 -> 00:06:03,680] 可是generative这个事情就变得非常的
[00:06:03,680 -> 00:06:07,680] 在文本上的generation就变得非常的普适
[00:06:07,680 -> 00:06:09,560] 因为人类有海量的文本
[00:06:09,560 -> 00:06:11,959] 那你只要告诉你就什么都不用想
[00:06:11,959 -> 00:06:13,279] 你甚至不用去定义这个人物
[00:06:13,279 -> 00:06:15,360] 你只要摆这个海量的文本
[00:06:15,360 -> 00:06:17,000] 只要你的质量还是可以的
[00:06:17,000 -> 00:06:19,519] 所以说你的这个数据量一下就可以多了很多
[00:06:19,519 -> 00:06:22,480] 那接下来你需要去做的就是去想方设法
[00:06:22,480 -> 00:06:23,600] 来把这个模型变大
[00:06:23,600 -> 00:06:25,279] 让他可以多学到这里面的知识
[00:06:25,279 -> 00:06:27,560] 和多给模型为高质量的文本
[00:06:27,560 -> 00:06:29,160] 接下来就是一个leap of faith
[00:06:29,160 -> 00:06:32,600] 就是你会相信这么一个大模型能产出好的结果
[00:06:32,600 -> 00:06:34,279] 这个leap of faith非常的重要
[00:06:34,279 -> 00:06:37,439] 但是OpenAI的人很明显是有这样的一个信仰的
[00:06:37,439 -> 00:06:38,519] 他们也做到了
[00:06:39,959 -> 00:06:41,800] 这些技术细节我们就不多聊了
[00:06:42,000 -> 00:06:46,000] 就是接下来一个技术很重要的点就是in context learning
[00:06:46,000 -> 00:06:48,240] 然后这一点其实是非常重要的
[00:06:48,240 -> 00:06:50,959] 就是fantuning和in context learning的区别是什么
[00:06:50,959 -> 00:06:53,319] 尤其是fantuning和few shot的区别是什么
[00:06:53,319 -> 00:06:56,079] 因为乍一看他们其实可能是差不多的
[00:06:57,720 -> 00:06:59,839] 这也是很多过去的machinery scientist
[00:06:59,839 -> 00:07:01,600] 在这方面会出现问题的地方
[00:07:01,600 -> 00:07:02,879] 在这个概念上会出现问题
[00:07:02,879 -> 00:07:05,560] 因为其实你说in context learning
[00:07:05,560 -> 00:07:06,600] 是不是fantuning
[00:07:06,600 -> 00:07:09,040] 从一定程度上也是可以这么说的
[00:07:09,040 -> 00:07:12,000] 因为fantuning这个词并不是特别的精确
[00:07:12,199 -> 00:07:14,519] 所以呢我们这儿就发现fantuning其实是
[00:07:14,519 -> 00:07:15,439] 一个过度
[00:07:15,639 -> 00:07:17,560] broad过度宽泛的一个词
[00:07:17,759 -> 00:07:19,639] 那我们怎么样子去区别呢
[00:07:19,639 -> 00:07:20,800] 我们就区别过去的
[00:07:20,800 -> 00:07:21,600] machinery model
[00:07:21,600 -> 00:07:23,879] 是需要change the weight of the base model
[00:07:24,040 -> 00:07:25,519] 但是in context learning呢他其实是activ是需要change the weight of the base model但是in context learning
[00:07:25,519 -> 00:07:28,720] 它其实是activate了different weights in the base model
[00:07:28,720 -> 00:07:30,199] 它不需要change the base
[00:07:30,199 -> 00:07:32,480] change the weight of the base model
[00:07:32,480 -> 00:07:35,360] 就是你用GPT出来的东西
[00:07:35,360 -> 00:07:37,319] 你其实是不改变的GPT的
[00:07:37,319 -> 00:07:38,600] 你是拿着GPT这个模型
[00:07:38,600 -> 00:07:40,560] 然后去提炼出来了一个不一样的东西
[00:07:40,560 -> 00:07:43,680] 是通过alignment这一层去提炼出来的不同的东西
[00:07:43,680 -> 00:07:45,319] activate了不同的weight但是你没有回去做的不同的东西activate不同的位置
[00:07:45,319 -> 00:07:47,639] 但是你没有回去做一个不同的任务
[00:07:47,639 -> 00:07:49,600] 就要去把GPT给改变一次
[00:07:49,600 -> 00:07:50,720] 这个是很重要的
[00:07:50,720 -> 00:07:51,759] 这就是区别了
[00:07:51,759 -> 00:07:52,439] 就traditional
[00:07:52,439 -> 00:07:53,920] 如果说一个high level的解释的话
[00:07:53,920 -> 00:07:56,839] traditional ML是new task需要new model
[00:07:56,839 -> 00:07:59,680] in context learning可以让你做到new task
[00:07:59,680 -> 00:08:02,000] same model different alignment
[00:08:02,000 -> 00:08:04,600] 然后第三个重要的点就是emergence
[00:08:04,600 -> 00:08:06,000] 就是涌现大模型的涌整然后第三个重要的点就是Emergence就是涌现
[00:08:06,000 -> 00:08:08,000] 大模型的涌现是一个非常重要的点
[00:08:08,000 -> 00:08:10,000] 就是它不是线性的一点一点变好的
[00:08:10,000 -> 00:08:12,000] 而是过了一个节点突然就变得很好了
[00:08:12,000 -> 00:08:14,000] 这个点是很重要的
[00:08:14,000 -> 00:08:18,000] 就是它会让你的工程变得不是那么可控
[00:08:18,000 -> 00:08:20,000] 我们不知道为什么我们也不能partake
[00:08:20,000 -> 00:08:23,000] 但是我们知道它好像你给它足够多的数据
[00:08:23,000 -> 00:08:25,120] 足够大的模型他就出现了
[00:08:25,759 -> 00:08:28,240] 这些我们就一个一个过我们就不多说了
[00:08:28,240 -> 00:08:29,720] 你如果想看的话可以了解
[00:08:29,720 -> 00:08:32,879] 所以这个时候你就是这个图虽然很可怕
[00:08:32,879 -> 00:08:34,720] 但是我觉得其实讲的还是有点道理的
[00:08:34,720 -> 00:08:38,159] 就是我们在背后是整个就是GPT的
[00:08:38,159 -> 00:08:40,080] 这个所谓的unsupervised learning
[00:08:40,080 -> 00:08:42,440] 当然这个词也不是完全准
[00:08:42,440 -> 00:08:46,840] 我觉得更准的是把unsupervised learning 变成 GPT
[00:08:46,840 -> 00:08:48,960] 就是它的 base model
[00:08:48,960 -> 00:08:52,799] 然后 supervised fine tuning 我们把它叫做 alignment
[00:08:52,799 -> 00:08:55,679] 然后 reinforcement learning with human feedback
[00:08:55,679 -> 00:08:57,879] 这个可以是 alignment 中间的一环
[00:08:57,879 -> 00:09:00,360] 是 alignment 的其中一种方法
[00:09:00,360 -> 00:09:03,519] 我就不太多去详细解释它了
[00:09:03,519 -> 00:09:09,360] 但是总之其实在 GPT 的大模型里面的知识是非常大的
[00:09:09,360 -> 00:09:12,559] 我们在现在只不过是activate了它的其中一点点
[00:09:12,559 -> 00:09:16,639] 然后是通过这种instruct或者说是chat的方式
[00:09:16,639 -> 00:09:21,120] 去让这个模型的输出变得更palatable to human
[00:09:21,120 -> 00:09:24,480] 就是我们更容易理解或者说我们更容易appreciate
[00:09:24,480 -> 00:09:28,399] 其实它的思维模式可能远远在我们所能理解之上
[00:09:28,399 -> 00:09:31,519] 只不过我们没有办法理解模型在想什么
[00:09:31,519 -> 00:09:34,799] 我们需要用chat的方式去理解模型在想什么
[00:09:34,799 -> 00:09:38,559] 最后就是reinforcement learning with human feedback
[00:09:38,559 -> 00:09:42,080] 其实如果大家去看extract gpt和chat gpt的paper的话
[00:09:42,080 -> 00:09:45,399] 你会发现他们的整个范式是非常接近的
[00:09:45,399 -> 00:09:47,639] 基本上就是蓝色和绿色的区别
[00:09:47,639 -> 00:09:51,240] 但是其他的就是你怎么样子去用reward function
[00:09:51,240 -> 00:09:52,440] 你怎么去用policy
[00:09:52,440 -> 00:09:55,720] 然后怎么样子去做reward model
[00:09:55,720 -> 00:09:58,480] 都是几乎是一样的方式
[00:09:58,480 -> 00:10:00,559] 就是其他的所有的点都是一样的
[00:10:00,559 -> 00:10:04,320] 只不过是他到底是用instruct去做align
[00:10:04,320 -> 00:10:05,759] 还是去用chat做align还是去用chart做align
[00:10:05,759 -> 00:10:08,000] 这就是未来其他很多模型
[00:10:08,000 -> 00:10:10,799] 就是openAI会出现很多模型的方法
[00:10:10,799 -> 00:10:12,600] 就是它不一定要用instruct或者chart
[00:10:12,600 -> 00:10:15,039] 它可以有别的方式去align模型
[00:10:15,039 -> 00:10:17,320] 然后去输出对应的效果
[00:10:17,320 -> 00:10:19,279] 来适配不同的任务种类
[00:10:19,279 -> 00:10:23,519] 最后一个就是我们把所有刚才说的东西给总结到一起
[00:10:23,519 -> 00:10:27,120] 我们在最底层会有一个pre-trained这个foundation model
[00:10:27,120 -> 00:10:30,159] 然后我们可以去funtune来change weight的话
[00:10:30,159 -> 00:10:32,879] 就是你拿到一个GPT你训练好了一个GPT
[00:10:32,879 -> 00:10:35,679] 然后你需要根据新的任务去funtune
[00:10:35,679 -> 00:10:38,639] 然后把整个GPT的foundation model都改了话
[00:10:38,639 -> 00:10:40,320] 那就是traditional ML的做法
[00:10:40,320 -> 00:10:42,080] 那不是我们现在的做法
[00:10:42,080 -> 00:10:43,840] 我们要在左边那条路径上画个X
[00:10:43,840 -> 00:10:47,799] 接下来我们是funtune to activate different weights
[00:10:47,799 -> 00:10:51,919] 其实我们就把这一层应该改成叫alignment
[00:10:51,919 -> 00:10:56,519] 因为GPT有了in-context learning的这样的一个涌现出来的能力
[00:10:56,519 -> 00:11:00,360] 导致我们可以通过alignment去activate不同的weight
[00:11:00,360 -> 00:11:03,320] 在这个之下我们再用不同的方式
[00:11:03,320 -> 00:11:06,519] 我们接下来会说就是我们现在所看到的
[00:11:06,519 -> 00:11:07,919] 不管是GPT Store也好
[00:11:07,919 -> 00:11:09,399] 还是这个agency也好
[00:11:09,399 -> 00:11:11,720] 都是在ChainGPT之下的一个方式
[00:11:11,720 -> 00:11:14,039] 我们回头再展开就好
[00:11:14,039 -> 00:11:15,720] 我打一个比方
[00:11:15,720 -> 00:11:16,919] 就是我们在了解了以后
[00:11:16,919 -> 00:11:18,200] 我们可以用一个比方再去理解
[00:11:18,200 -> 00:11:19,399] 我不喜欢用比方来开头
[00:11:19,399 -> 00:11:21,200] 因为那个时候会带来一些误解
[00:11:21,200 -> 00:11:24,399] 就是我们整个GPT的PrintTrend
[00:11:24,399 -> 00:11:26,000] 这个Base Foundation Model
[00:11:26,000 -> 00:11:29,080] 其实是钢铁侠的那个反应核心
[00:11:29,080 -> 00:11:30,879] 就是他那个Arc
[00:11:30,879 -> 00:11:33,000] 他中间这个反应核心有了以后
[00:11:33,000 -> 00:11:34,360] 你才有可能做出钢铁侠
[00:11:34,360 -> 00:11:37,159] 其实上面的一些武器人类都已经有了
[00:11:37,159 -> 00:11:38,480] 或者说Tony Stark
[00:11:38,480 -> 00:11:40,200] 就Stark Industry已经有了
[00:11:40,200 -> 00:11:41,639] 你没有中间的那个核心呢
[00:11:41,639 -> 00:11:43,360] 那就像下面这张图一样
[00:11:43,360 -> 00:11:45,120] 是那个什么Hemley Industries
[00:11:45,120 -> 00:11:47,279] 就是他试图做出来一堆
[00:11:47,279 -> 00:11:48,960] 长得像Ironman的东西
[00:11:48,960 -> 00:11:50,480] 可是他没有核心
[00:11:51,279 -> 00:11:52,320] 你有了核心以后
[00:11:52,320 -> 00:11:53,519] 你通过不同的Line问题
[00:11:53,519 -> 00:11:55,039] 能把它调教成不同的任务
[00:11:55,039 -> 00:11:57,039] 这里边我们看到钢铁侠3里边的
[00:11:57,039 -> 00:11:58,000] 不同的钢铁侠
[00:11:58,000 -> 00:11:59,360] 它可以适配不同的任务
[00:11:59,360 -> 00:12:01,600] 但是前提都是要有核心
[00:12:01,600 -> 00:12:03,759] 核心的质量是最重要的
[00:12:03,759 -> 00:12:08,360] 这个时候很多时候大家忽视的大家会用各种各样开源的模型去做出来一个
[00:12:08,840 -> 00:12:14,840] 看上去也不错的核心 但是其实它的核心的质量比钢铁侠差很远 其实就是钢铁侠2里边的
[00:12:15,679 -> 00:12:21,320] 那个鞭侠对吧 用鞭子的那个人 他也可以用 你可以把他理解成一个开源模型
[00:12:21,679 -> 00:12:24,159] 所以他也能做出来一个核心 然后他做的这个核心
[00:12:21,399 -> 00:12:23,000] 把它理解成一个太原模型它也能做出来一个核心
[00:12:23,000 -> 00:12:26,840] 然后它做的核心的效果也能似是而非
[00:12:26,840 -> 00:12:29,039] 但是它不是钢铁侠的核心
[00:12:29,039 -> 00:12:32,639] 它也不能像钢铁侠在接下来的漫威里边
[00:12:32,639 -> 00:12:35,200] 迭代出来那么多的tech
[00:12:35,200 -> 00:12:37,879] 因为它的核心是不够强的
[00:12:37,879 -> 00:12:40,039] 然后它的研发能力也是不够强的
[00:12:40,039 -> 00:12:42,120] 这个我在会员视频里边有讲过
[00:12:42,120 -> 00:12:46,100] 就是为什么OpenAI现在是站在一个指数增长的环节上
[00:12:46,100 -> 00:12:49,799] 这个LM的历史我就不多说了
[00:12:49,799 -> 00:12:52,100] 就是他到底是过去的发展
[00:12:52,100 -> 00:12:53,899] Transformers的他到底是什么
[00:12:53,899 -> 00:12:55,799] Transformers的这个发展
[00:12:55,799 -> 00:12:58,399] 我这之前都有兴趣的话
[00:12:58,399 -> 00:13:00,799] 其实应该去看俊林老师的那个文章
[00:13:00,799 -> 00:13:02,200] 就是我绝大多数的
[00:13:02,200 -> 00:13:05,500] 对这个知识是通过他的文章传起来的
[00:13:05,500 -> 00:13:08,000] 包括t5怎么样子把所有的task
[00:13:08,000 -> 00:13:09,500] line成generative task
[00:13:09,500 -> 00:13:11,500] 这是一个非常重要的点
[00:13:11,500 -> 00:13:14,500] 还有一些其他的quick takeover的东西
[00:13:14,500 -> 00:13:16,500] 比如说GPT是怎么开始的对吧
[00:13:16,500 -> 00:13:20,500] 然后这个就是GPT和Birds在
[00:13:20,500 -> 00:13:23,500] PKGPT完败的情况下
[00:13:23,500 -> 00:13:26,000] 大家是怎么样子去stick with GPT的
[00:13:26,000 -> 00:13:28,000] 然后ChunFuzi这边的作用
[00:13:28,000 -> 00:13:32,080] 和Gates在这里边扮演的关键角色
[00:13:32,080 -> 00:13:35,600] 就是在GPT3到3.5到拆GPT的时候
[00:13:35,600 -> 00:13:38,080] Bergeis在这里边其实扮演了非常重要的角色
[00:13:38,080 -> 00:13:39,279] 他在里边也有说
[00:13:39,279 -> 00:13:40,159] 我也不多说了
[00:13:41,600 -> 00:13:43,840] 接下来就进入我们的正式环节
[00:13:43,840 -> 00:13:45,039] 就是这五个问题
[00:13:45,039 -> 00:13:47,159] 第一个就是它是不是一个
[00:13:47,159 -> 00:13:48,759] 只是一个更好的代理模型
[00:13:48,759 -> 00:13:49,879] 这个其实是乐库的观点
[00:13:49,879 -> 00:13:51,679] 就是GPT其实没有什么不一样的
[00:13:51,679 -> 00:13:53,159] 它是一个更好的模型
[00:13:53,159 -> 00:13:54,200] 它没有凡事突破
[00:13:54,200 -> 00:13:56,159] 那我接下来要问的问题就是
[00:13:56,159 -> 00:13:58,440] 我们人类是不是只是一个更聪明的猴子
[00:13:58,840 -> 00:14:00,000] 答案肯定不是
[00:14:00,000 -> 00:14:02,320] 但我们就要抱着这个观点
[00:14:02,320 -> 00:14:05,360] 就是说你不能因为我们看不出来
[00:14:05,360 -> 00:14:07,080] 人类和猴子的大脑有什么不一样
[00:14:07,080 -> 00:14:09,159] 从而去否定人类和猴子不一样
[00:14:09,399 -> 00:14:12,360] Chai GPT似乎从原理上和其他大学模型不一样
[00:14:12,360 -> 00:14:15,919] 但是我们要接受Chai GPT有可能不一样的可能性
[00:14:16,279 -> 00:14:17,879] 过去的Models是什么
[00:14:17,879 -> 00:14:18,919] 就是我们要知道不一样的话
[00:14:18,919 -> 00:14:21,200] 我们就要知道过去的Models是什么
[00:14:21,200 -> 00:14:25,000] 过去的Models它其实就是Find Correspondence
[00:14:25,000 -> 00:14:28,000] 它是在数据里边寻找一些规律
[00:14:28,000 -> 00:14:31,000] 那你可以告诉它你这个规律寻找的对不对
[00:14:31,000 -> 00:14:34,000] 最简单的就是你给它一对X给它一对Y
[00:14:34,000 -> 00:14:35,000] 然后把X给map到Y
[00:14:35,000 -> 00:14:39,000] 那接下来它选好了这个X和Y之间的关系以后
[00:14:39,000 -> 00:14:42,000] 你再给它一对新的X和一对新的Y看看能不能map的好
[00:14:42,000 -> 00:14:45,000] 你可以在这里面有各种各样的方式
[00:14:45,000 -> 00:14:47,000] 设计各种各样的这个loss function
[00:14:47,000 -> 00:14:50,799] 去帮助他和你的机制去帮助他去
[00:14:50,799 -> 00:14:53,600] 把这个correspondence找的比较好
[00:14:53,600 -> 00:14:55,000] 找到你想要的correspondence
[00:14:55,000 -> 00:14:58,000] 而不要找那些over fitting或者说是under fitting的东西
[00:14:58,000 -> 00:15:03,100] 同时呢你再把他和其他的计算机的功能给结合起来
[00:15:03,100 -> 00:15:04,799] 你就可以让他做很多的事情
[00:15:04,799 -> 00:15:06,039] 这是过去的 machine learning
[00:15:06,480 -> 00:15:09,000] 但是 machine learning 它有一个问题
[00:15:09,000 -> 00:15:10,399] 就是它只会鹦鹉学舌
[00:15:10,399 -> 00:15:11,360] 它不能理解
[00:15:11,360 -> 00:15:13,440] 当然这两个词都非常的重
[00:15:13,440 -> 00:15:15,080] 所以说我们接下来就要去讲
[00:15:15,159 -> 00:15:16,559] 什么是理解
[00:15:16,559 -> 00:15:18,399] 在这里边有一个 window grade schema
[00:15:18,399 -> 00:15:21,600] 它非常好的去讲了这里边的理解
[00:15:21,879 -> 00:15:23,679] 我觉得最好的就是
[00:15:23,679 -> 00:15:27,799] 朱松成老师所说的乌鸦和鹦鹉的区别
[00:15:27,799 -> 00:15:30,399] 就是在一个城市里边呢
[00:15:30,399 -> 00:15:34,200] 乌鸦可以通过观察车观察人
[00:15:34,200 -> 00:15:38,000] 它想要达到一个打开一个坚果的这样的一个任务
[00:15:38,000 -> 00:15:42,000] 那它就发现车是可以在红绿灯前面停下来的
[00:15:42,000 -> 00:15:44,399] 车可以压碎它的坚果
[00:15:44,399 -> 00:15:46,200] 然后它就会把坚果drop到这个红绿灯前面停下来的车可以压碎他的坚果然后他就会把坚果
[00:15:46,200 -> 00:15:48,200] drop到红绿灯前面
[00:15:48,200 -> 00:15:49,799] 让车去把它压碎
[00:15:49,799 -> 00:15:50,799] 然后等到红灯的时候
[00:15:50,799 -> 00:15:52,799] 再去把坚果给pick up起来
[00:15:52,799 -> 00:15:55,200] 在这里边他只有一次任务
[00:15:55,200 -> 00:15:57,399] 就是他如果被车撞了就被撞死了
[00:15:57,399 -> 00:15:59,000] 所以说他所有这些东西
[00:15:59,000 -> 00:16:00,399] 都是通过他的inference
[00:16:00,399 -> 00:16:01,399] 都是通过他的理解
[00:16:01,399 -> 00:16:03,200] 都是通过他的comprehend
[00:16:03,200 -> 00:16:06,279] 然后他自己在脑子里边run了一个simulation
[00:16:06,279 -> 00:16:08,399] 然后发现他觉得这样可以他才去做的
[00:16:08,399 -> 00:16:12,240] 而不是通过试错来试出来的
[00:16:12,240 -> 00:16:14,440] 大家如果说是一个merchant learning scientist
[00:16:14,440 -> 00:16:16,720] 你就可以代入到merchant learning的工作方式
[00:16:16,720 -> 00:16:19,679] 你可以知道过去的merchant learning是不可能做这种东西的
[00:16:19,679 -> 00:16:21,559] 因为他没有办法得到这样的数据
[00:16:21,559 -> 00:16:24,600] 过去的merchant learning你只能通过1000个乌鸦
[00:16:24,600 -> 00:16:25,279] 1万个乌鸦1万个乌鸦
[00:16:25,279 -> 00:16:26,159] 100万个乌鸦
[00:16:26,159 -> 00:16:27,200] 反复的去
[00:16:27,480 -> 00:16:28,600] randomly尝试
[00:16:28,600 -> 00:16:29,399] 各种各样的pattern
[00:16:29,399 -> 00:16:30,159] 找到了以后
[00:16:30,159 -> 00:16:31,240] 然后再进化
[00:16:31,240 -> 00:16:32,159] 可是这样的代价
[00:16:32,159 -> 00:16:32,679] 就是必须要
[00:16:32,679 -> 00:16:34,200] 你要死这么多个乌鸦
[00:16:34,240 -> 00:16:35,679] 你是没有办法去
[00:16:36,080 -> 00:16:37,000] 在脑子里边
[00:16:37,000 -> 00:16:38,399] simulate出来不同的效果
[00:16:38,399 -> 00:16:39,159] 最后得到
[00:16:39,159 -> 00:16:40,679] 达成这个任务的
[00:16:40,679 -> 00:16:43,120] 就所谓的Deduce and Inference
[00:16:43,440 -> 00:16:45,879] 拆GPT是可以做到这件事情的
[00:16:45,879 -> 00:16:48,600] 而且他拆GPT就是这个
[00:16:48,600 -> 00:16:51,200] GPT3.5吧和GPT3和以前的
[00:16:51,200 -> 00:16:52,919] 我们训练的model有个很不一样的
[00:16:52,919 -> 00:16:54,279] 就是以前的大语言模型
[00:16:54,679 -> 00:16:56,759] 和很多哪怕现在的开源的大语言模型
[00:16:56,759 -> 00:16:57,440] 有很大的区别
[00:16:57,440 -> 00:16:59,639] 就是他可以做in context correction
[00:16:59,840 -> 00:17:01,840] 就是说你他跟你说了一个东西
[00:17:01,840 -> 00:17:03,240] 然后你跟他说你这说的不对
[00:17:03,240 -> 00:17:05,599] 他马上说我说的不对我来改
[00:17:05,599 -> 00:17:07,839] 这是一个非常强的推理能力
[00:17:07,839 -> 00:17:11,640] 这在这GPT3.5之前是没有一个模型
[00:17:11,640 -> 00:17:15,440] 哪怕GPT2和3都没有展现出来的能力
[00:17:15,440 -> 00:17:16,680] 展现出来了这个以后
[00:17:16,680 -> 00:17:19,440] 我们觉得GPT确实和过去是不一样的
[00:17:19,440 -> 00:17:23,240] 他有了一个真正的理解的能力在
[00:17:24,319 -> 00:17:28,680] 那接下来就遇到了就是去年我在出这个的时候的一个巨大的debate
[00:17:28,680 -> 00:17:31,319] 当然是乐坤为首和一大堆数据科学家
[00:17:31,319 -> 00:17:36,000] 一大堆这个machinery scientist都持这一派观点
[00:17:36,000 -> 00:17:38,480] 现在大家听到的这个争论越来越少了
[00:17:38,480 -> 00:17:39,920] 乐坤似乎也不这么想了
[00:17:39,920 -> 00:17:42,680] 但是是不是大家真的被说服了呢
[00:17:42,680 -> 00:17:46,119] 就是我们回来就去想GGBT是不是真的有意识
[00:17:46,480 -> 00:17:47,799] 这又是一个很重要的问题
[00:17:48,000 -> 00:17:49,400] 如果GBT能理解的话
[00:17:49,599 -> 00:17:50,640] GBT具备意识吗
[00:17:50,759 -> 00:17:53,599] 如果GBT能理解的话又具备意识
[00:17:53,839 -> 00:17:55,920] 它的模型我们又知道
[00:17:56,400 -> 00:17:57,559] 你在这样的一个
[00:17:57,559 -> 00:18:00,119] Auto Regressive Generative
[00:18:00,119 -> 00:18:02,240] Latent Language Models的范式之下
[00:18:02,240 -> 00:18:03,920] 能不能培养出来一个意识呢
[00:18:04,440 -> 00:18:07,279] 这就回到了一个哲学问题就是意识到底是什么
[00:18:07,279 -> 00:18:09,039] 其实我们不知道意识是什么
[00:18:09,039 -> 00:18:12,359] 这个是哲学的哲学给我们的启示
[00:18:12,359 -> 00:18:16,759] 哲学是说我们并不知道人类到底是否有意识
[00:18:16,759 -> 00:18:19,519] 然后我这里边有链接
[00:18:19,519 -> 00:18:22,839] 就是20世纪最重要的几个科学问题
[00:18:22,839 -> 00:18:24,039] 就是意识到底是什么
[00:18:24,039 -> 00:18:25,519] 人类到底是不是真的有意识
[00:18:25,519 -> 00:18:28,160] 但是在Cognitive Science里边
[00:18:28,480 -> 00:18:30,400] 我们就会发现了一个观点
[00:18:30,880 -> 00:18:34,880] 人其实和猴子和其他动物
[00:18:34,880 -> 00:18:35,920] Biological类
[00:18:36,119 -> 00:18:39,119] 其实不是特别的不一样
[00:18:39,119 -> 00:18:40,160] 就是说我们
[00:18:40,519 -> 00:18:42,799] 你如果光看我们和猴子的大脑的区别
[00:18:42,799 -> 00:18:43,440] 你不会觉得
[00:18:43,440 -> 00:18:44,440] 你不会得出一个结论
[00:18:44,440 -> 00:18:46,599] 说人类就是和猴子完全不一样的东西
[00:18:46,599 -> 00:18:50,000] 那这样看起来我们的意识其实是
[00:18:50,000 -> 00:18:50,880] emerged的
[00:18:50,880 -> 00:18:53,079] 这个是一个cognitive science的观点
[00:18:53,079 -> 00:18:54,920] 这个词大家就很熟悉了
[00:18:54,920 -> 00:18:58,799] 就是GPT虽然它的结构和其他的
[00:18:58,799 -> 00:19:00,160] Machine Learning没有那么不一样
[00:19:00,160 -> 00:19:01,920] 或者其他大语言模型那么不一样
[00:19:01,920 -> 00:19:04,519] 但是它似乎emerged出来了一些不一样的东西
[00:19:04,519 -> 00:19:07,880] 我们现在不要去深究就是为什么GPT不一样我们也不要去深究言模型那么不一样但是它似乎emerge出来了一些不一样的东西我们现在不要去深究为什么GPT不一样
[00:19:07,880 -> 00:19:09,599] 我们也不要去深究人类为什么不一样
[00:19:09,599 -> 00:19:13,000] 我们只要去关注它有可能是不一样的就好了
[00:19:13,000 -> 00:19:18,599] 第二个就是我们说GPT和以前是一个完全不一样的范式更新
[00:19:18,599 -> 00:19:21,559] GPT到底是一个什么样的东西
[00:19:21,759 -> 00:19:26,000] 这个其实我在我的视频里面总结Gates和Ultimate的说法
[00:19:26,000 -> 00:19:28,299] 就是GUI加Morris law for everything
[00:19:29,200 -> 00:19:30,480] 第一个就是它是一个
[00:19:30,480 -> 00:19:32,680] near perfect abstraction of
[00:19:32,880 -> 00:19:34,539] internet technologies
[00:19:34,539 -> 00:19:36,579] 就是我们其实在过往的
[00:19:36,940 -> 00:19:38,240] 呃这个计算机呢
[00:19:38,240 -> 00:19:40,980] 就是我们是在算力和storage和存储上
[00:19:40,980 -> 00:19:42,279] 进行了很多的
[00:19:42,740 -> 00:19:43,740] 颠覆和
[00:19:44,279 -> 00:19:45,319] advancement我们在数据的generation和利用上进行了很多的颠覆和advancement
[00:19:45,319 -> 00:19:48,200] 我们在数据的generation和利用上
[00:19:48,200 -> 00:19:49,400] 进行了很多进步
[00:19:49,400 -> 00:19:52,599] 然后我们是把这两个事给结合的很好
[00:19:52,599 -> 00:19:56,000] 那其实GUI它就解决了很多
[00:19:56,000 -> 00:19:58,119] specific purpose的东西
[00:19:58,119 -> 00:20:00,319] 比如说我现在在看的这些东西
[00:20:00,319 -> 00:20:01,920] 都是跟GUI相关的
[00:20:01,920 -> 00:20:03,119] 我去刷抖音
[00:20:03,119 -> 00:20:06,200] 抖音是一个GUI去解决我的
[00:20:06,200 -> 00:20:08,000] 就是产生视频
[00:20:08,000 -> 00:20:09,599] 然后产生我的喜好
[00:20:09,599 -> 00:20:12,000] 把该我喜欢的视频推送到我面前
[00:20:12,000 -> 00:20:13,500] 然后高效率的去刷
[00:20:13,500 -> 00:20:15,799] 它都被GUI解决的很好
[00:20:15,799 -> 00:20:16,900] 但是拆GPT呢
[00:20:16,900 -> 00:20:19,200] 它可以解决一个general purpose的东西
[00:20:19,200 -> 00:20:21,700] 就是说我之前我抖音想的很好
[00:20:21,700 -> 00:20:22,700] 但是我跟他说
[00:20:22,700 -> 00:20:25,000] 我想用抖音的这个能力去干一些别的事情
[00:20:25,200 -> 00:20:26,640] 那我就需要去编程
[00:20:26,640 -> 00:20:29,160] 但是这个编程的门槛是非常非常之高的
[00:20:29,359 -> 00:20:31,440] 现在Chai GPT呢是可以让我
[00:20:31,680 -> 00:20:34,519] 去用自然语言去调动一个编程
[00:20:34,799 -> 00:20:36,359] 这就是我左上角的这个例子
[00:20:36,359 -> 00:20:38,480] 就是你来做一个Linux terminal
[00:20:38,599 -> 00:20:40,119] 之后我们可能就跟Chai GPT说
[00:20:40,119 -> 00:20:41,279] 我要做一个什么的
[00:20:41,359 -> 00:20:44,440] GPT就可以帮助你调用算力存储数据
[00:20:44,720 -> 00:20:46,400] 来去实现你的目的
[00:20:46,400 -> 00:20:49,799] 我有另外一个比喻就是GUI是山
[00:20:49,799 -> 00:20:51,599] 然后GPT是水
[00:20:51,599 -> 00:20:54,599] 水涨船高迟早会淹没很多山的
[00:20:54,599 -> 00:20:59,500] 那我们接下来就是说就是intellectual
[00:20:59,500 -> 00:21:04,700] 就是就是我们智能智能的分发过去是非常非常之贵的
[00:21:04,700 -> 00:21:07,400] 因为智能是通过人
[00:21:07,400 -> 00:21:09,440] 然后人能面对的人是有限的
[00:21:09,440 -> 00:21:11,720] 可是我们接下来就可以进行智能的分发
[00:21:11,720 -> 00:21:13,839] 把智能分发的编制成本降为0
[00:21:13,839 -> 00:21:16,319] 那一个医生我就在过去也说了
[00:21:16,319 -> 00:21:18,160] 就是医生律师等等的这些人
[00:21:18,160 -> 00:21:20,559] 他可以同时服务无限度的人
[00:21:20,559 -> 00:21:23,000] 而不只需要服务他面前的用户
[00:21:23,000 -> 00:21:25,480] 我希望在一两年之后
[00:21:25,680 -> 00:21:28,599] 我的GPT是可以做一个非常非常好的
[00:21:28,720 -> 00:21:30,599] 数据分析师或者数据科学家的
[00:21:30,759 -> 00:21:31,880] 这就是刚刚说的
[00:21:31,880 -> 00:21:33,559] 就是你做出来一个Everman之后
[00:21:33,559 -> 00:21:35,519] 你给他再加一个差不多的大脑
[00:21:35,680 -> 00:21:37,839] 那他其实自动的就可以去
[00:21:38,079 -> 00:21:39,240] 做很多很多的任务
[00:21:39,240 -> 00:21:40,480] 这个就是那个
[00:21:40,640 -> 00:21:41,400] outrun对吧
[00:21:41,400 -> 00:21:43,839] 但是这是一个好版的outrun
[00:21:43,839 -> 00:21:46,720] 就是就是曾经如果说是完美的情况下
[00:21:46,720 -> 00:21:48,720] 奥创所能干的是什么事情
[00:21:48,720 -> 00:21:49,920] 就是这样的一个事情
[00:21:49,920 -> 00:21:51,920] 就是一下子出现了
[00:21:51,920 -> 00:21:54,559] Unlimited Element
[00:21:54,559 -> 00:21:57,359] Element自己一个人能干的事情是有限的
[00:21:57,359 -> 00:21:59,359] 我相信有了奥创大军以后
[00:21:59,359 -> 00:22:01,359] Thanos是不可能打过他们的
[00:22:01,359 -> 00:22:03,680] 就像在飞猴女巫的宇宙里
[00:22:03,680 -> 00:22:05,400] 就是有光明会的那个宇宙一样
[00:22:05,400 -> 00:22:06,960] 那接下来就是如何
[00:22:07,400 -> 00:22:09,400] 这个它有多难制造
[00:22:09,599 -> 00:22:11,720] 这个我就简单的跳过吧
[00:22:11,720 -> 00:22:13,640] 因为其实我已经说过很多遍了
[00:22:14,000 -> 00:22:16,240] 第四个就是我们应该怎么去使用它
[00:22:16,519 -> 00:22:18,119] 其实就是说你在
[00:22:18,559 -> 00:22:19,519] 浏览器刚出来的时候
[00:22:19,519 -> 00:22:20,680] 不要去再造一个浏览器
[00:22:20,680 -> 00:22:22,559] 而是应该去做网页
[00:22:22,839 -> 00:22:24,119] 这是回到刚才的那个文章
[00:22:24,119 -> 00:22:25,440] 我把最下面打开
[00:22:25,440 -> 00:22:28,359] 其实我们就是一年前看的
[00:22:28,359 -> 00:22:31,759] 今这一年的所有的变化和这个几乎是
[00:22:31,759 -> 00:22:33,119] 完全走在剧本上
[00:22:33,119 -> 00:22:34,920] 就是没有什么超出意想的东西
[00:22:34,920 -> 00:22:35,319] 为什么呢
[00:22:35,319 -> 00:22:37,160] 因为当时new bing和microsoft
[00:22:37,160 -> 00:22:39,519] copilot其实已经把这个路线
[00:22:39,519 -> 00:22:40,799] 探索的很好了
[00:22:40,799 -> 00:22:42,519] 就是你能access to tools
[00:22:42,519 -> 00:22:44,960] 然后这个prompt as a configuration
[00:22:45,359 -> 00:22:46,960] 你在开放这一层就是你能access to tools然后这个prompt as a configuration呃你在开放这一层
[00:22:47,160 -> 00:22:48,279] 就是你开放
[00:22:48,640 -> 00:22:50,559] chai gpt可以去调用别的东西
[00:22:50,559 -> 00:22:52,519] 你可以写代码你可以去改变系统
[00:22:52,839 -> 00:22:54,759] 然后你在开放给一些
[00:22:55,039 -> 00:22:56,839] 指定的指令给chai gpt
[00:22:56,839 -> 00:22:58,000] 那他就能干很多事
[00:22:58,000 -> 00:22:59,920] 那再往上呢是开放你的这个
[00:22:59,920 -> 00:23:01,200] element这个接口
[00:23:02,119 -> 00:23:04,079] 这我就不再多说了
[00:23:04,079 -> 00:23:05,279] 这个我们就直接看呃这一年的发布就好了不再多说了这个我们就直接看
[00:23:05,279 -> 00:23:07,279] 这一年的发布就好了
[00:23:07,279 -> 00:23:10,319] 相信都已经说了很就是这一年的发布
[00:23:10,319 -> 00:23:14,559] 非常好的验证了我一年前的这些预测
[00:23:14,559 -> 00:23:15,599] 这里有一个问题了
[00:23:15,599 -> 00:23:20,000] 就是我们如果说调用Tri-GPT的能力很重要的话
[00:23:20,000 -> 00:23:21,920] 其实有一个问题就是你的prompt
[00:23:21,920 -> 00:23:25,079] 你要去让Tri-GPT完成各种各样的任务
[00:23:25,079 -> 00:23:29,119] 那到底是一个工程技巧还是一个PM技巧
[00:23:29,119 -> 00:23:31,799] 就是你是要教给Chai GPT怎么用呢
[00:23:31,799 -> 00:23:34,599] 还是你是要告诉Chai GPT做什么
[00:23:34,599 -> 00:23:38,400] 我的想法是在一开始你一定要有很强的工程能力
[00:23:38,400 -> 00:23:40,039] 去告诉Chai GPT怎么用
[00:23:40,039 -> 00:23:44,680] 然后在未来越来越重要的是告诉Chai GPT做什么
[00:23:49,119 -> 00:23:50,720] 我其实在这一年用ChaiGBT做了很多尤其是我的数据分析
[00:23:50,720 -> 00:23:55,559] 我发现就是像我的一个实习生一样去使用ChaiGBT
[00:23:55,559 -> 00:23:56,960] 你先提出问题
[00:23:56,960 -> 00:23:58,759] 然后跟他一起去来按思路
[00:23:58,759 -> 00:23:59,880] 然后看他的思路对不对
[00:23:59,880 -> 00:24:01,799] 如果他的思路和你的思路差不多的时候
[00:24:01,799 -> 00:24:03,079] 跟他说你现在去做
[00:24:03,079 -> 00:24:05,599] 做完了以后再跟他不断的反馈提高
[00:24:05,599 -> 00:24:08,160] 这里边有非常多的要告诉他GPT做什么
[00:24:08,160 -> 00:24:09,599] 他才能把这个东西做好
[00:24:09,599 -> 00:24:12,640] 那之后我相信随着我的调教变多的话
[00:24:12,640 -> 00:24:15,559] 如果说我已经把他非常好的调教了
[00:24:15,559 -> 00:24:17,200] 告诉他如何做了
[00:24:17,200 -> 00:24:19,680] 那我之后再告诉他你要去做什么就行了
[00:24:20,160 -> 00:24:22,000] 所以说总结一下的话
[00:24:22,000 -> 00:24:23,960] 就是一开始是有很多
[00:24:23,960 -> 00:24:26,359] 你要告诉这个大�学模型怎么做
[00:24:26,359 -> 00:24:28,440] 在未来更多的是告诉他做什么
[00:24:28,440 -> 00:24:31,000] 再说一些过往的历史吧
[00:24:31,000 -> 00:24:33,799] 就是XGBT这件事不是一个真的prediction
[00:24:33,799 -> 00:24:37,400] 它只不过是历史很多颠覆科技的重复
[00:24:37,400 -> 00:24:41,960] 这个颠覆科技的重复就是当你电脑出现的时候
[00:24:41,960 -> 00:24:43,599] 当互联网出现的时候
[00:24:43,599 -> 00:24:45,440] 当移动互联网出现的时候
[00:24:45,640 -> 00:24:48,279] 其实第一波都是把现有的东西
[00:24:48,279 -> 00:24:49,559] 放到新的科技上
[00:24:49,559 -> 00:24:50,480] 这个是Selecon Valley
[00:24:50,480 -> 00:24:51,880] 那个把radio on internet
[00:24:51,880 -> 00:24:53,559] 那个变成billionaire的
[00:24:53,559 -> 00:24:55,000] 那个asshole对吧
[00:24:55,000 -> 00:24:57,039] 呃就是他只不过把现有的东西
[00:24:57,039 -> 00:24:57,720] 放到了互联网
[00:24:57,720 -> 00:24:59,400] 然后就得到了巨大的财富
[00:24:59,519 -> 00:25:00,759] 但是在那之后
[00:25:00,759 -> 00:25:03,160] 最重要的就是10倍百倍的机会
[00:25:03,200 -> 00:25:07,319] 一定是新的科技做了过去科技所做不到的事情的
[00:25:07,319 -> 00:25:10,799] 就比如说Google在一开始的互联网上是没有用的
[00:25:10,799 -> 00:25:13,039] 因为那个时候互联网上都没有什么信息
[00:25:13,039 -> 00:25:16,759] 但是Google它作为一个internet的fundamental的科技
[00:25:16,759 -> 00:25:18,759] 它是随着互联网增加的
[00:25:18,759 -> 00:25:22,400] 就是你互联网的信息指数增加了以后
[00:25:22,400 -> 00:25:25,039] Google的有用程度也变得指数重要了
[00:25:25,039 -> 00:25:28,200] 所以说一开始我们会看到很多
[00:25:28,200 -> 00:25:30,440] 把现有的东西用代语模型去实现
[00:25:30,440 -> 00:25:32,480] 但是未来一定是代语模型去实现
[00:25:32,480 -> 00:25:34,359] 现在完全实现不了的东西
[00:25:34,359 -> 00:25:36,359] 然后这里边最重要的东西
[00:25:36,359 -> 00:25:38,799] 就是start with build simple things
[00:25:38,799 -> 00:25:40,079] that people really want
[00:25:40,079 -> 00:25:42,039] Instagram其实之前就是一个future app
[00:25:42,039 -> 00:25:43,920] 它不是一个social media或者怎么样
[00:25:43,920 -> 00:25:46,079] 现在的这些东西都是他做了一个
[00:25:46,079 -> 00:25:48,400] 人们真正需要的东西之后才出来的
[00:25:48,640 -> 00:25:50,599] 你没有人们需要的那个东西的话
[00:25:50,599 -> 00:25:51,400] 其他都是白谈
[00:25:51,400 -> 00:25:52,799] 你说那么多概念也没有用的
[00:25:53,000 -> 00:25:54,480] 然后这就是我的一下opinion了
[00:25:54,480 -> 00:25:56,480] 就是他到底是一个2b2c的机会
[00:25:56,759 -> 00:25:58,039] 它是Scannet吗
[00:25:58,039 -> 00:25:58,759] 我觉得不是
[00:25:58,759 -> 00:26:00,079] 但是它有可能是可以
[00:26:00,319 -> 00:26:00,720] crack
[00:26:00,720 -> 00:26:03,000] encryption的
[00:26:03,000 -> 00:26:07,000] GPG native application application到底是什么东西
[00:26:07,000 -> 00:26:11,000] 然后这里边这个personalized private search有多么的重要
[00:26:11,000 -> 00:26:14,000] 就是现在我们所说的retrieved
[00:26:14,000 -> 00:26:16,000] argumented generation
[00:26:16,000 -> 00:26:17,000] 对吧 RAG
[00:26:17,000 -> 00:26:20,000] 其实personalized private search
[00:26:20,000 -> 00:26:22,000] 就是这个retrieved这个环节非常重要的
[00:26:22,000 -> 00:26:24,000] 其实到现在这GPT都没有做得很好
[00:26:24,000 -> 00:26:26,119] 它也是一个未来非常重要的方向
[00:26:26,119 -> 00:26:29,480] 那个big tech在这里边的会benefit什么
[00:26:29,480 -> 00:26:30,079] 其实是的
[00:26:30,079 -> 00:26:31,599] 因为他们已经有了现有的场景
[00:26:31,599 -> 00:26:33,839] 他们其实可以把拆GPT在一开始用的很好
[00:26:34,119 -> 00:26:37,680] 最后一个问题就是人类和拆GPT的区别是什么
[00:26:37,680 -> 00:26:40,960] 就是拆GPT其实这个是乐坤去讲的一个
[00:26:40,960 -> 00:26:42,640] 我觉得他这点反而讲的很对
[00:26:42,640 -> 00:26:45,839] 就是拆GPT他其实可以知道很多东西
[00:26:45,839 -> 00:26:48,200] 但是问题他不知道什么东西是对的
[00:26:48,200 -> 00:26:50,599] 所以说需要人去告诉他什么东西是对的
[00:26:50,599 -> 00:26:52,960] 而且这个时候其实没有一个绝对的正确
[00:26:52,960 -> 00:26:55,319] 而只不过是什么东西对我更有用而已
[00:26:55,319 -> 00:26:58,359] 所以说他一直需要人去告诉他什么东西对我更有用
[00:26:59,559 -> 00:27:03,559] 那就是人类在这里边是需要知道什么东西真正有用的
[00:27:03,799 -> 00:27:07,039] 然后去知道这个世界上缺的是什么
[00:27:07,400 -> 00:27:08,720] 有一词叫做Eureka
[00:27:08,720 -> 00:27:11,319] 就是阿基米德发明福利定律的那件
[00:27:11,319 -> 00:27:13,200] 或者发现福利定律的事情
[00:27:13,400 -> 00:27:15,480] 其实Eureka就是人类独特的能力
[00:27:15,480 -> 00:27:17,759] 然后这里边大家仔细去想一下Eureka的话
[00:27:17,759 -> 00:27:19,519] 会发现有两个步骤
[00:27:19,519 -> 00:27:22,160] 第一个就是你要能找到答案
[00:27:22,519 -> 00:27:26,440] 但是第二个是你要发现答案是重要的
[00:27:26,799 -> 00:27:28,400] 猜猜比提拉很有可能
[00:27:28,400 -> 00:27:31,240] 他通过自己的特别强大的算力
[00:27:31,240 -> 00:27:32,319] 他能找到答案
[00:27:32,319 -> 00:27:34,839] 问题是他只不过是他找到的
[00:27:34,839 -> 00:27:36,599] 所有答案中的其中一个
[00:27:36,960 -> 00:27:39,640] 你要能知道这个答案是多么重要的话
[00:27:39,640 -> 00:27:43,519] 那还是需要人的这种直觉去知道
[00:27:43,960 -> 00:27:45,599] 我在这1000个答案里边
[00:27:45,599 -> 00:27:47,000] 这个答案是真正重要的
[00:27:47,000 -> 00:27:47,799] 那个答案
[00:27:47,799 -> 00:27:49,200] 我们回到乔布斯
[00:27:49,200 -> 00:27:51,920] 其实乔布斯说的这些东西就是这些crazy ones
[00:27:51,920 -> 00:27:53,440] 他们就是知道这个答案
[00:27:53,440 -> 00:27:56,200] 并且能把这个答案通过自己的conviction
[00:27:56,200 -> 00:27:58,799] 然后去通过自己的行动去把它实现出来
[00:27:58,799 -> 00:28:00,799] 他们是真正change the world
[00:28:00,799 -> 00:28:03,559] 所以说你如果只是停留在一些表面的思考的话
[00:28:03,559 -> 00:28:05,279] 那确实可以被拆式背景取代的
[00:28:05,279 -> 00:28:07,039] 然后这就是最后一个点了
[00:28:07,039 -> 00:28:09,920] 其实just make something people want
[00:28:09,920 -> 00:28:11,599] 是这里边所有的答案
[00:28:11,599 -> 00:28:15,920] 你在代语言模型中的代语言时代怎么样子去抓住机会
[00:28:15,920 -> 00:28:17,759] just make something people want
[00:28:17,759 -> 00:28:22,960] 好的 这是一些appendix去讲
[00:28:22,960 -> 00:28:26,000] 这里边就是
[00:28:26,000 -> 00:28:28,000] 技术的演进到底是什么样子的
[00:28:28,000 -> 00:28:30,000] 这就是我给大家画的一些东西
[00:28:30,000 -> 00:28:32,000] 不在这里面讲了 如果大家感兴趣的话可以去看
[00:28:32,000 -> 00:28:34,000] 好的
[00:28:34,000 -> 00:28:36,000] 这里就是我们
[00:28:36,000 -> 00:28:38,000] Vision Pro的
[00:28:38,000 -> 00:28:40,000] 一个
[00:28:40,000 -> 00:28:42,000] 看看刚才东西有没有录上
[00:28:46,839 -> 00:28:49,240] 希望大家喜欢
[00:28:49,240 -> 00:28:51,839] 或者说觉得这是一个有用的东西
[00:28:51,839 -> 00:28:53,319] 我的视频到那边去了
[00:28:53,599 -> 00:28:54,880] 那就先这样吧
[00:28:56,640 -> 00:28:58,319] 好了 我们下次见
[00:28:58,319 -> 00:28:59,000] 拜拜
