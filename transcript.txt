[00:00:00,000 -> 00:00:04,000] 我覺得我們聊得有點散
[00:00:04,000 -> 00:00:06,000] 我們再把它抓回來吧
[00:00:06,000 -> 00:00:08,000] 我們給大家提供一個主線
[00:00:08,000 -> 00:00:12,000] 主線是這樣子的
[00:00:12,000 -> 00:00:15,000] 我們深入學習人工智能
[00:00:15,000 -> 00:00:17,000] 機器學習
[00:00:17,000 -> 00:00:25,000] 人工智能是存在很久很久的一個話題
[00:00:00,000 -> 00:00:04,799] 那機器學習可能七八十年代到現在發展起來也已經有很多了
[00:00:04,799 -> 00:00:09,800] 但是生動學習在11年發展起來到現在也已經發展了蠻久的時間
[00:00:09,800 -> 00:00:14,800] 而且這個所有的互聯網大廠巨量的資金人力和數據投入到裡面
[00:00:14,800 -> 00:00:20,600] 但是我們發現就是人工智能和我們想像的差的還有點遠
[00:00:20,600 -> 00:00:26,000] 就比如說這個從Siri包括你剛剛說的微軟的這個語音識別
[00:00:00,000 -> 00:00:03,640] 到現在已經發展了很久了
[00:00:03,640 -> 00:00:06,599] 但是我們看到我們身邊的語音智能助手
[00:00:06,599 -> 00:00:08,599] 智能語音助手
[00:00:08,599 -> 00:00:10,880] 基本上只能完成一些簡單的任務
[00:00:10,880 -> 00:00:12,199] 他沒有辦法完成對話
[00:00:12,199 -> 00:00:14,199] 就是你跟他對話你知道
[00:00:14,199 -> 00:00:15,480] 它是一個語音識別軟件
[00:00:15,480 -> 00:00:16,640] 他可能識別得很準
[00:00:16,640 -> 00:00:18,640] 但是他並沒有一個智能的感覺
[00:00:18,640 -> 00:00:20,079] 他不管怎麼樣
[00:00:20,079 -> 00:00:23,120] 就是你能感覺到他沒有自己的想法
[00:00:23,120 -> 00:00:26,839] 也沒有一個智能的樣子
[00:00:26,839 -> 00:00:29,719] 那我這關心的問題就是
[00:00:00,000 -> 00:00:04,040] 就是大廠人工智能在大廠的應用是什麼
[00:00:04,040 -> 00:00:08,519] 和這些應用它現在是一個起飛的前夜
[00:00:08,519 -> 00:00:10,320] 還只是一個剛剛開始
[00:00:10,320 -> 00:00:15,279] 還是已經是到了一個平靜期
[00:00:15,279 -> 00:00:18,519] 或者說是如果沒有一個基礎科學的突破
[00:00:18,519 -> 00:00:21,280] 它的應用的上限也差不多就到這裡了
[00:00:21,280 -> 00:00:23,000] 對 我覺得這都是很好的問題
[00:00:23,000 -> 00:00:24,160] 我想一想
[00:00:24,160 -> 00:00:25,480] 可以先兩個一塊
[00:00:25,480 -> 00:00:28,000] 就是我們先跟我們介紹一下
[00:00:00,000 -> 00:00:03,080] 比如说在你工作的接触的大厂
[00:00:03,080 -> 00:00:05,280] 人工智能大厂的应用都有什么样的问题
[00:00:06,280 -> 00:00:09,560] 对 我觉得可以这样简单的分类
[00:00:09,560 -> 00:00:12,519] 就是人工智能或者机器学习的应用
[00:00:12,519 -> 00:00:13,720] 特别工业界的应用
[00:00:14,439 -> 00:00:17,399] 你可以大概分成一些经典的
[00:00:17,399 -> 00:00:19,600] 一些比较well defined的一些问题
[00:00:19,600 -> 00:00:21,640] 比如说语音识别
[00:00:22,320 -> 00:00:24,480] 比如说图像识别 是吧
[00:00:24,480 -> 00:00:27,480] 然后比如说广告里面的那些经典的应用
[00:00:27,480 -> 00:00:28,519] 比如推荐引擎
[00:00:00,000 -> 00:00:02,399] 推荐引擎像抖音做的这么好
[00:00:02,399 -> 00:00:03,240] TikTok做这么好
[00:00:03,240 -> 00:00:05,000] 就是它推荐引擎做的很好
[00:00:05,000 -> 00:00:06,160] 然后或者像
[00:00:06,599 -> 00:00:08,000] 呃广告里面的搜索
[00:00:08,000 -> 00:00:09,839] 搜索广告里面的那个推荐
[00:00:09,839 -> 00:00:10,960] 或者点击率预测
[00:00:10,960 -> 00:00:12,800] 这都是很核心的一些应用
[00:00:13,240 -> 00:00:15,000] 这些是相对于比较经典的一些应用
[00:00:15,000 -> 00:00:16,440] 然后还有一大类应用
[00:00:16,440 -> 00:00:17,199] 我觉得
[00:00:17,960 -> 00:00:19,039] 呃就是
[00:00:19,559 -> 00:00:21,839] 你需要去了解那个business
[00:00:22,199 -> 00:00:24,839] 呃然后你去把它给用一个
[00:00:25,480 -> 00:00:28,440] 人工智能或者现有的机器学习的框架
[00:00:00,000 -> 00:00:04,040] 能够解决能够solvable能够doable的一个问题
[00:00:04,040 -> 00:00:06,320] 然后你再去要不你去apply
[00:00:06,320 -> 00:00:08,919] 或者你去做一些创新方法上面的创新
[00:00:08,919 -> 00:00:10,039] 解决这个问题
[00:00:10,919 -> 00:00:12,839] 我觉得你如果把这样分的话
[00:00:12,839 -> 00:00:15,679] 第一个那些比较well defined好的
[00:00:15,679 -> 00:00:17,719] 我觉得它可能遇到了一些
[00:00:18,079 -> 00:00:19,879] 一些相对来说一些瓶颈
[00:00:20,440 -> 00:00:22,120] 因为其实大家做了很久了
[00:00:22,120 -> 00:00:24,679] 已经然后深度学习这个该挖的
[00:00:25,039 -> 00:00:26,519] 可能已经挖的差不多了
[00:00:00,000 -> 00:00:03,680] 然后你的数据量也不可能再大很多了
[00:00:03,680 -> 00:00:04,200] 对
[00:00:04,200 -> 00:00:06,400] 嗯行
[00:00:06,400 -> 00:00:08,519] 我回头再重新你先说完吧
[00:00:08,519 -> 00:00:09,839] 回头想再讨论一下
[00:00:09,839 -> 00:00:11,839] 然后另外那一类呢
[00:00:11,839 -> 00:00:14,000] 就是你需要去了解那个business
[00:00:14,000 -> 00:00:19,359] 然后去把它给用机器学习或者AI的一些语言把它给描述出来
[00:00:19,359 -> 00:00:21,239] 然后是然后进而把它解决出来
[00:00:21,239 -> 00:00:24,120] 我觉得这一块它的潜力还很大很大
[00:00:24,120 -> 00:00:26,160] 这一块这一块才刚刚开始
[00:00:26,160 -> 00:00:26,440] 对
[00:00:26,440 -> 00:00:28,079] 好
[00:00:00,000 -> 00:00:03,680] 那我的問題其實是這個吧
[00:00:03,680 -> 00:00:07,320] 就是你說的第一個是已經Wild define的問題
[00:00:07,320 -> 00:00:10,160] 其實就是一個提高模型精度的問題
[00:00:10,160 -> 00:00:10,759] 對
[00:00:10,759 -> 00:00:13,759] 然後你說現在模型精度已經很高了
[00:00:13,759 -> 00:00:16,280] 它再往上往前走的機會不大
[00:00:16,280 -> 00:00:18,800] 比如說已經達到99.8%的準確率了
[00:00:18,800 -> 00:00:19,280] 對
[00:00:19,280 -> 00:00:23,160] 這個也是看它有沒有動機去做這個事情
[00:00:23,160 -> 00:00:26,399] 比如說像你說的大廠的那個
[00:00:00,000 -> 00:00:03,640] 比如說Siri或者Alexa或者微軟的那個語音助手
[00:00:04,160 -> 00:00:07,719] 它其實沒有太大的動機去把它再提高到很多
[00:00:07,719 -> 00:00:10,359] 比如現在它可能能夠說三回合以內的對話是吧
[00:00:10,720 -> 00:00:12,400] 超過三回合以上就不行了
[00:00:13,039 -> 00:00:16,039] 你把它說到了五回合或七回合又怎麼樣呢
[00:00:16,039 -> 00:00:17,879] 它好像比如亞馬遜並不關心這個
[00:00:17,879 -> 00:00:20,559] 它覺得好像並不能給它帶來多大的經濟收益
[00:00:21,600 -> 00:00:25,120] 你確定就是因為在我看來就是未必是三回合
[00:00:25,120 -> 00:00:28,399] 就是我覺得現在很多語音助手只停留在一回合
[00:00:00,000 -> 00:00:02,240] 並達不到兩回合
[00:00:02,240 -> 00:00:05,679] 對,他不是說所有的case都能達到三回合
[00:00:05,679 -> 00:00:07,200] 對,他不是
[00:00:07,200 -> 00:00:11,199] 就是照著稍稍加上一下我自己的理解
[00:00:11,199 -> 00:00:14,960] 我自己的理解是所有的兩回合以上的東西
[00:00:14,960 -> 00:00:18,800] 都是用這個都是針對場景單獨設計出來的
[00:00:18,800 -> 00:00:22,239] 它並不是因為你的模型理解了人的對話
[00:00:22,239 -> 00:00:25,199] 它自然而然的能進行下一回合的對話
[00:00:25,199 -> 00:00:28,160] 它並不是基於就像
[00:00:00,000 -> 00:00:02,359] 如果說你要分的話
[00:00:02,359 -> 00:00:05,519] 在我看來這不是一個無監督的問題
[00:00:05,519 -> 00:00:07,080] 這是一個有監督的問題
[00:00:07,080 -> 00:00:09,560] 但是時間下去解決的
[00:00:09,560 -> 00:00:13,240] 比如說他在進行了第一輪對話以後
[00:00:13,240 -> 00:00:15,039] 他根據這個場景
[00:00:15,039 -> 00:00:16,559] 然後不管是PM
[00:00:16,559 -> 00:00:19,320] 然後Scientist或者Engineer去說
[00:00:19,320 -> 00:00:22,399] 接下來他可能會是想做如下的幾個問題
[00:00:22,399 -> 00:00:26,320] 我們可以通過對話去補足我之前信息的不足
[00:00:26,320 -> 00:00:28,920] 或者說去延伸一下這個場景
[00:00:00,000 -> 00:00:04,519] 但是這個是一個就是把人的 prior knowledge
[00:00:04,519 -> 00:00:07,679] 加到這個模型裡面去針對場景進行的一個設計
[00:00:07,679 -> 00:00:10,759] 並不是因為這個模型本身真的理解了你要幹嘛
[00:00:10,759 -> 00:00:12,480] 我可以這樣理解嗎
[00:00:12,480 -> 00:00:16,519] 這樣說是 我覺得也對也有不準確的
[00:00:16,519 -> 00:00:17,920] 比如說你那個
[00:00:17,920 -> 00:00:21,640] 像實際上你所有的涉及到那個對話
[00:00:21,640 -> 00:00:25,480] conversational agent 或者涉及到那個自然語言理解
[00:00:00,000 -> 00:00:04,599] 它都会有一个叫我得理解用户的intent
[00:00:04,599 -> 00:00:07,940] 就是它的目的或者动机到底是什么
[00:00:07,940 -> 00:00:09,980] 它说这种话它想表达什么意思
[00:00:09,980 -> 00:00:14,660] 像一般就是NIOU里面最经典的就是我说一句话
[00:00:14,660 -> 00:00:16,780] 然后你得知道我的intent是什么
[00:00:16,780 -> 00:00:18,420] 你得知道what I'm talking about
[00:00:18,420 -> 00:00:21,059] 就是intent和entity的recognition
[00:00:21,059 -> 00:00:24,820] 然后比如说我们说一个term或者两个term
[00:00:24,820 -> 00:00:26,219] 或者三个term的那个对话
[00:00:26,219 -> 00:00:28,059] 就一个经典的东西
[00:00:00,000 -> 00:00:01,560] 我得知道他這個intent
[00:00:01,560 -> 00:00:03,560] 第一句的intent是不是carry over
[00:00:03,560 -> 00:00:04,799] 到了第二句話裡面
[00:00:04,799 -> 00:00:06,440] 這其實是一個模型
[00:00:06,440 -> 00:00:09,439] 然後至於我理解了這個intent之後
[00:00:09,439 -> 00:00:10,279] 我要說什麼
[00:00:10,279 -> 00:00:11,599] 那是另一個模型做的事情
[00:00:11,599 -> 00:00:13,480] 所以如果你可以這樣說
[00:00:13,480 -> 00:00:14,759] 你比如說你跟Alexa說
[00:00:14,759 -> 00:00:17,839] Alexa, what's the weather today in Seattle?
[00:00:17,839 -> 00:00:19,480] What's the weather today?
[00:00:19,480 -> 00:00:21,199] 他可能就根據你的location說
[00:00:21,199 -> 00:00:22,600] 哦 西雅圖20度
[00:00:22,600 -> 00:00:25,440] 然後你說How about Boston?
[00:00:25,440 -> 00:00:27,239] 這時候Alexa就要想
[00:00:27,239 -> 00:00:28,879] 你到底在說什麼
[00:00:00,000 -> 00:00:03,319] 它得判断你的weather intent是不是carry over
[00:00:03,319 -> 00:00:04,599] 到了下一句话里面去
[00:00:05,040 -> 00:00:06,799] 如果你接着又问一个weather
[00:00:06,799 -> 00:00:08,080] 比如说what about Houston
[00:00:08,199 -> 00:00:09,640] 那你就达到三个turn了
[00:00:09,640 -> 00:00:13,439] 就是所以说这个东西它只适用于一些use case
[00:00:13,880 -> 00:00:15,960] 就是你不能说它cover所有的use case
[00:00:15,960 -> 00:00:18,879] 就是所以我说这也是像你说的那个
[00:00:18,879 -> 00:00:20,160] 是有一点道理的
[00:00:20,160 -> 00:00:20,480] 对
[00:00:21,079 -> 00:00:26,559] 因为就是从我日常中
[00:00:26,559 -> 00:00:29,399] 我是一个算是用Alexa用的比较多的人吧
[00:00:00,000 -> 00:00:03,160] 在我看來他只不過是給了我一個
[00:00:03,160 -> 00:00:05,360] 用語音
[00:00:05,360 -> 00:00:07,519] 只不過是給了我一個輸入手段
[00:00:07,519 -> 00:00:09,599] 就可能我本來開燈是需要用開關
[00:00:09,599 -> 00:00:10,679] 或者用手機來開
[00:00:10,679 -> 00:00:13,199] 現在我用Alexa去控制一下它
[00:00:13,199 -> 00:00:15,199] 它完成這種任務完成的比較好
[00:00:15,199 -> 00:00:16,719] 或者說我要打開一個News
[00:00:16,719 -> 00:00:18,079] 本來我是用手機打開News
[00:00:18,079 -> 00:00:20,079] 現在我讓Alexa把這個News給我讀出來
[00:00:20,079 -> 00:00:22,120] 它完成這些就是直接控制
[00:00:22,120 -> 00:00:24,120] 一一對應的事情完成的比較好
[00:00:24,120 -> 00:00:25,800] 但是我完全沒有一個
[00:00:25,800 -> 00:00:27,399] 它是一個智能體的感覺
[00:00:27,399 -> 00:00:29,719] 我現在沒有辦法特別好地描述它
[00:00:00,000 -> 00:00:02,439] 但是在我看來這裡面是有應用的
[00:00:02,439 -> 00:00:06,280] 這裡面是有一個很大的gap的
[00:00:06,280 -> 00:00:09,359] 可能我們再闡述一下你的第二
[00:00:09,359 -> 00:00:11,679] 這可能我們給不出一個特別好的答案
[00:00:11,679 -> 00:00:14,519] 但是說一下就是你剛說的第二類問題了
[00:00:14,519 -> 00:00:18,079] 第二類問題就是我們尋找各種各樣的應用場景
[00:00:18,079 -> 00:00:20,440] 然後在這裡還有很多種
[00:00:20,440 -> 00:00:25,399] 很多東西沒有做好
[00:00:25,399 -> 00:00:28,440] 到時候我可能會再提一下第三類
[00:00:00,000 -> 00:00:02,540] 第三類問題就是會不會有範式突破
[00:00:02,540 -> 00:00:03,940] 其實這個是我更關心的
[00:00:03,940 -> 00:00:05,240] 但我們先講第二個吧
[00:00:05,240 -> 00:00:07,540] 就是在現有範式之下去尋找新的應用
[00:00:07,540 -> 00:00:09,339] 我這有一個挺好的例子
[00:00:09,339 -> 00:00:10,220] 而且不是我的例子
[00:00:10,220 -> 00:00:12,019] 就是這本書的作者
[00:00:12,019 -> 00:00:14,320] 他來亞馬遜做講座的時候
[00:00:14,320 -> 00:00:16,679] 作者之一他來亞馬遜做講座的時候
[00:00:16,679 -> 00:00:17,519] 提了一個例子
[00:00:17,519 -> 00:00:19,320] 我覺得其實這個例子非常有啟發性
[00:00:19,320 -> 00:00:22,300] 就是亞馬遜在你買東西的時候
[00:00:22,300 -> 00:00:24,199] 一定會有recommendation對吧
[00:00:24,199 -> 00:00:27,399] 這個recommendation model的清度大概是多少呢
[00:00:27,399 -> 00:00:28,199] 大概5%
[00:00:00,000 -> 00:00:03,080] 他自己的感覺和做了一個survey
[00:00:03,080 -> 00:00:05,719] 就是裡面他給你推薦20個產品的時候
[00:00:05,719 -> 00:00:08,480] 大概有一個是你真的可能會想要的東西
[00:00:08,480 -> 00:00:10,720] 就是這個模型進度是非常低的
[00:00:10,720 -> 00:00:14,359] 然後他說亞馬遜有這麼多數據
[00:00:14,359 -> 00:00:17,199] 他如果這個模型真的能做高
[00:00:17,199 -> 00:00:19,719] 可能做高超過50%的時候
[00:00:19,719 -> 00:00:22,519] 整個生意模式都會有一個非常大的改變
[00:00:22,519 -> 00:00:23,600] 什麼意思呢?
[00:00:23,600 -> 00:00:25,559] 不光是你可以賣更多的東西了
[00:00:25,559 -> 00:00:28,519] 你在這個人想買這個東西之前
[00:00:00,000 -> 00:00:01,540] 你就已經預測到他想買了
[00:00:01,540 -> 00:00:04,299] 說不定你就可以直接先放到他家裡
[00:00:04,299 -> 00:00:05,379] 直接送到他家裡去
[00:00:05,379 -> 00:00:07,179] 當你預測他想要這個東西的時候
[00:00:07,179 -> 00:00:08,179] 就直接送到他家
[00:00:08,179 -> 00:00:10,339] 如果比如說你模型進度超過60%的話
[00:00:10,339 -> 00:00:11,800] 你可能你送上來
[00:00:11,800 -> 00:00:13,419] 然後他不想要的話再退回來
[00:00:13,419 -> 00:00:15,419] 比你現在這種直接買
[00:00:15,419 -> 00:00:18,300] 要更就是這個商業模型更便宜
[00:00:18,300 -> 00:00:20,800] 那他會就會有一個非常大的這個不同
[00:00:20,800 -> 00:00:22,339] 但是並沒有做上去
[00:00:22,339 -> 00:00:24,300] 亞馬遜人到底這麼多數據
[00:00:24,300 -> 00:00:25,679] 這麼多transaction
[00:00:25,679 -> 00:00:29,219] 他為什麼沒有把這個最簡單的推薦模型做好呢
[00:00:00,000 -> 00:00:04,599] 这个很有道理,这不是Rolly Chin说的那个Prime Before吗?
[00:00:04,599 -> 00:00:06,000] 你看那个Rolly Chin吗?
[00:00:06,000 -> 00:00:08,000] Stand Comedian
[00:00:08,000 -> 00:00:11,199] 我没有看过具体的,我知道那个人,但是我没看过这个
[00:00:11,199 -> 00:00:14,000] 现在是Prime Now,但以后是Prime Before
[00:00:14,000 -> 00:00:19,000] 你在想要什么之前,order之前,我已经知道你要什么
[00:00:19,000 -> 00:00:22,000] 这是个很好的问题,我还没有想过这个问题
[00:00:22,000 -> 00:00:25,000] 这个听起来是在现有范式之下可以做好的东西
[00:00:25,000 -> 00:00:28,000] 那你在亚马逊里面,你可不可以大概讲一下
[00:00:28,000 -> 00:00:29,000] 你觉得为什么亚马逊没有做好?
[00:00:00,000 -> 00:00:05,360] 首先我觉得他的这个数字有点太低了
[00:00:05,360 -> 00:00:06,280] 跟我想的不一样
[00:00:06,280 -> 00:00:07,559] 当然具体是多少
[00:00:07,559 -> 00:00:08,679] 我不是很清楚
[00:00:08,679 -> 00:00:09,919] 知道我可能也不能说
[00:00:09,919 -> 00:00:11,800] 但是我觉得肯定不止那么低
[00:00:11,800 -> 00:00:14,759] 到时候读者留言
[00:00:14,759 -> 00:00:18,160] 但是你在多少情况下
[00:00:18,160 -> 00:00:19,199] 你在买了一东西
[00:00:19,199 -> 00:00:20,399] 比如说来马逊的时候
[00:00:20,399 -> 00:00:21,760] 觉得他给你的推荐是
[00:00:21,760 -> 00:00:25,280] 因为他推荐他是personalization的
[00:00:25,280 -> 00:00:27,160] 他是每个人看的不一样的
[00:00:00,000 -> 00:00:04,240] 所以可能那个教授或者像你不是一个average person
[00:00:04,240 -> 00:00:05,240] 可能就不一样
[00:00:05,240 -> 00:00:06,639] 我挺众多用户的
[00:00:06,639 -> 00:00:08,640] 然后但是反正给我推荐了
[00:00:08,640 -> 00:00:10,480] 我觉得这大多数情况推荐东西
[00:00:10,480 -> 00:00:11,560] 我并不觉得要买
[00:00:12,759 -> 00:00:14,679] 就是推荐几个你一个都不想买吗
[00:00:15,080 -> 00:00:15,519] 对
[00:00:16,000 -> 00:00:19,719] 那问题是那时候你自己到底有多强的积蓄购物的意愿呢
[00:00:20,239 -> 00:00:21,760] 我是在上面找东西要买
[00:00:21,760 -> 00:00:24,519] 比如说我可能我买了一个纸
[00:00:24,519 -> 00:00:27,120] 之后我就想买一个这个湿纸巾
[00:00:27,120 -> 00:00:29,120] 然后湿纸巾之后我可能想买洗手液
[00:00:00,000 -> 00:00:03,359] 对,这是complementary的推荐
[00:00:03,359 -> 00:00:04,799] 就是它有两种推荐
[00:00:04,799 -> 00:00:08,000] 一个是substitute推荐和complementary推荐
[00:00:08,000 -> 00:00:11,279] 像substitute推荐一般来说会做得好一点
[00:00:11,279 -> 00:00:13,439] complementary做一些
[00:00:13,439 -> 00:00:13,919] 对
[00:00:13,919 -> 00:00:17,440] 那你理论上就把最好的东西推荐给我就行了
[00:00:17,440 -> 00:00:20,480] 对,complementary是个比较难的问题
[00:00:20,480 -> 00:00:22,719] 对,为什么没有做好呢
[00:00:22,719 -> 00:00:26,000] 就是这个问题本身就要难很多
[00:00:26,000 -> 00:00:29,679] 对,因为像它的难点在哪里呢
[00:00:00,000 -> 00:00:03,520] 它就是它没有像substitute定义的那么好
[00:00:04,120 -> 00:00:06,320] complementary它有两种
[00:00:06,320 -> 00:00:09,119] 比如说你是
[00:00:09,119 -> 00:00:12,640] 我们不就这一个问题展开吧
[00:00:12,640 -> 00:00:14,039] 我们就要说一下
[00:00:14,039 -> 00:00:16,480] 就这个东西是可能做的更好的东西吗
[00:00:16,839 -> 00:00:18,519] 然后是有提升空间的
[00:00:18,519 -> 00:00:19,679] 这个是有提升空间的
[00:00:19,679 -> 00:00:20,039] 对
[00:00:20,039 -> 00:00:21,559] 然后现在没有提升
[00:00:21,559 -> 00:00:23,239] 是因为算力不足
[00:00:23,239 -> 00:00:24,280] 数据不足
[00:00:24,280 -> 00:00:26,239] 还是execution有问题
[00:00:26,239 -> 00:00:27,719] 所以这模型的人不行
[00:00:00,000 -> 00:00:04,480] 我觉得是推荐的很好了对吧
[00:00:04,480 -> 00:00:06,320] 我觉得这个是需要
[00:00:06,320 -> 00:00:09,800] 需要一个science的一些进步
[00:00:09,800 -> 00:00:12,359] 但不是说那个模型需要怎么样进步
[00:00:12,359 -> 00:00:15,359] 而是说你这个问题的理解和它的定义
[00:00:15,359 -> 00:00:16,600] 可能要再进步一些
[00:00:16,600 -> 00:00:18,879] 就这个问题它没有很好的定义
[00:00:18,879 -> 00:00:20,120] 没有很好的well defined
[00:00:20,120 -> 00:00:22,879] 你比如说像complementary
[00:00:22,879 -> 00:00:26,359] compatible也是一种complementary
[00:00:26,359 -> 00:00:29,359] 就比如说你的那个iPhone
[00:00:00,000 -> 00:00:01,120] 它有几种线
[00:00:01,120 -> 00:00:02,520] 比如说这是一个吧
[00:00:02,520 -> 00:00:02,839] 是吧
[00:00:02,839 -> 00:00:03,799] 这叫compatible
[00:00:04,360 -> 00:00:07,120] 你的这么大一个iphone和你的你的线
[00:00:07,120 -> 00:00:10,080] 可能比如说你usb3.0和那个usb a和c
[00:00:10,080 -> 00:00:10,839] 它又不一样
[00:00:11,320 -> 00:00:13,240] 然后比如说你compatible
[00:00:13,240 -> 00:00:16,320] 像你说的牙膏牙刷这种也是一种compatibility
[00:00:16,399 -> 00:00:17,480] 或者complementary
[00:00:17,920 -> 00:00:20,359] 或者还有一种像renew
[00:00:20,399 -> 00:00:22,760] 比如说我喝完那瓶牛奶
[00:00:22,760 -> 00:00:23,719] 我要不要给他
[00:00:23,760 -> 00:00:24,519] 他要不要renew
[00:00:24,559 -> 00:00:25,640] 他想什么时候renew
[00:00:26,039 -> 00:00:26,879] 这也是一个问题
[00:00:26,879 -> 00:00:29,120] 比如说对这些都是
[00:00:00,000 -> 00:00:02,319] 都是一類的問題我覺得
[00:00:02,319 -> 00:00:03,520] OK
[00:00:03,520 -> 00:00:10,640] 那我可以把這個歸根到底的原因是因為
[00:00:10,640 -> 00:00:13,439] 就是沒有足夠的範式突破
[00:00:13,439 -> 00:00:15,919] 導致它沒有被well defined
[00:00:15,919 -> 00:00:21,199] 我覺得在現有的範式是可以把它做出來的
[00:00:21,199 -> 00:00:22,320] 我覺得是可以做得更好
[00:00:22,320 -> 00:00:23,280] 反正我是這麼覺得
[00:00:23,280 -> 00:00:24,079] 有上升的空間
[00:00:24,079 -> 00:00:26,480] 那為什麼沒做好
[00:00:26,480 -> 00:00:29,440] 不能說現有的範式吧
[00:00:00,000 -> 00:00:02,740] 现在有的模型和算力应该是可以把它做得更好的
[00:00:02,740 -> 00:00:03,140] 我觉得
[00:00:03,140 -> 00:00:06,139] 那没有做好的原因主要是因为execution
[00:00:06,139 -> 00:00:08,980] 不是 主要是因为这个建模没有做好
[00:00:08,980 -> 00:00:12,019] 我觉得这个它的数学模型没有做好
[00:00:13,419 -> 00:00:15,740] 它的那个问题的建模没有做好
[00:00:15,740 -> 00:00:18,820] 那为什么没有做好
[00:00:20,100 -> 00:00:21,379] 就是需要
[00:00:21,379 -> 00:00:22,699] 这也不是说不好吧
[00:00:22,699 -> 00:00:24,420] 像有的人说到你的那个
[00:00:24,420 -> 00:00:27,820] 你说是因为动力不足吗
[00:00:27,820 -> 00:00:29,179] 这个问题不够重要吗
[00:00:00,000 -> 00:00:03,279] 这个不是,这个有动力,这个是很有动力的东西
[00:00:03,279 -> 00:00:04,919] 所以亚马逊肯定想把它做好
[00:00:04,919 -> 00:00:07,639] 为什么这么多人,这么多钱没有做好
[00:00:08,519 -> 00:00:10,839] 就是一个难问题,就是一个比较难的问题
[00:00:10,839 -> 00:00:14,679] 你可以去搜有一些paper,最近有一些paper
[00:00:14,679 -> 00:00:17,879] 就算一个比较open,在学术圈都算一个很open的一个问题
[00:00:17,879 -> 00:00:19,280] 就是它确实是个难问题
[00:00:19,800 -> 00:00:25,120] 就是说,就是说你所有的model是吧
[00:00:25,120 -> 00:00:27,640] mathematical model它都是错的
[00:00:28,079 -> 00:00:29,320] 这是一个著名的说法
[00:00:00,000 -> 00:00:03,080] or every model is wrong, but some model is useful
[00:00:03,080 -> 00:00:04,719] 所以你既然是这样的话
[00:00:04,719 -> 00:00:06,040] 你就可以提出一个更好的模型
[00:00:06,040 -> 00:00:06,839] 把它做得更好
[00:00:06,839 -> 00:00:09,480] 所以这个东西它是不断的raise the bar的一个事情
[00:00:09,480 -> 00:00:10,839] 对好
[00:00:10,839 -> 00:00:13,880] 那我觉得这个时候又可以进行三个分类了
[00:00:13,880 -> 00:00:16,120] 刚刚你说的第一类是well-defined
[00:00:16,120 -> 00:00:18,000] 然后这里边进步空间不大的
[00:00:18,000 -> 00:00:19,679] 第二类是找use case
[00:00:19,679 -> 00:00:22,519] 我觉得这算是一个类似的
[00:00:22,519 -> 00:00:23,519] 这是个很好的例子
[00:00:23,519 -> 00:00:27,000] 对就是它虽然有提升空间
[00:00:00,000 -> 00:00:03,520] 但是還要取決於我們在科學方面
[00:00:03,520 -> 00:00:07,160] 和模型本身工程方面的進步
[00:00:07,160 -> 00:00:08,439] 才可以把它做得更好
[00:00:08,439 -> 00:00:09,800] 而且有很大的形成空間
[00:00:09,800 -> 00:00:10,759] 這是第一
[00:00:10,759 -> 00:00:14,000] 第三個就是在目前的科學來看
[00:00:14,000 -> 00:00:15,000] 基礎科學來看
[00:00:15,000 -> 00:00:17,280] 就是從人工智能的基礎科學來看
[00:00:17,280 -> 00:00:20,719] 並沒有成功的希望
[00:00:20,719 -> 00:00:22,600] 比如說做成一個智能體
[00:00:22,600 -> 00:00:24,399] 或者說強人工智能
[00:00:24,399 -> 00:00:26,760] 看起來暫時是沒有希望的
[00:00:00,000 -> 00:00:02,839] 就是暫時是對的
[00:00:02,839 -> 00:00:08,199] 然後現在大廠一部分盈利是投在前面
[00:00:08,199 -> 00:00:11,400] 或者說把這個Well-defined的問題把它應用到更好
[00:00:11,400 -> 00:00:13,560] 應用到更廣或者提高這個金度
[00:00:13,560 -> 00:00:16,719] 我覺得像我接觸到的這個
[00:00:16,719 -> 00:00:19,679] 比如說廣告模型就是一個很典型的例子
[00:00:19,679 -> 00:00:22,000] 它提高一點金度收益都會很大
[00:00:22,000 -> 00:00:24,280] 那也有很多人力物力放在這上面
[00:00:24,280 -> 00:00:27,559] 第二類就是找各種各樣的這個應用
[00:00:00,000 -> 00:00:03,200] 那在你看来大厂是在非常积极的推动这些吗
[00:00:03,200 -> 00:00:06,440] 还是他们把主要的是人力物力放到前一种了
[00:00:07,639 -> 00:00:09,279] 对我觉得这是个很好的问题
[00:00:09,279 -> 00:00:11,279] 像这个每个公司情况又不一样
[00:00:11,720 -> 00:00:14,119] 你比如说Google它更倾向于像前一种
[00:00:14,119 -> 00:00:16,559] 包括我觉得Facebook或者抖音这种
[00:00:16,559 -> 00:00:17,800] 它都倾向于前一种
[00:00:18,280 -> 00:00:20,719] 就是它去把它那个做到极致是吧
[00:00:20,719 -> 00:00:22,160] 比如推荐引擎做到最好
[00:00:22,160 -> 00:00:23,960] 或者广告的搜索做到最好
[00:00:24,320 -> 00:00:26,120] 亚马逊它是第二种
[00:00:26,679 -> 00:00:28,920] 所以亚马逊它招这么多applied scientist
[00:00:00,000 -> 00:00:02,000] 它是希望你来做应用题的
[00:00:02,000 -> 00:00:04,000] 就是我data在这里是吧
[00:00:04,000 -> 00:00:07,000] 然后我有这些business metric
[00:00:07,000 -> 00:00:09,000] 要不是revenue或者别的什么我想提高
[00:00:09,000 -> 00:00:11,000] 你来给我想怎么做
[00:00:11,000 -> 00:00:13,000] 我不care你是去找个paper把它给做出来
[00:00:13,000 -> 00:00:15,000] 还是你自己写个paper
[00:00:15,000 -> 00:00:17,000] 创造一个方法把它做出来
[00:00:17,000 -> 00:00:19,000] 反正你要把它给我做出来
[00:00:19,000 -> 00:00:21,000] 亚马逊的思路就是这样的
[00:00:21,000 -> 00:00:24,000] 是不是因为亚马逊它的业务范围比较广
[00:00:24,000 -> 00:00:27,000] 比如说都是来自于广告是吧
[00:00:27,000 -> 00:00:29,000] 然后亚马逊的各种各样
[00:00:00,000 -> 00:00:02,000] 它的data多样性比较大
[00:00:02,000 -> 00:00:05,000] 那在你看来就是公司的机制
[00:00:05,000 -> 00:00:09,000] 就是公司提供了这么多实验和应用的土壤
[00:00:09,000 -> 00:00:12,000] 也给你提供了很多工具和数据
[00:00:12,000 -> 00:00:16,000] 那你觉得大家有可能在这里边形成很多突破吗
[00:00:16,000 -> 00:00:21,000] 就是公司能鼓励这些突破吗
[00:00:21,000 -> 00:00:22,000] 我觉得可以
[00:00:22,000 -> 00:00:26,000] 我觉得至少这种亚马逊这种模式的应用研究是可以的
[00:00:00,000 -> 00:00:01,700] 的应用研究是可以的
[00:00:01,700 -> 00:00:03,620] 就是它是可以形成
[00:00:03,620 -> 00:00:04,660] 至少它可以形成很多
[00:00:04,660 -> 00:00:06,459] 它自己的一些新的应用
[00:00:06,919 -> 00:00:07,620] 那有没有
[00:00:08,880 -> 00:00:09,220] 嗯
[00:00:09,539 -> 00:00:11,619] 就是有没有能说的例子
[00:00:11,880 -> 00:00:14,339] 就是在过去的多少年之内发生了
[00:00:14,339 -> 00:00:16,300] 几个比较好的应用
[00:00:17,839 -> 00:00:18,839] 我想想啊
[00:00:19,760 -> 00:00:21,300] 因为我之前是做
[00:00:21,300 -> 00:00:21,960] well defined
[00:00:21,960 -> 00:00:24,039] 我在广告里面做了两年多是吧
[00:00:24,039 -> 00:00:24,960] 就算是well defined
[00:00:24,960 -> 00:00:26,539] 现在我做智能客服
[00:00:26,960 -> 00:00:28,460] 智能客服这个东西
[00:00:00,000 -> 00:00:03,200] 它其实也算一个比较常见的一个问题
[00:00:03,200 -> 00:00:05,679] 只是说它每个公司可能它的case不一样
[00:00:05,679 -> 00:00:09,119] 像像像亚马逊的话
[00:00:09,919 -> 00:00:11,640] 我想想我可以说什么
[00:00:11,640 -> 00:00:13,279] 比如说你在用户打进来
[00:00:13,279 -> 00:00:15,039] 我得预测你想你想要什么
[00:00:15,039 -> 00:00:16,640] 你的那个issue到底是什么
[00:00:16,640 -> 00:00:18,320] 这有点类似一个intent
[00:00:18,320 -> 00:00:21,879] intent的那个detection或者叫identification
[00:00:21,879 -> 00:00:26,760] 然后呢我就我现在比如说我要我的模型要做一个决定
[00:00:26,760 -> 00:00:28,679] 我到底是让自动解决你的问题
[00:00:00,000 -> 00:00:02,419] 还是让一个人来解决你的问题是吧
[00:00:02,899 -> 00:00:03,740] 这也是一个
[00:00:03,740 -> 00:00:07,500] 所以对他可能会根据你的一些特性啊什么的
[00:00:07,500 -> 00:00:11,220] 根据你的一些说的什么呀来做这个决定
[00:00:11,500 -> 00:00:13,099] 具体的这个我就不能说了
[00:00:13,099 -> 00:00:14,939] 这是一个
[00:00:14,939 -> 00:00:16,579] 包括你刚才说那个例子也很好
[00:00:16,579 -> 00:00:18,620] 就是他的那个产品的推荐
[00:00:18,940 -> 00:00:20,940] 他如果做得很好就会改变业务模式
[00:00:21,260 -> 00:00:22,940] 具体的例子不能说
[00:00:22,940 -> 00:00:25,059] 但是我们这个问题也值得展开一下
[00:00:25,059 -> 00:00:27,579] 因为我之前做那个management consulting的时候
[00:00:00,000 -> 00:00:03,759] 還跟國內的一些很多公司去做
[00:00:03,759 -> 00:00:05,320] 然後國內很多公司
[00:00:05,320 -> 00:00:07,480] 比如說這個移動通信運營商
[00:00:07,480 -> 00:00:11,160] 他們最關心的就是他們提到人工智能應用
[00:00:11,160 -> 00:00:13,279] 很多時候就在講這種客服
[00:00:13,279 -> 00:00:14,560] 因為對他們來說
[00:00:14,560 -> 00:00:17,039] Concentr是一個非常大的人力支出
[00:00:17,039 -> 00:00:19,519] 對他們就講到這些
[00:00:19,519 -> 00:00:20,600] 然後前一段時間
[00:00:20,600 -> 00:00:23,679] Google也出了自動幫你打電話訂餐
[00:00:23,679 -> 00:00:26,440] 然後以假亂真的這種程度的東西
[00:00:26,440 -> 00:00:29,480] 你覺得這兩個之間的gap到底有多大
[00:00:00,000 -> 00:00:04,200] 就是Google那個從它展示出來的應用來看
[00:00:04,200 -> 00:00:08,480] 似乎已經做到了以假亂真的這個完全的對話
[00:00:08,480 -> 00:00:12,000] 對吧,完成了一整個,完成一整系列對話
[00:00:12,000 -> 00:00:13,279] 最後達到了這個任務
[00:00:13,279 -> 00:00:16,600] 但是如果說你真正看
[00:00:16,600 -> 00:00:19,519] 尤其國內企業的普遍的客服應用
[00:00:19,519 -> 00:00:21,719] 沒有任何這個智能空間
[00:00:21,719 -> 00:00:23,280] 包括比如說我用美國銀行
[00:00:23,280 -> 00:00:25,039] 它給我來一個智能的東西
[00:00:25,039 -> 00:00:26,480] 包括亞馬遜的客服
[00:00:26,480 -> 00:00:27,719] 如果說是智能的
[00:00:00,000 -> 00:00:02,680] 其實就是幾個選項的問答機器人而已
[00:00:02,680 -> 00:00:05,440] 就是說你來了以後從這裡面九個選一個
[00:00:05,440 -> 00:00:07,679] 然後進去以後再從這三個裡面選一個
[00:00:07,679 -> 00:00:09,800] 這種感覺解決不了的
[00:00:09,800 -> 00:00:12,439] 要麼給你已經好的答案
[00:00:12,439 -> 00:00:14,679] 要麼給你人工智庫
[00:00:14,679 -> 00:00:16,079] 只不過是一個
[00:00:16,079 -> 00:00:20,600] 只不過是一個自動問答機而已
[00:00:20,600 -> 00:00:23,879] 那你覺得比如說Google在這兒
[00:00:23,879 -> 00:00:26,199] Google的應用展示場景在這兒
[00:00:26,199 -> 00:00:27,000] 亞馬遜在這兒
[00:00:00,000 -> 00:00:03,640] 然后可能更简单的电话问答机在这的话
[00:00:03,640 -> 00:00:05,879] 那我们离这有多远
[00:00:05,879 -> 00:00:11,240] 我们离这个Google的这个模式大规模应用有多远
[00:00:11,240 -> 00:00:12,560] 或者是不是一个可能
[00:00:12,560 -> 00:00:14,119] Foreseeable future
[00:00:14,119 -> 00:00:17,839] 我觉得这个不是个apple to apple的一个比较
[00:00:17,839 -> 00:00:21,160] 因为Google那个还是一个特定的use case
[00:00:21,160 -> 00:00:22,079] 我觉得点餐
[00:00:22,079 -> 00:00:23,719] 因为点餐我只要把那个
[00:00:23,719 -> 00:00:26,719] 它还是一个比较limited的一个场景
[00:00:00,000 -> 00:00:02,279] 我是这么认为的
[00:00:02,279 -> 00:00:04,080] 退货是一个理面体场景吗?
[00:00:05,599 -> 00:00:07,440] 退货是一个比较well defined的场景
[00:00:07,440 -> 00:00:10,080] 对,已经可以做得比较自动化了这个事情
[00:00:10,320 -> 00:00:11,080] 是吗?
[00:00:11,359 -> 00:00:11,679] 对
[00:00:14,119 -> 00:00:16,239] 比如说亚马逊他得知道你是在
[00:00:16,239 -> 00:00:17,600] 你是要退货或者干别的吧
[00:00:17,600 -> 00:00:18,640] 这是一个intent吧
[00:00:18,640 -> 00:00:19,800] 一个级别的intent
[00:00:20,199 -> 00:00:21,320] 然后你如果是退货
[00:00:21,320 -> 00:00:22,879] 他得知道你要退哪个货吧
[00:00:22,879 -> 00:00:23,199] 是吧
[00:00:23,199 -> 00:00:24,800] 这是另外一个intent
[00:00:25,079 -> 00:00:26,440] 那我那我就说吧
[00:00:26,440 -> 00:00:29,640] 就是比如说我就拿一个移动运营商来
[00:00:00,000 -> 00:00:01,199] 比较AT&T
[00:00:01,480 -> 00:00:04,599] 你打电话给AT&T有各种各样的事情需要解决
[00:00:04,599 -> 00:00:05,519] 或者说你网络不好
[00:00:05,519 -> 00:00:06,400] 你打电话给Comcast
[00:00:06,400 -> 00:00:07,919] 有各种各样的事情被解决
[00:00:08,279 -> 00:00:12,240] 把这套东西做成完全人工智能
[00:00:12,560 -> 00:00:15,119] 然后精度可能95%以上
[00:00:15,400 -> 00:00:17,440] 在你看来是一个做得到的
[00:00:17,440 -> 00:00:19,399] 是一线有技术条件是做得到的事情
[00:00:19,399 -> 00:00:19,760] 对吧
[00:00:20,839 -> 00:00:22,839] 具体是不是95%
[00:00:22,839 -> 00:00:25,440] 我觉得这个就要看它到底use case有多复杂
[00:00:25,440 -> 00:00:27,399] 但我觉得是可以不断提升的
[00:00:27,399 -> 00:00:29,960] 这个有点像那种自动驾驶
[00:00:00,000 -> 00:00:03,359] 就是你要做95%的自动驾驶都不是那么难
[00:00:03,359 -> 00:00:04,519] 现在可能已经做到了
[00:00:04,919 -> 00:00:07,360] 但是你要做100%的自动驾驶就很难了
[00:00:07,360 -> 00:00:07,759] 对
[00:00:08,599 -> 00:00:11,199] 这个在我看来只不过是一个价格的问题
[00:00:11,199 -> 00:00:13,960] 就是自动驾驶它是一个一旦你出事了
[00:00:13,960 -> 00:00:17,480] 它的负面影响特别特别高
[00:00:17,719 -> 00:00:21,039] 但是你打电话过去这个精度不高
[00:00:21,079 -> 00:00:22,879] 它是一个tolerable的事
[00:00:22,920 -> 00:00:25,879] 因为你人工就是人工服务也没有100%
[00:00:25,879 -> 00:00:27,559] 人工服务很多时候你打个电话过去
[00:00:27,559 -> 00:00:29,039] 他才给你搞错
[00:00:00,000 -> 00:00:02,000] 對,philosophical是這樣的
[00:00:02,000 -> 00:00:02,500] 對
[00:00:02,500 -> 00:00:06,000] 但從技術來講,它確實也是說你要提升
[00:00:06,000 -> 00:00:08,000] 你到最後要再提升就很難了
[00:00:08,000 -> 00:00:13,000] 對,那我們現在其實是分別講了兩大塊內容
[00:00:13,000 -> 00:00:19,000] 一個是講了這個人工智能深入學習和機器學習到底是什麼
[00:00:19,000 -> 00:00:21,000] 一個是他們在大廠的應用
[00:00:21,000 -> 00:00:23,000] 我現在想把他們兩個給聯繫起來
[00:00:23,000 -> 00:00:25,000] 就是為什麼是現在的這個狀態
[00:00:00,000 -> 00:00:04,519] 就是这些应用是不是在场
[00:00:04,519 -> 00:00:08,199] 全都是集中精力在机器学习和生动学习中
[00:00:08,199 -> 00:00:12,800] 然后他们有没有去做机器学习生动学习以外的人工智能的其他部分
[00:00:12,800 -> 00:00:14,519] 这是第一个问题
[00:00:14,519 -> 00:00:16,399] 第二个问题
[00:00:16,399 -> 00:00:18,000] 你先回答第一个问题吧
[00:00:18,000 -> 00:00:20,879] 是有的
[00:00:20,879 -> 00:00:22,199] 都有的
[00:00:22,199 -> 00:00:23,719] 你比如说
[00:00:23,719 -> 00:00:28,280] 像我在IBM Research做过实习
[00:00:00,000 -> 00:00:02,799] 当时他们会做一些比较稍微前沿的东西
[00:00:02,799 -> 00:00:08,519] 比如说他用推荐引擎来做那个合成化学物高分子
[00:00:08,519 -> 00:00:11,480] 比如说高分子它涉及到我怎么在这里加一个那个
[00:00:11,480 -> 00:00:13,000] 那你加一个那个怎么做呢
[00:00:13,000 -> 00:00:16,920] 我有没有一些新的principle的办法来做这个
[00:00:17,320 -> 00:00:19,239] 他就比如说用推荐引擎来
[00:00:19,239 -> 00:00:21,000] 然后通过一些指标来看
[00:00:21,000 -> 00:00:22,920] 他是不是这样加比较make sense
[00:00:23,480 -> 00:00:26,960] 然后包括一些更基础的人工智能的一些
[00:00:00,000 -> 00:00:02,919] 一些方向吧分支吧
[00:00:02,919 -> 00:00:04,960] 比如说理论计算机
[00:00:04,960 -> 00:00:08,119] 我要怎么研究复杂度分析这种东西
[00:00:08,119 -> 00:00:09,599] 或者在一些经典的问题上
[00:00:09,599 -> 00:00:12,320] 我能不能找到更快的算法
[00:00:12,320 -> 00:00:14,359] 因为你如果能够做到这个的话
[00:00:14,359 -> 00:00:16,719] 你可能就能解决一些更多的新的问题
[00:00:17,239 -> 00:00:19,199] 像比如说那些经典的
[00:00:19,199 -> 00:00:21,320] 对这也是人工智能其实很重要的一方面
[00:00:21,320 -> 00:00:22,719] 就除了机器学习以外
[00:00:22,719 -> 00:00:27,559] 它是凡是智能体能够做或者不能做的事情
[00:00:27,559 -> 00:00:29,160] 它都属于人工智能的范畴
[00:00:00,000 -> 00:00:03,399] 比如说比如说你自己人的最经典的
[00:00:03,399 -> 00:00:04,799] 你找了一个最短路径是吧
[00:00:04,799 -> 00:00:06,360] 你从A到B有这么多条路
[00:00:06,360 -> 00:00:09,080] 你要哪条路你最最短能够到达
[00:00:09,080 -> 00:00:10,599] 像蚂蚁就可以做得很好
[00:00:10,880 -> 00:00:13,000] 或者人其实那么一看
[00:00:13,000 -> 00:00:14,839] heuristic他也可以做得比较好
[00:00:15,279 -> 00:00:17,359] 但计算机它最开始就要去不断的去
[00:00:17,359 -> 00:00:18,679] 穷举所有的solution
[00:00:18,679 -> 00:00:20,679] 直到后来有人做出了更好的算法
[00:00:21,320 -> 00:00:23,920] 包括很经典的一个特别特别难的问题
[00:00:23,920 -> 00:00:25,519] 是那个旅行商问题
[00:00:25,519 -> 00:00:27,600] 就是你有那么五个城市
[00:00:27,600 -> 00:00:29,440] 比如说traveling salesman problem
[00:00:00,000 -> 00:00:01,800] 你得把它全部都走一遍
[00:00:01,800 -> 00:00:03,399] 然后你要让你的路径最短
[00:00:03,399 -> 00:00:04,919] 这是一个很难很难的问题
[00:00:04,919 -> 00:00:06,960] 这比那个最短路径要难很多很多倍
[00:00:06,960 -> 00:00:09,119] 它是一个指数级难度的一个问题
[00:00:09,119 -> 00:00:11,400] 像比如说像
[00:00:11,400 -> 00:00:14,039] 据我所知比如微软研究院
[00:00:14,039 -> 00:00:16,000] 它就在它有很多人在研究这些问题
[00:00:16,000 -> 00:00:18,079] 包括谷歌研究院肯定也有
[00:00:18,079 -> 00:00:22,879] 所以他们就会做一些这样的基础性的一些研究
[00:00:22,879 -> 00:00:25,839] 就是比较它不一定有直接的实际的价值
[00:00:00,000 -> 00:00:04,879] 但它long term来讲是能够推动这个学科的下一步的发展
[00:00:05,759 -> 00:00:07,280] 这其实蛮有意思的
[00:00:07,280 -> 00:00:12,320] 因为谷歌微软包括Facebook都有自己的AI实验室
[00:00:12,320 -> 00:00:12,640] 对吧
[00:00:12,640 -> 00:00:13,759] 有一个centralized
[00:00:13,759 -> 00:00:15,199] 但是亚马逊好像没有
[00:00:15,480 -> 00:00:19,760] 但是刚刚说的亚马逊是一个以这种去中心化的模式
[00:00:19,760 -> 00:00:23,359] 然后让每个招来一大堆的PyScientist
[00:00:23,359 -> 00:00:24,719] 然后在不同的领域
[00:00:24,719 -> 00:00:29,800] 也可能能试出来一些从应用方面来推动
[00:00:00,000 -> 00:00:02,160] 那都蠻有意思的
[00:00:02,160 -> 00:00:06,440] 還有業務,我覺得他的業務還沒到就是
[00:00:06,440 -> 00:00:11,519] 怎麼說呢,就是他現在的priority不是去研究那些特別基礎的問題吧
[00:00:11,519 -> 00:00:12,320] 我是這麼覺得
[00:00:12,320 -> 00:00:14,519] 我覺得這個應該可以說吧
[00:00:14,519 -> 00:00:15,839] 我記得我在亞馬遜應該可以說
[00:00:15,839 -> 00:00:19,199] 在亞馬遜的時候他有一些那個所謂的big bet
[00:00:19,199 -> 00:00:21,440] 他有說這個我們要研究三年之後
[00:00:21,440 -> 00:00:22,879] 對,我不知道有沒有人在做
[00:00:22,879 -> 00:00:24,320] 也可能有人在做,只是我不知道
[00:00:24,320 -> 00:00:28,879] 因為我知道就是包括有一些central team
[00:00:00,000 -> 00:00:03,839] 其實像之前那個Core AI什麼的也都有一些
[00:00:03,839 -> 00:00:06,919] 但不一定Google和Facebook
[00:00:06,919 -> 00:00:08,439] 外界知名度這麼高吧
[00:00:08,439 -> 00:00:09,919] 也先把學了很多東西
[00:00:09,919 -> 00:00:11,240] 學術透明度
[00:00:11,240 -> 00:00:15,439] 對 蘋果也是那樣的
[00:00:15,439 -> 00:00:18,760] 這是第一個問題
[00:00:18,760 -> 00:00:22,280] 我覺得就是答案就是我們現在一方面
[00:00:22,280 -> 00:00:25,839] 這些大廠們是看當下的應用
[00:00:25,839 -> 00:00:29,640] 也會往前看一看推動學科往前發展
[00:00:00,000 -> 00:00:02,000] 但是可能就像你剛剛說的
[00:00:02,000 -> 00:00:04,000] 所謂的範式突破
[00:00:04,000 -> 00:00:08,000] 我們沒有去指望去發明一顆原子彈
[00:00:08,000 -> 00:00:10,500] 發明發現智能方程的這樣一個方式突破
[00:00:10,500 -> 00:00:14,000] 而是有一些其他的一小點一小點
[00:00:14,000 -> 00:00:15,000] 推動這個學科往前走
[00:00:15,000 -> 00:00:18,000] 但是也可以拓展這個學科邊界
[00:00:18,000 -> 00:00:21,000] 比較高的程度
[00:00:21,000 -> 00:00:25,000] 第二個問題其實是關於
[00:00:25,000 -> 00:00:28,000] 這個模型本身和生意模式的關係
[00:00:00,000 -> 00:00:02,819] 就是你如果看抖音,你剛提到抖音
[00:00:02,819 -> 00:00:06,400] 它其實是一個基於推薦算法的公司
[00:00:06,400 -> 00:00:08,900] 就是它把推薦算法做好了以後
[00:00:08,900 -> 00:00:11,519] 它找到了不同的各種各樣的應用
[00:00:11,519 -> 00:00:13,900] 然後其中有一些活的,有一些沒活的
[00:00:13,900 -> 00:00:16,199] 但是它是一個基於算法起來的公司
[00:00:16,199 -> 00:00:17,280] 這是一個很新的公司
[00:00:17,280 -> 00:00:18,739] 如果往回看的話
[00:00:18,739 -> 00:00:21,620] 其實Google也算是一個基於算法的公司
[00:00:21,620 -> 00:00:26,120] 基於它的這個爬的能力和這個search的能力
[00:00:26,120 -> 00:00:27,839] 去做出來的這樣一個公司
[00:00:00,000 -> 00:00:02,879] 那人工智能再往前走
[00:00:02,879 -> 00:00:05,200] 可能會出來很多這種
[00:00:05,200 -> 00:00:07,440] 算法模式上的創新
[00:00:07,440 -> 00:00:11,240] 然後這些創新是會出現在大城裡呢
[00:00:11,240 -> 00:00:12,599] 還會出現在外面
[00:00:12,599 -> 00:00:13,839] 為什麼
[00:00:13,839 -> 00:00:15,679] 就是如果說是出現在
[00:00:15,679 -> 00:00:18,440] 抖音其實我覺得挺奇怪的
[00:00:18,440 -> 00:00:19,960] 就是按道理
[00:00:19,960 -> 00:00:21,760] 像Google Facebook
[00:00:21,760 -> 00:00:24,000] 包括國內的這個BAT
[00:00:24,000 -> 00:00:25,199] 那時候的BAT
[00:00:25,199 -> 00:00:29,160] 他們都是更有條件數據去開發這個算法的
[00:00:00,000 -> 00:00:02,000] 他們可以把這個算法做得更好
[00:00:02,000 -> 00:00:04,000] 但是他們為什麼沒有出現抖音
[00:00:04,000 -> 00:00:06,000] 為什麼抖音是一個新公司
[00:00:06,000 -> 00:00:08,000] 而不是出現在這些大廠裡
[00:00:08,000 -> 00:00:10,000] 這是個很好很好的問題
[00:00:10,000 -> 00:00:12,000] 其實我也想討論這樣的問題
[00:00:12,000 -> 00:00:15,000] 就是要不我先回答第二個問題吧
[00:00:15,000 -> 00:00:18,000] 就我認為抖音它幾乎做到了一件
[00:00:18,000 -> 00:00:19,000] 不可能完成的任務
[00:00:19,000 -> 00:00:22,000] 就是它從零做出來的一個這樣的產品
[00:00:22,000 -> 00:00:25,000] 就是它一開始它沒有數據是吧
[00:00:25,000 -> 00:00:27,000] 你看如果看張一鳴他幾年前
[00:00:27,000 -> 00:00:29,000] 大概14 13年他的微博
[00:00:00,000 -> 00:00:02,200] 他的微博他所有东西都在微博上
[00:00:02,200 -> 00:00:03,480] 你可以看他整个创业过程
[00:00:03,480 -> 00:00:05,000] 他那时候发的东西是
[00:00:05,000 -> 00:00:07,639] 哎呀我怎么用Google Analytics来做增长
[00:00:07,639 -> 00:00:10,320] 他说中国怎么没几个人用Google Analytics用的好
[00:00:10,320 -> 00:00:12,960] 所以他相当于是从零做起来这样一个东西
[00:00:12,960 -> 00:00:14,279] 我觉得这还是很了不起的
[00:00:14,279 -> 00:00:16,079] 就是因为他一开始没有数据
[00:00:16,079 -> 00:00:17,399] 他后来把他数据越做越大
[00:00:17,399 -> 00:00:18,960] 然后推荐引擎做得越来越好
[00:00:18,960 -> 00:00:21,920] 就我觉得这个模式已经做到了极致了
[00:00:21,920 -> 00:00:25,399] 这个模式的特点就是赢者通吃
[00:00:25,399 -> 00:00:27,719] 比如说我如果抖音我的推荐引擎
[00:00:00,000 -> 00:00:03,700] 比另一家競爭對手做的好那麼一點點
[00:00:03,700 -> 00:00:05,299] 大家全部都會去用抖音
[00:00:05,299 -> 00:00:07,599] 他就是贏者通吃的一個市場
[00:00:07,599 -> 00:00:11,300] 然後所以他就可以形成一個壟斷了
[00:00:11,300 -> 00:00:13,500] 然後你說的第一個
[00:00:13,500 -> 00:00:16,899] 就是在他發力的那麼長一段時間
[00:00:16,899 -> 00:00:19,300] 所有的大廠都可以比他做得好
[00:00:19,300 -> 00:00:24,199] 因為他們的算力數據人才都比他好
[00:00:24,199 -> 00:00:27,199] 或者除非你說就是張一鳴一個人
[00:00:27,199 -> 00:00:29,199] 可以吊打所有大廠所有的工程師
[00:00:00,000 -> 00:00:04,320] 它當然這是一個整體的文化或者激勵機制
[00:00:04,320 -> 00:00:06,200] 然後它確實人才也還挺好的
[00:00:06,200 -> 00:00:11,080] 就是說它確實是把這個模式就做到了極致
[00:00:11,080 -> 00:00:12,000] 我覺得
[00:00:12,000 -> 00:00:16,320] 但是為什麼它
[00:00:16,320 -> 00:00:22,280] 或者說其實數據降低沒有我們想像那麼重要
[00:00:22,280 -> 00:00:25,079] 而是它有一個mindset更重要
[00:00:25,079 -> 00:00:28,399] 比如說我們說有兩種世界
[00:00:00,000 -> 00:00:03,259] 第一个就是这些大厂在他们积累越来越多的数据
[00:00:03,259 -> 00:00:05,540] 越来越强的算力和越来越多应用的情况下
[00:00:05,540 -> 00:00:06,900] 他们壁垒越来越高
[00:00:07,580 -> 00:00:11,500] 但是我们另外一方面也会看到很多的模型其实是开源的
[00:00:11,500 -> 00:00:16,300] 包括他们模型背后的框架和工具都是开源的
[00:00:16,539 -> 00:00:19,019] 任何一个人都可以使用它
[00:00:19,019 -> 00:00:20,579] 也许它没有数据
[00:00:20,579 -> 00:00:24,300] 但是这个数据可能我从几千个人收集上来的数据
[00:00:24,300 -> 00:00:27,460] 和几百亿个人收集上来的数据差别不是那么大
[00:00:00,000 -> 00:00:03,080] 就是只要我把這個模型做好了
[00:00:03,080 -> 00:00:04,480] 也許我的是90%
[00:00:04,480 -> 00:00:05,879] 然後你的是99%
[00:00:05,879 -> 00:00:07,280] 但是我剩下的這些差距
[00:00:07,280 -> 00:00:11,119] 我暫時可以用更好的生意模式來彌補
[00:00:11,119 -> 00:00:14,439] 直到我把我的模型慢慢做上去
[00:00:15,439 -> 00:00:18,120] 我覺得這很有意思的問題
[00:00:18,120 -> 00:00:19,559] 我這幾天一直在想這個問題
[00:00:19,559 -> 00:00:22,120] 特別是聽證會開完了以後
[00:00:22,600 -> 00:00:25,800] 就是國會眾議院的聽證會
[00:00:25,800 -> 00:00:27,800] 其實我覺得大家都說
[00:00:00,000 -> 00:00:03,899] 算力和數據是造成人工智能
[00:00:03,899 -> 00:00:05,900] 或者深度學習騰飛的兩個條件
[00:00:05,900 -> 00:00:09,699] 但我覺得其實數據遠遠比算力要更重要
[00:00:09,699 -> 00:00:13,099] 算力其實是類似於除透
[00:00:13,099 -> 00:00:15,300] 數據才是那個礦
[00:00:15,300 -> 00:00:17,500] 如果比如google的裝逼
[00:00:17,500 -> 00:00:21,000] 我覺得他把特別牛逼的模型開源了
[00:00:21,000 -> 00:00:23,300] 說你看我特別open access
[00:00:23,300 -> 00:00:24,800] 然後我是人類的希望
[00:00:24,800 -> 00:00:26,800] 但他數據他不會給你開源的
[00:00:26,800 -> 00:00:29,100] 就是你拿這個再fancy的除透
[00:00:29,100 -> 00:00:29,899] 你也沒有用
[00:00:00,000 -> 00:00:05,879] 但是抖音的成功是不是一定程度上告訴我們說數據也沒有那麼重要
[00:00:05,879 -> 00:00:11,000] 我覺得不是,我覺得它一開始,你看它特別強調那個增長
[00:00:11,000 -> 00:00:13,320] 它就是要把數據抓在自己手上
[00:00:13,320 -> 00:00:15,679] 就是說我覺得它的成功
[00:00:15,679 -> 00:00:17,079] 大廠沒有成
[00:00:17,079 -> 00:00:20,600] 我不知道具體的歷史
[00:00:20,600 -> 00:00:22,800] 會不會是說它已經做到了一定程度
[00:00:22,800 -> 00:00:24,199] 大廠才意識到這個威脅
[00:00:24,199 -> 00:00:26,879] 然後特別是國內的話
[00:00:00,000 -> 00:00:02,960] 然后呢他因为他比如TikTok
[00:00:02,960 -> 00:00:04,519] 他可以用国内的数据来train嘛
[00:00:04,519 -> 00:00:05,480] 然后再到美国来
[00:00:05,480 -> 00:00:09,240] 他其实已经有了一部分的那个先发优势
[00:00:09,240 -> 00:00:10,839] 已经有了一部分的优势
[00:00:10,839 -> 00:00:13,240] 我不知道在国内刚开始做的时候
[00:00:13,839 -> 00:00:15,800] 大厂有可能没有意识到啊
[00:00:15,800 -> 00:00:18,519] 有可能大厂有可能没有意识到
[00:00:18,519 -> 00:00:22,039] 我觉得可能是就是他有一段有一段时间
[00:00:22,039 -> 00:00:24,039] 然后他度过了最危险的时候
[00:00:24,199 -> 00:00:26,519] 这个有可能仍然我也不是很了解
[00:00:00,000 -> 00:00:03,839] 而且它相当于也是一个比较新的一个模式
[00:00:03,839 -> 00:00:04,679] 它是短视频嘛
[00:00:04,679 -> 00:00:07,639] 它没有去说像做一个微信或者什么那样
[00:00:08,199 -> 00:00:09,759] 或者说搜索引擎
[00:00:09,759 -> 00:00:16,039] 就是我相信当它在出现在大厂的radar之上的时候
[00:00:16,760 -> 00:00:21,359] 这个时候它的数据肯定也是不如这些大厂多的
[00:00:22,640 -> 00:00:24,559] 你到了一定的量以后就
[00:00:24,559 -> 00:00:26,600] 通过方式腾讯阿里这样的大厂
[00:00:26,600 -> 00:00:27,440] 包括微博
[00:00:27,440 -> 00:00:29,760] 我相信微博它如果想的话
[00:00:00,000 -> 00:00:01,700] 他也想做出一個抖音,對吧?
[00:00:01,700 -> 00:00:05,040] 他又能,而且他的數據安道理是比抖音要多的
[00:00:05,040 -> 00:00:09,199] 當抖音出現已經受sales success的時候
[00:00:09,199 -> 00:00:11,839] 或者頭條那個時候已經受sales success的時候
[00:00:11,839 -> 00:00:14,800] 他要真的想做,他安道理是可以做的
[00:00:14,800 -> 00:00:17,879] 而且他有那個時候比抖音更多的數據
[00:00:17,879 -> 00:00:19,399] 但是他做沒有做出來
[00:00:19,399 -> 00:00:22,839] 對,我覺得到了一定程度數據就差不多了吧
[00:00:22,839 -> 00:00:26,120] 你可能有100萬條什麼的就可以開始搞了
[00:00:26,120 -> 00:00:28,160] 對,他那個東西
[00:00:00,000 -> 00:00:06,200] 很重要的一點就是我們一直在說中美未來在AI上的競爭優勢
[00:00:06,200 -> 00:00:08,880] 然後大家會說中國的競爭優勢非常強
[00:00:08,880 -> 00:00:12,480] 因為中國有更好的數據,更多的數據,更開放的數據
[00:00:12,480 -> 00:00:15,199] 中國的數據更開放嗎?
[00:00:15,199 -> 00:00:19,640] 不是啊,就是大家你可以拿到更多的關於個人的數據
[00:00:19,640 -> 00:00:21,960] 就是你所說的那個是吧
[00:00:21,960 -> 00:00:26,120] 就是access更多的數據,不是更這個
[00:00:00,000 -> 00:00:02,819] 或者说更多
[00:00:02,819 -> 00:00:04,940] 但是如果数据
[00:00:04,940 -> 00:00:08,140] 所以我想知道这个数据到底有多重要
[00:00:08,140 -> 00:00:11,220] 数据是最重要的
[00:00:11,220 -> 00:00:12,859] 我觉得比算力重要很多很多
[00:00:12,859 -> 00:00:14,980] 数量更重要还是维度更重要
[00:00:14,980 -> 00:00:17,179] 都重要
[00:00:17,179 -> 00:00:19,859] 但是它的数量达到一定以后可能就没那么重要
[00:00:19,859 -> 00:00:22,940] 比如Google十一条跟两一条差别可能没有那么大
[00:00:22,940 -> 00:00:23,820] 或者Query的话
[00:00:23,820 -> 00:00:25,100] 好吧
[00:00:25,100 -> 00:00:28,539] 我们这基本上先把内容就讲到这吧
[00:00:00,000 -> 00:00:01,700] 我覺得以後有機會的話
[00:00:01,700 -> 00:00:05,120] 還想再請你第一把人工智能和機器學習
[00:00:05,120 -> 00:00:06,200] 生物學習的歷史
[00:00:06,200 -> 00:00:07,879] 包括幾篇重要的論文
[00:00:07,879 -> 00:00:11,119] 重要的人幫我們講一下
[00:00:11,119 -> 00:00:14,199] 第二個就是可能把這個模型本身
[00:00:14,199 -> 00:00:17,000] 就比如說到底什麼是相量機
[00:00:17,000 -> 00:00:18,079] 什麼是智能相量機
[00:00:18,079 -> 00:00:19,460] 什麼是Random Forest
[00:00:19,460 -> 00:00:21,239] 什麼是這個深陷網絡
[00:00:21,239 -> 00:00:24,000] 大概講一下和他們常見的應用的是什麼
[00:00:24,000 -> 00:00:26,879] 可以看大家的feedback
[00:00:26,879 -> 00:00:27,879] 如果有興趣的話
[00:00:00,000 -> 00:00:02,879] 還可以講計算機科學江湖史
[00:00:02,879 -> 00:00:04,280] 哦
[00:00:04,280 -> 00:00:06,480] 就是幾個大腦之間的
[00:00:06,480 -> 00:00:07,280] 和大腸之間的
[00:00:07,280 -> 00:00:08,320] 醫院情仇
[00:00:08,320 -> 00:00:08,919] 對
[00:00:08,919 -> 00:00:10,279] 根植啊什麼的
[00:00:10,279 -> 00:00:10,599] 可以
[00:00:10,599 -> 00:00:12,320] 是人的地方就有江湖
[00:00:12,320 -> 00:00:12,720] 對
[00:00:13,039 -> 00:00:13,679] 好的
[00:00:13,919 -> 00:00:14,800] 那多謝了
[00:00:15,240 -> 00:00:16,120] 好好好
[00:00:16,120 -> 00:00:17,800] 謝謝孫老闆的邀請
[00:00:17,800 -> 00:00:18,320] 好
[00:00:18,600 -> 00:00:19,199] 拜拜
[00:00:19,199 -> 00:00:20,399] 好好拜拜
