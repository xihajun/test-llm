[00:00:00,000 -> 00:00:02,160] Hello大家好欢迎回到Code with 雷正
[00:00:02,160 -> 00:00:04,400] 今天我们聊一下为什么复制一个
[00:00:04,400 -> 00:00:07,280] XGPT可能不像大家想的那么简单
[00:00:07,559 -> 00:00:10,320] 其实大家也看到了很多XGPT的复制产品
[00:00:10,560 -> 00:00:11,759] 国内国外的都有
[00:00:11,960 -> 00:00:13,599] 国内的我就不点名了
[00:00:13,599 -> 00:00:15,720] 但是不管是大公司还是小公司
[00:00:15,720 -> 00:00:19,760] 其实都有很多复制XGPT形式的这样的产品
[00:00:19,920 -> 00:00:22,199] 国外最著名的就是谷歌的BART
[00:00:22,199 -> 00:00:24,280] 然后也有很多开源的模型
[00:00:24,320 -> 00:00:28,280] 这些产品他们或多或少的也会去宣称自己
[00:00:28,280 -> 00:00:32,000] 在某些任务上是比XGPT的效果更好
[00:00:32,039 -> 00:00:33,560] 最近还有一个开源模型
[00:00:33,600 -> 00:00:35,920] 说自己是GPT-4认证的
[00:00:35,920 -> 00:00:39,799] 达到了3.5的XGPT的80%的水平
[00:00:40,000 -> 00:00:42,079] 这些东西就很扯
[00:00:42,079 -> 00:00:44,159] 因为大家真的去试用以后
[00:00:44,159 -> 00:00:47,079] 发现其实那些模型根本就无法使用
[00:00:47,079 -> 00:00:49,240] 他们空有一个对话的生成方式
[00:00:49,240 -> 00:00:51,280] 可是底层大模型的能力天差地别
[00:00:51,280 -> 00:00:53,560] 就表现在虽然都是在说话
[00:00:53,560 -> 00:00:55,960] 但是一个是正常人
[00:00:55,960 -> 00:00:58,439] 或者说优秀的有理解能力的人在说话
[00:00:58,479 -> 00:01:00,079] 一个就像是智障在说话
[00:01:00,119 -> 00:01:02,159] 那你跟一个智障对话有什么帮助呢
[00:01:02,159 -> 00:01:03,320] 肯定是没有帮助的
[00:01:03,479 -> 00:01:05,319] 我也跟业内的同学聊过
[00:01:05,319 -> 00:01:09,359] 就是你想做一个generative的large language model
[00:01:09,359 -> 00:01:12,120] 用对话的形式去生成一篇对话
[00:01:12,120 -> 00:01:14,200] 其实这个难度也没有那么大
[00:01:14,200 -> 00:01:16,200] 就是很多团队
[00:01:16,200 -> 00:01:20,359] 然后花个几百万的人民币的钱都可以做到
[00:01:20,359 -> 00:01:22,760] 可是想要做到GPT 3.5这样一个水平
[00:01:22,760 -> 00:01:23,959] 那就超级超级难了
[00:01:23,959 -> 00:01:29,799] 那我们这期视频就聊一下为什么做一个GPT 3.5这样的水平的大模型是这么难的一件事
[00:01:29,799 -> 00:01:35,200] 首先我们要知道GPT 3.5它没有一些特别的秘籍
[00:01:35,200 -> 00:01:38,760] 就是它不是说我藏着掖着一个模型的饭食
[00:01:38,760 -> 00:01:40,599] 其实它的命名都已经很清楚了
[00:01:40,599 -> 00:01:43,400] 就是Generative Pre-trained Transformers
[00:01:43,400 -> 00:01:46,680] 是一个基于Transformers的这样一个大模型
[00:01:46,680 -> 00:01:49,879] 它也有各种各样的论文和各种各样的资料出来
[00:01:49,879 -> 00:01:52,439] 大家大概知道它的参数量大概是什么样子的
[00:01:52,439 -> 00:01:55,200] 和它在训练的过程中有做什么
[00:01:55,200 -> 00:01:57,400] 可是在这种情况下还是很难复制
[00:01:57,400 -> 00:01:58,079] 为什么呢
[00:01:58,079 -> 00:02:00,400] 因为这是一个复杂的工程问题
[00:02:00,400 -> 00:02:01,760] 工程问题的难度
[00:02:01,760 -> 00:02:04,040] 大家在日常生活中可能很难感知到
[00:02:04,040 -> 00:02:05,500] 所以说我们经常就忽略了
[00:02:05,500 -> 00:02:09,599] 但是我們知道我們國家經常被卡脖子的這些科技
[00:02:09,599 -> 00:02:11,199] 就所謂的硬科技啊
[00:02:11,199 -> 00:02:13,000] 比如說大飛機的引擎
[00:02:13,000 -> 00:02:15,000] 比如說一些特殊的材料
[00:02:15,000 -> 00:02:16,400] 比如說芯片
[00:02:16,400 -> 00:02:18,900] 這都是吃工程能力的
[00:02:18,900 -> 00:02:21,099] 就是我們其實知道引擎的原理是什麼
[00:02:21,099 -> 00:02:22,300] 我們知道芯片的原理是什麼
[00:02:22,300 -> 00:02:24,400] 我們知道了配方我們也做不出來
[00:02:24,400 -> 00:02:26,840] 就是因為它中間需要很多的工程积累
[00:02:27,000 -> 00:02:29,120] 我这还有一个更形象的故事
[00:02:29,280 -> 00:02:32,199] 就是大家如果看我之前有采访过我一个学长
[00:02:32,439 -> 00:02:34,360] 他在英特尔做5nm芯片
[00:02:34,479 -> 00:02:36,560] 我那个时候就在他家他跟我聊天
[00:02:36,599 -> 00:02:37,360] 跟我聊天的时候
[00:02:37,360 -> 00:02:39,080] 他那个时候就在抱怨说
[00:02:39,080 -> 00:02:42,000] 自己虽然在这个5nm的实验室里边工作
[00:02:42,039 -> 00:02:45,400] 可是工作的内容也不是特别有技术含量
[00:02:45,400 -> 00:02:47,560] 他做的这些事情觉得一个初中生也可以做
[00:02:47,560 -> 00:02:48,840] 我说为什么
[00:02:48,840 -> 00:02:51,080] 就是你给我讲讲你的工作内容到底是什么吧
[00:02:51,080 -> 00:02:55,000] 他就说其实他每天就是拿到一个担心龟
[00:02:55,000 -> 00:02:58,159] 实验室里会生长出来这种结晶的担心龟
[00:02:58,159 -> 00:03:00,360] 然后去做各种各样的实验
[00:03:00,360 -> 00:03:01,759] 根据实验的结果
[00:03:01,759 -> 00:03:04,280] 再去决定下一步的实验怎么样子去迭代
[00:03:04,280 -> 00:03:06,599] 可是这些实验结果本身也没什么复杂的
[00:03:06,599 -> 00:03:08,900] 他只要积累一些工程的knowhow就好了
[00:03:08,900 -> 00:03:13,199] 一个就是聪明的初中学历的工程师过来完全可以做
[00:03:13,199 -> 00:03:14,800] 他是康奈尔的一个化学博士
[00:03:14,800 -> 00:03:18,300] 他觉得他在博士中学的这些知识其实是完全用不上的
[00:03:18,300 -> 00:03:19,800] 听完了以后我就问他说
[00:03:19,800 -> 00:03:21,199] 两个问题啊
[00:03:21,199 -> 00:03:25,000] 第一个你做这个单轻硅需要多少个步骤
[00:03:25,000 -> 00:03:27,800] 第二你做一片单轻硅需要多少钱
[00:03:27,800 -> 00:03:30,879] 他说25片单轻硅因为它的要求比较高
[00:03:30,879 -> 00:03:33,319] 纯度要求是很高和很固定的
[00:03:33,319 -> 00:03:36,919] 所以说做这么一个单轻硅的成本
[00:03:36,919 -> 00:03:40,400] 对于英特尔这样一个非常有工程积累的企业来说
[00:03:40,400 -> 00:03:42,240] 大概25片是100万美元
[00:03:42,240 -> 00:03:45,360] 然后做这么一个单轻硅的步骤大概是几百步到1000步
[00:03:45,400 -> 00:03:48,319] 如果这里边的一步出了一点点的小问题
[00:03:48,319 -> 00:03:51,000] 最后的良率就会受到很大的影响
[00:03:51,120 -> 00:03:52,759] 所以说你叠加起来的话
[00:03:52,960 -> 00:03:54,879] 你的技术积累稍稍差了一点
[00:03:54,919 -> 00:03:58,120] 可能你的良品率就是人家的1 1 10
[00:03:58,120 -> 00:03:59,319] 或者说1%
[00:03:59,599 -> 00:04:02,680] Intel花100万美元可以做出来25片
[00:04:02,719 -> 00:04:03,960] 你可能就要花1000万
[00:04:03,960 -> 00:04:05,680] 1亿美元才能做出来25片
[00:04:05,680 -> 00:04:07,199] 那你就根本没法做了 对吧
[00:04:07,199 -> 00:04:09,800] 所以说我就说OK
[00:04:09,800 -> 00:04:13,680] 那你的这个看似很简单的这些知识
[00:04:13,680 -> 00:04:17,279] 其实是几千万美元的成本烧出来的
[00:04:17,279 -> 00:04:19,959] 那回到大模型也是这样子
[00:04:19,959 -> 00:04:21,279] 我们模型的训练
[00:04:21,439 -> 00:04:23,680] 包括这个数据的积累清洗
[00:04:23,800 -> 00:04:25,439] 需要很贵很贵的成本更关键的是这里的学习成本就是你大模型�训练啊包括这个数据的积累啊清洗啊需要很贵很贵的成本
[00:04:25,439 -> 00:04:27,240] 更关键的是这里的学习成本
[00:04:27,639 -> 00:04:29,319] 就是你大模型迭代一次的话
[00:04:29,319 -> 00:04:30,920] 可能要一个月到两个月
[00:04:31,120 -> 00:04:34,639] 所以说哪怕对于谷歌这样发明了Transformer
[00:04:34,639 -> 00:04:35,319] 发明了T5
[00:04:35,319 -> 00:04:37,279] 发明了Scetella这样的一个公司
[00:04:37,399 -> 00:04:39,800] 他也觉得自己乐观估计
[00:04:39,959 -> 00:04:42,399] 如果一一切都非常非常顺利的话
[00:04:42,680 -> 00:04:45,240] 怎么样也要花一年才能复现出来
[00:04:45,240 -> 00:04:46,959] GPT-3.5的那个能力
[00:04:47,079 -> 00:04:48,800] GPT-4就更久了
[00:04:48,959 -> 00:04:49,639] 在这种情况下
[00:04:49,639 -> 00:04:51,240] 我实在是不知道为什么
[00:04:51,279 -> 00:04:52,399] 有那么多人有自信
[00:04:52,399 -> 00:04:55,560] 觉得我们跟OpenAI差距很近
[00:04:55,680 -> 00:04:57,680] 其实人家的工程人才的密度
[00:04:57,680 -> 00:04:58,839] 是非常非常高的
[00:04:58,839 -> 00:05:01,439] 他们的工程的思路
[00:05:01,439 -> 00:05:02,759] 他们的决策体系
[00:05:02,759 -> 00:05:04,920] 他们的整个迭代机制
[00:05:05,000 -> 00:05:05,040] 都已经很优化了所以在我们各方面都落后的情况下工程的思路他们的决策体系他们的整个迭代机制
[00:05:06,399 -> 00:05:08,720] 都已经很优化了所以在我们各方面都落后的情况下
[00:05:08,720 -> 00:05:11,759] 如果我们再不认识到这里边的巨大差距
[00:05:11,759 -> 00:05:13,800] 那我们是不可能赶上这个差距的
[00:05:13,879 -> 00:05:15,319] 意识到这里的巨大差距
[00:05:15,319 -> 00:05:17,639] 就是去尊重工程
[00:05:17,680 -> 00:05:19,279] 尊重工程的knowhow
[00:05:19,279 -> 00:05:20,839] 是需要很强的积累的
[00:05:20,879 -> 00:05:22,800] 它是要一步一步的去做出来的
[00:05:22,800 -> 00:05:24,399] 而不能一步登天
[00:05:24,560 -> 00:05:25,720] 那这儿再稍稍说一下
[00:05:25,720 -> 00:05:28,040] 就是为什么我们之前的模型不是这样子
[00:05:28,040 -> 00:05:30,079] 就是之前的机器学习模型
[00:05:30,120 -> 00:05:32,160] 好像大家看到中美没什么差距的吧
[00:05:32,199 -> 00:05:34,959] 这是因为机器之前的模型全都是开源的
[00:05:34,959 -> 00:05:38,920] 而且那个模型本身不是一个特别有门槛的东西
[00:05:38,920 -> 00:05:40,759] 尤其是开源了之后你拿去用
[00:05:40,759 -> 00:05:41,600] 谁都可以调包
[00:05:41,600 -> 00:05:43,000] 人都把代码都给你了
[00:05:43,040 -> 00:05:46,480] 你的壁垒其实是在你把它跟业务的结合
[00:05:46,480 -> 00:05:47,600] 和你的数据上
[00:05:47,639 -> 00:05:49,680] 那我们又恰好收集了很多数据
[00:05:49,720 -> 00:05:52,519] 所以说显得好像我们的AI能力
[00:05:52,519 -> 00:05:54,399] 和美国是在一个水平线
[00:05:54,480 -> 00:05:57,079] 但是大家要知道背后的这个脑子
[00:05:57,120 -> 00:05:59,240] 基础科研能力以及工程能力
[00:05:59,279 -> 00:06:00,839] 是有很大差距的
[00:06:00,879 -> 00:06:03,360] 尤其是我们现在连谷歌都跟
[00:06:03,360 -> 00:06:04,720] OpenAI的工程能力
[00:06:04,720 -> 00:06:06,360] 有这么大差距的情况下大家再不我们现在连谷歌都跟OpenAI的工程能力有这么大差距的情况下
[00:06:06,360 -> 00:06:08,560] 大家再不认真对待这件事的话
[00:06:08,560 -> 00:06:10,040] 那我觉得是没什么希望的
[00:06:10,040 -> 00:06:13,439] 我们认真对待这件事的话去一步一步的去补
[00:06:13,439 -> 00:06:16,560] 从清理数据开始 把清理数据这件事搞清楚
[00:06:16,560 -> 00:06:18,920] 然后再去把怎么样子用大模型
[00:06:18,920 -> 00:06:20,439] 怎么样子去调度好算力
[00:06:20,439 -> 00:06:22,120] 然后在这里边怎么样子快速迭代
[00:06:22,120 -> 00:06:23,480] 怎么样子早期失措等等等等
[00:06:23,480 -> 00:06:25,300] 一系列的工程问题全都解决了以后
[00:06:25,300 -> 00:06:26,399] 我觉得才有希望
[00:06:26,399 -> 00:06:30,300] 不然的话就会沦为像材料科学
[00:06:30,300 -> 00:06:32,199] 引擎和芯片这样子
[00:06:32,199 -> 00:06:33,800] 我们天天说被人卡脖子
[00:06:33,800 -> 00:06:35,000] 我们烧了无数的钱
[00:06:35,000 -> 00:06:36,899] 最后离别人的差距不是越来越近
[00:06:36,899 -> 00:06:37,800] 而是越来越远
[00:06:37,800 -> 00:06:39,199] 好的这期视频就到这儿
[00:06:39,199 -> 00:06:41,300] 希望可以帮大家澄清这样一个误会
[00:06:41,300 -> 00:06:42,500] 那我们下期再见
[00:06:42,500 -> 00:06:43,000] 拜拜
