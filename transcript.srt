1
00:00:00,000 --> 00:00:03,919
拆GPT的出現對我來說無疑是狗突然會說人話

2
00:00:03,919 --> 00:00:05,799
而且這件事情是Nubian已經做到的

3
00:00:05,799 --> 00:00:07,280
拆GPT只是沒有把它開放出來

4
00:00:07,280 --> 00:00:10,039
如果你的算力和你的信息明顯會不如拆GPT

5
00:00:10,039 --> 00:00:11,800
你的態度然後你的ego

6
00:00:11,800 --> 00:00:16,000
然後你的這個心地你的理性都不如拆GPT

7
00:00:16,000 --> 00:00:18,920
你的判斷力和你的思維能力再不如拆GPT的話

8
00:00:18,920 --> 00:00:19,920
那你還剩下什麼呢

9
00:00:19,920 --> 00:00:21,519
大家好歡迎回到課堂筆電政

10
00:00:21,519 --> 00:00:23,359
今天我們聊拆GPT

11
00:00:23,359 --> 00:00:26,039
已經有很多小夥伴忽悠我去聊下GPT了

12
00:00:26,039 --> 00:00:27,960
其實我寫了一個文檔

13
00:00:27,960 --> 00:00:29,600
這個文檔我在一直更新

14
00:00:00,000 --> 00:00:02,399
现在我上次看的时候已经有18000次了

15
00:00:02,399 --> 00:00:05,200
把我对拆机配器的各种各样的理解

16
00:00:05,440 --> 00:00:07,000
尤其是对技术的理解

17
00:00:07,000 --> 00:00:09,000
它到底是什么能颠覆什么

18
00:00:09,160 --> 00:00:10,199
怎么应用等等

19
00:00:10,199 --> 00:00:11,960
全都写在了那个文档里边

20
00:00:12,119 --> 00:00:14,320
我在这里把这个文档的RM放在这

21
00:00:14,320 --> 00:00:16,600
欢迎大家去看也欢迎大家去收藏

22
00:00:16,879 --> 00:00:19,280
那个文档我会提出非常强烈的观点

23
00:00:19,280 --> 00:00:20,800
我不会说那些正确的废话

24
00:00:20,800 --> 00:00:22,839
我其实说的是非常强烈的观点

25
00:00:22,839 --> 00:00:24,640
它到底有什么不一样的能力

26
00:00:24,920 --> 00:00:26,879
和之前的人工智能有什么不一样

27
00:00:27,160 --> 00:00:28,399
它到底能颠覆什么

28
00:00:00,000 --> 00:00:01,720
为什么能颠覆这些东西

29
00:00:01,760 --> 00:00:03,200
国产大模型到底有没有前途

30
00:00:03,200 --> 00:00:05,320
我也会是有一个非常明确的结论

31
00:00:05,559 --> 00:00:08,320
但是正因为有这些非常强烈的观点

32
00:00:08,359 --> 00:00:10,560
我非常清楚这些观点的来源

33
00:00:10,599 --> 00:00:13,720
所以说当我遇到了一个我没有见过的东西

34
00:00:13,720 --> 00:00:15,320
或者说当我知道我中间的一个

35
00:00:15,320 --> 00:00:16,679
factor被改变的时候

36
00:00:16,719 --> 00:00:19,039
这些观点都很有可能是变化的

37
00:00:19,199 --> 00:00:21,960
这就叫所谓的strong opinions weakly held

38
00:00:22,000 --> 00:00:24,600
总之那个是我推荐大家去看的

39
00:00:24,839 --> 00:00:27,719
我觉得聊拆这边是一个很长的话题

40
00:00:27,760 --> 00:00:29,960
所以说我们今天就简单上一下结论

41
00:00:00,000 --> 00:00:02,399
如果你是一个结论党的话到这就可以结束了

42
00:00:02,399 --> 00:00:05,400
是我聊完这些结论以后会马上去讲一下

43
00:00:05,400 --> 00:00:08,699
为什么做一个结论党对于自己的认知是没有帮助的

44
00:00:08,699 --> 00:00:10,699
那好我们直接就上结论吧

45
00:00:10,699 --> 00:00:15,000
第一,Chai GPT和过去的Machine Learning是有一个极大的范式不同的

46
00:00:15,000 --> 00:00:17,800
过去的Machine Learning只能寻找对应关系

47
00:00:17,800 --> 00:00:19,899
而Chai GPT能理解

48
00:00:19,899 --> 00:00:21,699
如果用一个例子的话

49
00:00:21,699 --> 00:00:27,199
是2017年朱松纯教授讲人工智能与智能的关系的时候

50
00:00:00,000 --> 00:00:03,080
提出來的一個鸚鵡和烏鴉的例子

51
00:00:03,080 --> 00:00:05,919
鸚鵡只會模仿人說話

52
00:00:05,919 --> 00:00:07,919
但是它其實是在模仿這些話

53
00:00:07,919 --> 00:00:10,080
它根本就不知道這些話什麼意思

54
00:00:10,080 --> 00:00:13,599
但是烏鴉是對這個世界有理解有思考的

55
00:00:13,599 --> 00:00:15,800
這其實是一個很神奇的比喻

56
00:00:15,800 --> 00:00:18,440
而且在那篇五年前的文章裡邊

57
00:00:18,440 --> 00:00:20,359
現在可能快六年前的文章裡邊

58
00:00:20,359 --> 00:00:21,719
朱松成教授就說

59
00:00:21,719 --> 00:00:23,600
我們所有的人工智能學者

60
00:00:23,600 --> 00:00:26,879
應該以烏鴉為圖騰去尋找烏鴉的智能

61
00:00:26,879 --> 00:00:28,440
今天Chachapiti出來了

62
00:00:00,000 --> 00:00:01,919
它就是具备了无压的智能

63
00:00:01,919 --> 00:00:03,799
这在我看来是非常非常颠覆

64
00:00:03,799 --> 00:00:05,240
和非常非常不可想象的

65
00:00:05,240 --> 00:00:07,960
因为我之前的工作跟Machine Learning是太相关了

66
00:00:07,960 --> 00:00:10,199
我自己的频道还有那么多视频去讲Machine Learning

67
00:00:10,199 --> 00:00:13,119
尤其是讲Machine Learning在这里边的Limitation

68
00:00:13,119 --> 00:00:16,000
因为它只能做寻找对应关系这件事

69
00:00:16,000 --> 00:00:16,879
所以

70
00:00:16,879 --> 00:00:19,399
XGBT的出现对我来说无疑是

71
00:00:19,399 --> 00:00:21,320
狗突然会说人话了

72
00:00:21,320 --> 00:00:22,719
就是我真的我看到XGBT

73
00:00:22,719 --> 00:00:24,519
我就觉得人工智能有理解能力

74
00:00:24,519 --> 00:00:26,519
就好像狗会说人话一样

75
00:00:26,519 --> 00:00:28,480
但是我觉得我们的人类就是这样子

76
00:00:00,000 --> 00:00:01,600
今天听到的狗说人话

77
00:00:01,600 --> 00:00:03,520
可能三天后也觉得这是一件

78
00:00:03,520 --> 00:00:04,519
习以为常的事情了

79
00:00:04,519 --> 00:00:05,519
不就是

80
00:00:05,519 --> 00:00:07,320
这是一个非常非常颠覆的事情

81
00:00:07,320 --> 00:00:10,279
我回头会专门出文章去讲这些

82
00:00:10,279 --> 00:00:11,640
我今天就只把结论放上来

83
00:00:11,640 --> 00:00:12,679
大家不用着急

84
00:00:12,679 --> 00:00:14,759
当然了最好是看我的那个文章

85
00:00:14,759 --> 00:00:15,359
好

86
00:00:16,039 --> 00:00:17,120
第二就是Chachabitty

87
00:00:17,120 --> 00:00:18,559
它会颠覆什么样的工作

88
00:00:18,559 --> 00:00:20,640
它会颠覆所有搬砖类的工作

89
00:00:20,640 --> 00:00:22,760
除了真正的搬砖它不能颠覆

90
00:00:22,760 --> 00:00:24,879
但是如果说你是一个在电脑前面

91
00:00:24,879 --> 00:00:26,559
你形容你的工作是搬砖

92
00:00:26,559 --> 00:00:29,239
那Chachabitty大概率是会取代你的工作的

93
00:00:00,000 --> 00:00:02,799
取代这样的搬砖类的工作可能有一个好处

94
00:00:02,799 --> 00:00:05,400
就是它可以极大地减少内卷

95
00:00:05,400 --> 00:00:06,200
什么意思呢

96
00:00:06,200 --> 00:00:08,320
因为你搬砖这个东西就很明显

97
00:00:08,320 --> 00:00:09,679
很容易被其他人取代

98
00:00:09,679 --> 00:00:12,560
那大家在搬砖类的工作上就只能内卷

99
00:00:12,560 --> 00:00:13,560
只能拼996

100
00:00:13,560 --> 00:00:14,560
那你现在拼不了

101
00:00:14,560 --> 00:00:16,640
拼996肯定是拼不过拆GPT的

102
00:00:16,640 --> 00:00:18,839
那大家会努力的去思考

103
00:00:18,839 --> 00:00:20,320
如果我不内卷还可以干嘛

104
00:00:20,320 --> 00:00:23,000
所以说它取代搬砖减少内卷

105
00:00:23,000 --> 00:00:26,199
这是它会对人类工作的颠覆

106
00:00:26,199 --> 00:00:28,160
就是它不是颠覆一类工作

107
00:00:28,160 --> 00:00:29,239
只要你是搬砖类

108
00:00:00,000 --> 00:00:01,320
它几乎都可以颠覆的

109
00:00:01,320 --> 00:00:04,320
第三个是这个讲到了刚才

110
00:00:04,320 --> 00:00:05,280
Touch TV的颠覆

111
00:00:05,280 --> 00:00:07,160
接下来我们就讲它怎么颠覆

112
00:00:07,160 --> 00:00:10,199
或者说OpenAI开放了什么是最重要的

113
00:00:10,199 --> 00:00:13,720
OpenAI很明显是对这里边非常谨慎小心

114
00:00:13,720 --> 00:00:16,679
它现在不开放很重要的能力

115
00:00:16,679 --> 00:00:18,600
在我看来不是因为它不能做

116
00:00:18,600 --> 00:00:20,320
他们的工程能力是非常强的

117
00:00:20,320 --> 00:00:21,719
它想做到这样的开放

118
00:00:21,719 --> 00:00:23,199
可能一晚上就可以做到了

119
00:00:23,199 --> 00:00:25,839
当然它是担心这样的开放

120
00:00:25,839 --> 00:00:28,600
对人类社会所造成的冲击而没有开放

121
00:00:00,000 --> 00:00:01,560
但是迟早也会开放的

122
00:00:01,840 --> 00:00:04,120
它开放的就是prompting的长度

123
00:00:04,519 --> 00:00:06,839
尤其是记忆你prompting的长度

124
00:00:06,960 --> 00:00:09,599
以及它调用其他工具的接口

125
00:00:09,720 --> 00:00:10,320
什么意思呢

126
00:00:10,320 --> 00:00:12,759
大家其实要知道就是

127
00:00:12,759 --> 00:00:15,000
New Beam它并不是什么

128
00:00:15,000 --> 00:00:17,679
拆GPT背后的模型去有什么更改

129
00:00:17,679 --> 00:00:19,719
而是GPT 3.5放在那儿

130
00:00:19,719 --> 00:00:21,079
模型参数从来不变

131
00:00:21,120 --> 00:00:22,800
你的这些东西也从来没有进到

132
00:00:22,800 --> 00:00:24,839
GPT 3.5的这个参数里面

133
00:00:25,000 --> 00:00:27,239
然后我们在这拆GPT的基础之上

134
00:00:27,239 --> 00:00:29,160
给它搜索的能力

135
00:00:00,000 --> 00:00:02,480
然后再给了他一堆instruction

136
00:00:02,480 --> 00:00:04,679
给了他一堆instruct prompting

137
00:00:04,679 --> 00:00:06,599
去教他怎么去使用搜索

138
00:00:06,599 --> 00:00:08,439
然后你的搜索什么是好的搜索

139
00:00:08,439 --> 00:00:10,400
什么是不好的搜索的情况下

140
00:00:10,400 --> 00:00:12,599
ChatGPT学会了使用搜索

141
00:00:12,599 --> 00:00:13,839
然后就变成了NeoBing

142
00:00:13,839 --> 00:00:15,199
大家应该有感觉到这种关系

143
00:00:15,199 --> 00:00:16,800
所以说他只要把这块

144
00:00:16,800 --> 00:00:19,480
NeoBing和ChatGPT之间的这些东西开放出来

145
00:00:19,480 --> 00:00:20,960
我可以去教他一堆话

146
00:00:20,960 --> 00:00:21,839
让他记住

147
00:00:21,839 --> 00:00:23,879
并且让他可以调用数据

148
00:00:23,879 --> 00:00:25,039
或者调用搜索

149
00:00:25,039 --> 00:00:26,160
调用其他的能力

150
00:00:26,160 --> 00:00:28,879
尤其是使用自然语言的方式去调用的情况下

151
00:00:00,000 --> 00:00:04,160
它就已经可以100%的颠覆很多很多的东西了

152
00:00:04,160 --> 00:00:05,200
我举一个例子吧

153
00:00:05,200 --> 00:00:08,160
假设你是一个非常厉害的程序员

154
00:00:08,160 --> 00:00:10,960
你现在看XGBT编出来的东西还有很多问题

155
00:00:10,960 --> 00:00:13,759
但是已经有一些地方可以用了

156
00:00:13,759 --> 00:00:17,559
这个时候你给XGBT开放了所有的代码

157
00:00:17,559 --> 00:00:19,679
让他可以去搜索这里的所有代码

158
00:00:19,679 --> 00:00:23,039
然后你让XGBT能记住你一万句话

159
00:00:23,039 --> 00:00:25,039
写着一万句话的全中可调

160
00:00:25,039 --> 00:00:28,399
你可以去教XGBT一万句话

161
00:00:00,000 --> 00:00:02,839
那你想想这一万句话交出来的这个XGBT

162
00:00:02,839 --> 00:00:04,480
它的编程能力会有多强

163
00:00:04,480 --> 00:00:07,120
你想想你用一万句话如果去教一个人的话

164
00:00:07,120 --> 00:00:08,679
那个人会变成什么样子

165
00:00:08,679 --> 00:00:11,720
XGBT又有理性又有理解

166
00:00:11,720 --> 00:00:15,679
然后又有这个强大的算力和无尽的知识

167
00:00:15,679 --> 00:00:17,480
然后他去学真的去听

168
00:00:17,480 --> 00:00:19,280
你只要教他什么他就学什么

169
00:00:19,280 --> 00:00:22,079
这一万句话之后他会变成一个多么强大的程序员

170
00:00:22,079 --> 00:00:24,160
而且这件事情是NewBin已经做到的

171
00:00:24,160 --> 00:00:25,920
XGBT只是没有把它开放出来而已

172
00:00:25,920 --> 00:00:28,440
讲完它的开放我们就要回归它的本质

173
00:00:28,440 --> 00:00:29,960
它到底是一个什么东西

174
00:00:00,000 --> 00:00:06,160
ChatGPT是一个人类调用算力和数据接近最完美的形态

175
00:00:06,160 --> 00:00:07,160
我再重复一遍

176
00:00:07,160 --> 00:00:12,919
ChatGPT是人类调用算力和数据接近最完美的形态

177
00:00:12,919 --> 00:00:14,480
其实这个观点一点都不新鲜

178
00:00:14,480 --> 00:00:17,920
就是很多人说ChatGPT是自然语言编程机

179
00:00:17,920 --> 00:00:19,600
或者自然语言计算机

180
00:00:19,600 --> 00:00:22,600
我们的计算机发展史其实是算力在进步

181
00:00:22,600 --> 00:00:24,839
数据在增加和进步

182
00:00:24,839 --> 00:00:25,839
就不断的被生成

183
00:00:25,839 --> 00:00:28,280
比如说你在抖音上刷视频的数据

184
00:00:28,280 --> 00:00:29,480
视频本身是数据

185
00:00:00,000 --> 00:00:01,720
你刷的行为也是数据

186
00:00:01,720 --> 00:00:03,200
我们积累了很多数据以后

187
00:00:03,200 --> 00:00:05,200
就对这个世界了解的越来越多

188
00:00:05,200 --> 00:00:06,040
算力越来越多

189
00:00:06,040 --> 00:00:08,279
我们就可以去更好的去利用这些

190
00:00:08,279 --> 00:00:09,800
更好的去算很多东西

191
00:00:10,480 --> 00:00:11,480
之前的编程

192
00:00:11,480 --> 00:00:12,800
零和一机器

193
00:00:12,800 --> 00:00:14,439
会编这些东西我都不说了

194
00:00:14,439 --> 00:00:15,480
到了高级语言

195
00:00:15,480 --> 00:00:16,800
但是其实在网上还有

196
00:00:16,800 --> 00:00:19,160
比如说虚拟机是对硬件的抽象

197
00:00:19,160 --> 00:00:21,640
云服务是对整个Infra的抽象

198
00:00:21,640 --> 00:00:24,559
API又是对背后的Infra

199
00:00:24,559 --> 00:00:27,839
加上很多Computing和存储的抽象

200
00:00:27,839 --> 00:00:28,960
其实我们用API

201
00:00:00,000 --> 00:00:01,080
已经可以解决很多

202
00:00:01,080 --> 00:00:03,960
尤其 serverless 的 API 已经可以解决很多东西了

203
00:00:03,960 --> 00:00:08,839
那接下来 XGBT 也就是对所有的计算的过程

204
00:00:08,839 --> 00:00:11,199
调用 IT 的这个过程的终极抽象

205
00:00:11,199 --> 00:00:13,160
那你就跟 XGBT 经常

206
00:00:13,160 --> 00:00:14,759
你现在还有很多步骤

207
00:00:14,759 --> 00:00:17,000
你跟他说我要写一段这个

208
00:00:17,000 --> 00:00:18,760
你告诉我那个公式是什么样子

209
00:00:18,760 --> 00:00:20,839
他已经可以很好的帮助你这一点了

210
00:00:20,839 --> 00:00:21,719
但是到最后

211
00:00:21,719 --> 00:00:23,879
如果 XGBT 真的去理解这个系统

212
00:00:23,879 --> 00:00:24,879
理解这些数据库

213
00:00:24,879 --> 00:00:26,559
你就可以跟他直接要一个结果

214
00:00:26,559 --> 00:00:27,800
他可以给你一个结果

215
00:00:00,000 --> 00:00:04,200
像我们所谓很让我们难受的这些 SQL Market 取数的工作

216
00:00:04,200 --> 00:00:07,000
Chai GPT 真的可以很好的就完成它

217
00:00:07,000 --> 00:00:13,199
所以说记住 Chai GPT 是人类调用算力和存储的最终极形态

218
00:00:13,199 --> 00:00:15,439
最后一个问题就是 Chai GPT 有多难模仿

219
00:00:15,439 --> 00:00:17,399
其实这个问题是两个问题

220
00:00:17,399 --> 00:00:19,399
我觉得 Chai GPT 我们一定要理解

221
00:00:19,399 --> 00:00:23,000
GPT 3.5 是拥有理解能力的大语言模型

222
00:00:23,000 --> 00:00:25,000
它是最难模仿的

223
00:00:25,000 --> 00:00:29,480
它具有的理解能力是我们现在很多人都不知道怎么发生

224
00:00:00,000 --> 00:00:01,800
但是它就发生了的东西

225
00:00:01,800 --> 00:00:03,279
文章里有一些猜想

226
00:00:03,279 --> 00:00:05,360
这里就不展开了

227
00:00:05,360 --> 00:00:07,280
接下来比较难的东西是什么

228
00:00:07,280 --> 00:00:08,919
是把这个大模型

229
00:00:08,919 --> 00:00:11,160
乔教成人类喜欢的模式

230
00:00:11,160 --> 00:00:12,400
那就是他做的

231
00:00:12,400 --> 00:00:14,480
这个reinforced learning with human feedback

232
00:00:14,480 --> 00:00:17,079
RLHF的这件事情

233
00:00:17,079 --> 00:00:18,719
当然就是这个instructor范式

234
00:00:18,719 --> 00:00:19,839
然后几步对吧

235
00:00:19,839 --> 00:00:20,879
到了Chai GPT

236
00:00:20,879 --> 00:00:23,920
Chai GPT这个对话形式是很容易实现的

237
00:00:23,920 --> 00:00:25,679
所以说我们可以看到

238
00:00:25,679 --> 00:00:27,440
市面上已经有很多人

239
00:00:27,440 --> 00:00:29,199
快速的可以用一个

240
00:00:00,000 --> 00:00:02,359
不管是开源的还是自研的还是怎样的

241
00:00:02,359 --> 00:00:04,440
这个大宇元模型做一个生成式的任务

242
00:00:04,440 --> 00:00:06,240
套上这个对话机器人的形式

243
00:00:06,240 --> 00:00:08,039
就可以去跟你进行对话

244
00:00:08,039 --> 00:00:10,960
当然大家就觉得对出来这个话非常奇怪

245
00:00:10,960 --> 00:00:12,679
它背后是没有压的能力的

246
00:00:12,679 --> 00:00:15,519
我在未来的视频也会展开

247
00:00:15,519 --> 00:00:18,519
就是如何去判定一个跟你对话的机器人

248
00:00:18,519 --> 00:00:19,960
到底有没有无压的能力

249
00:00:19,960 --> 00:00:21,719
也会是一个非常重要的事情

250
00:00:22,160 --> 00:00:24,960
我今天的录制时间是3月12号

251
00:00:24,960 --> 00:00:27,239
我争取在3月16号文心盈演出来之前

252
00:00:27,239 --> 00:00:27,960
把这个发出来

253
00:00:00,000 --> 00:00:01,919
就是文心言我 fully trust

254
00:00:01,919 --> 00:00:03,520
他可以做到一个对话

255
00:00:03,520 --> 00:00:05,440
然后他这个对话也会让你觉得

256
00:00:05,440 --> 00:00:06,599
有的地方 make sense

257
00:00:06,599 --> 00:00:07,799
有的地方不 make sense

258
00:00:07,960 --> 00:00:11,599
但是其实就是一个真正的智者和一个智障

259
00:00:11,679 --> 00:00:15,000
在一开始几句话是很难发现区别的

260
00:00:15,039 --> 00:00:18,519
可是背后的智能是很难很难做出来的

261
00:00:18,760 --> 00:00:20,559
我不是说文心言是智障

262
00:00:20,559 --> 00:00:21,160
一定是智障

263
00:00:21,160 --> 00:00:24,039
但是我觉得他很有可能是一个智障

264
00:00:24,039 --> 00:00:26,120
但是模仿出来可以对话的样子

265
00:00:26,199 --> 00:00:28,679
好的我们回来继续讲这里边的复刻

266
00:00:00,000 --> 00:00:03,000
第一就是有可能已经能复刻出来了

267
00:00:03,000 --> 00:00:05,360
其他大型模型也具备理解能力了

268
00:00:05,360 --> 00:00:06,480
这个就没得可说

269
00:00:06,480 --> 00:00:07,559
第二种可能性

270
00:00:07,559 --> 00:00:09,839
而且我觉得它是我默认的可能性

271
00:00:09,839 --> 00:00:12,199
它非常可能就是它很难复刻

272
00:00:12,199 --> 00:00:15,800
它是有一个强工程能力门槛的事情

273
00:00:15,800 --> 00:00:16,800
举一个例子

274
00:00:16,800 --> 00:00:18,600
比如说我们国家的材料科学

275
00:00:18,600 --> 00:00:22,280
芯片和飞机引擎都是受限于材料科学

276
00:00:22,280 --> 00:00:24,960
那为什么材料科学这件事情就很难模仿

277
00:00:24,960 --> 00:00:26,920
因为它是一个很吃工程能力的

278
00:00:26,920 --> 00:00:29,199
我之前一年多前采访

279
00:00:00,000 --> 00:00:02,799
在Intel工作的芯片工程师

280
00:00:03,080 --> 00:00:06,799
他的工作就是要从结晶的晶体上

281
00:00:06,799 --> 00:00:08,439
去做下一代的芯片

282
00:00:08,599 --> 00:00:10,919
但是结晶的这个晶体

283
00:00:10,919 --> 00:00:13,039
你这一步差了0.1%的杂质

284
00:00:13,160 --> 00:00:15,720
那一步可能就差10% 20%的产出

285
00:00:15,960 --> 00:00:18,160
这么多步骤结合到一起的时候

286
00:00:18,280 --> 00:00:19,960
你最后可能你的良品率

287
00:00:19,960 --> 00:00:22,280
就是它的10% 1%

288
00:00:22,399 --> 00:00:25,600
那你的成本就完全不可接受

289
00:00:25,600 --> 00:00:25,879
对吧

290
00:00:25,879 --> 00:00:29,399
所以说工程能力是一个很重要的东西

291
00:00:00,000 --> 00:00:01,399
且很难被复制

292
00:00:01,399 --> 00:00:02,399
不幸的是

293
00:00:02,399 --> 00:00:07,200
OpenAI就是有一个强工程能力壁垒的这样的一个机构

294
00:00:07,200 --> 00:00:09,000
它里边的人才密度是非常高的

295
00:00:09,000 --> 00:00:10,199
在碰撞的过程中

296
00:00:10,199 --> 00:00:12,599
他们解决了很多很多的工程瓶颈

297
00:00:12,599 --> 00:00:16,000
而且大语言模型本来就是一个非常吃工程能力的东西

298
00:00:16,000 --> 00:00:18,199
我们现在有无数的人去讨论

299
00:00:18,199 --> 00:00:19,600
怎么怎么样子去用NLP

300
00:00:19,600 --> 00:00:21,000
怎么怎么样子用大语言模型

301
00:00:21,000 --> 00:00:22,000
这里边的原理是什么

302
00:00:22,000 --> 00:00:23,000
我们应该怎么做出来

303
00:00:23,000 --> 00:00:27,600
但是有几个人真的能像OpenAI做好文本清理那一步

304
00:00:00,000 --> 00:00:03,600
大家真的能把真正的世界的文本

305
00:00:03,600 --> 00:00:06,080
很好的清理到一个数据集

306
00:00:06,080 --> 00:00:07,080
去喂给大陆人模型

307
00:00:07,080 --> 00:00:08,800
我觉得真正能做好这一步的人

308
00:00:08,800 --> 00:00:09,919
反而是非常非常少的

309
00:00:09,919 --> 00:00:11,279
以及我没有听到谁

310
00:00:11,279 --> 00:00:12,919
很认真地去讨论这一步

311
00:00:12,919 --> 00:00:15,000
如果大家真的很认真的要去复刻

312
00:00:15,000 --> 00:00:15,800
Chats with Tea

313
00:00:15,800 --> 00:00:17,199
起码先把第一步做好吧

314
00:00:17,879 --> 00:00:19,519
那在这种情况下

315
00:00:19,519 --> 00:00:22,199
叠加leadership是缺乏技术判断力的

316
00:00:22,199 --> 00:00:23,920
叠加我们的工程师

317
00:00:23,920 --> 00:00:26,199
尤其有原理性思考的工程师的人才密度

318
00:00:26,199 --> 00:00:27,039
是不够的

319
00:00:27,039 --> 00:00:29,480
再叠加我们的商业社会

320
00:00:00,000 --> 00:00:04,559
或者说我们这样一个很复杂的环境和我们的人的思考模式

321
00:00:04,559 --> 00:00:06,080
大家一定要认真严肃对待

322
00:00:06,080 --> 00:00:08,199
Chai GPT是很难复刻的这一现实

323
00:00:08,560 --> 00:00:10,199
如果观众里有一些不懂的同学

324
00:00:10,199 --> 00:00:13,839
他们会说过去的ML我们都复制的不是很好吗

325
00:00:13,839 --> 00:00:15,320
中国的AI不是很领先吗

326
00:00:15,359 --> 00:00:17,000
其实不是这样子的

327
00:00:17,000 --> 00:00:19,839
过去的AI的绝大多数的日本人都是开源的

328
00:00:19,839 --> 00:00:21,000
模型都是开源的

329
00:00:21,000 --> 00:00:24,679
因为它的真正的竞争力在数据和对商业的结合上

330
00:00:24,839 --> 00:00:27,039
但是Chai GPT再说一遍

331
00:00:27,039 --> 00:00:29,239
它是一个强工程门槛的东西

332
00:00:00,000 --> 00:00:02,759
它的那个训练它的模型是必然的

333
00:00:02,759 --> 00:00:05,440
它的那个训练也是一个很难很难的

334
00:00:05,440 --> 00:00:07,679
它也不会开源给你死雷小新

335
00:00:07,679 --> 00:00:11,080
它哪怕把CHPT的这个原理全都给你了

336
00:00:11,080 --> 00:00:13,720
你要想拿着CHPT去重新复刻一遍

337
00:00:13,720 --> 00:00:16,160
就像我给你一个材料的recipe

338
00:00:16,160 --> 00:00:18,079
我们每个人都能买到飞机引擎

339
00:00:18,079 --> 00:00:19,199
不是每个人都能买到吧

340
00:00:19,199 --> 00:00:20,679
但是我们能买到飞机引擎

341
00:00:20,679 --> 00:00:24,960
我们知道这个东西的原理和它的成型的样子

342
00:00:24,960 --> 00:00:26,800
但是你没有办法做出来

343
00:00:26,800 --> 00:00:28,280
大概就是这样一件事情

344
00:00:00,000 --> 00:00:02,680
好的以上就是我的几个主要结论

345
00:00:02,960 --> 00:00:04,480
但是你知道这些结论

346
00:00:04,480 --> 00:00:06,080
不知道这些结论是怎么来的

347
00:00:06,080 --> 00:00:06,960
意义其实不大

348
00:00:06,960 --> 00:00:09,199
因为你换到另外一个人说另外一个结论

349
00:00:09,199 --> 00:00:10,480
你就没有办法比较了

350
00:00:10,519 --> 00:00:12,160
你只会说这个人咖啡大

351
00:00:12,160 --> 00:00:13,759
那个人咖啡大或者怎么样

352
00:00:13,759 --> 00:00:16,079
这个人听着和我的想法比较一致

353
00:00:16,120 --> 00:00:17,519
我就选择相信这个人

354
00:00:17,559 --> 00:00:19,559
你是很难形成这里的判断力的

355
00:00:19,719 --> 00:00:21,480
真正的我的思辨过程

356
00:00:21,480 --> 00:00:22,640
我对技术的理解

357
00:00:22,640 --> 00:00:25,399
我对技术的总结和为什么这些技术的总结

358
00:00:25,399 --> 00:00:26,760
叠加这些东西

359
00:00:26,879 --> 00:00:28,559
可以让我得到这样的结论

360
00:00:00,000 --> 00:00:02,200
我都在我的文档里面说了

361
00:00:02,200 --> 00:00:04,599
大家有兴趣的话可以去看

362
00:00:04,599 --> 00:00:07,799
但是总之我的建议就是不要去做结论党

363
00:00:07,799 --> 00:00:09,400
不要去做省留党

364
00:00:09,400 --> 00:00:13,400
你真正有价值的结论没价值

365
00:00:13,400 --> 00:00:14,400
你真的就是他

366
00:00:14,400 --> 00:00:17,800
你只是在寻找一个和你听着有点关系的东西

367
00:00:17,800 --> 00:00:22,199
但是他怎么得到这个的才是你最应该关心的

368
00:00:22,199 --> 00:00:24,800
尤其在这个ChinaGPT马上就要取代绝大多数

369
00:00:24,800 --> 00:00:26,899
观众类公司的一个年代了

370
00:00:26,899 --> 00:00:28,699
你如果还停留在找结论的话

371
00:00:00,000 --> 00:00:02,680
那你的思维能力一定是不如拆GPT的

372
00:00:02,879 --> 00:00:05,799
如果你的算力和你的信息明显会不如拆GPT

373
00:00:05,839 --> 00:00:07,559
你的态度 然后你的ego

374
00:00:07,559 --> 00:00:11,759
然后你的心地 你的理性都不如拆GPT

375
00:00:11,800 --> 00:00:13,439
你的判断力和你的思维能力

376
00:00:13,439 --> 00:00:14,640
再不如拆GPT的话

377
00:00:14,640 --> 00:00:15,839
那你还剩下什么呢

378
00:00:15,880 --> 00:00:18,359
好的 灌输焦虑就灌输到这吧

379
00:00:18,399 --> 00:00:19,719
我反正是一点都不焦虑

380
00:00:19,719 --> 00:00:21,640
我特别希望拆GPT的到来

381
00:00:21,640 --> 00:00:24,320
我迫不及待等待它赶紧到来的那一天

382
00:00:24,519 --> 00:00:26,280
那这期视频就到这里

383
00:00:26,320 --> 00:00:27,839
我们下期再见 拜拜

