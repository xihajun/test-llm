1
00:00:00,000 --> 00:00:02,160
难道不是希望做一个比Google更好的吗

2
00:00:02,720 --> 00:00:04,320
不 我十分钟做一个Google

3
00:00:05,080 --> 00:00:07,240
所以降临派到时候

4
00:00:07,240 --> 00:00:09,039
到时候应该降临了

5
00:00:09,039 --> 00:00:10,880
要禁止我去降临派了

6
00:00:10,880 --> 00:00:11,759
群主

7
00:00:11,759 --> 00:00:12,919
你们禁临派了

8
00:00:12,919 --> 00:00:13,919
另外一个就是说

9
00:00:13,919 --> 00:00:15,480
那我们应该怎么看待

10
00:00:15,480 --> 00:00:16,199
HotSession这个问题

11
00:00:16,199 --> 00:00:18,359
就没有HotSession就真的是更好吗

12
00:00:21,280 --> 00:00:23,679
对 我这有两个问题先留着

13
00:00:23,679 --> 00:00:24,640
要不先问吧

14
00:00:24,640 --> 00:00:25,199
你说

15
00:00:25,199 --> 00:00:26,199
第一个就是

16
00:00:26,199 --> 00:00:27,199
Conversation是这样的

17
00:00:27,199 --> 00:00:28,120
Instruct

18
00:00:00,000 --> 00:00:03,040
instruction 为什么需要强化学习这一

19
00:00:03,040 --> 00:00:05,599
第二个就是它的那一步

20
00:00:05,599 --> 00:00:07,080
它的alignment这一步

21
00:00:07,080 --> 00:00:10,560
现在是用 reinforcement learning的方式

22
00:00:10,560 --> 00:00:13,080
但是是否可以用其他方式也有些

23
00:00:13,080 --> 00:00:15,599
我觉得第二个问题稍微更好回答一点

24
00:00:15,599 --> 00:00:18,239
就是你如果align的只是这个format

25
00:00:18,239 --> 00:00:19,559
或者说想用的时候

26
00:00:19,559 --> 00:00:21,239
就其实并不需要

27
00:00:21,239 --> 00:00:24,000
毕竟并不见得需要所谓的强化学习

28
00:00:24,000 --> 00:00:25,600
因为强化学习更多的是

29
00:00:25,600 --> 00:00:28,640
你需要让这个模型去探索这些东西

30
00:00:00,000 --> 00:00:01,600
那如果你已经知道答案的话

31
00:00:01,600 --> 00:00:02,759
你为什么要让他探索呢

32
00:00:02,759 --> 00:00:03,640
对对吧

33
00:00:03,640 --> 00:00:03,919
嗯

34
00:00:03,919 --> 00:00:04,480
对

35
00:00:04,480 --> 00:00:06,559
然后你第一个问题是

36
00:00:06,559 --> 00:00:07,480
instruct

37
00:00:07,480 --> 00:00:08,560
就是instructivity

38
00:00:08,560 --> 00:00:09,720
是用reinforcement learning

39
00:00:09,720 --> 00:00:10,439
但是为什么呢

40
00:00:11,080 --> 00:00:12,560
我觉得这个可能也是跟

41
00:00:12,560 --> 00:00:15,359
就是他需要在conversation上有behave

42
00:00:15,359 --> 00:00:17,160
有有有相关的

43
00:00:17,160 --> 00:00:18,719
但这个我觉得我们可以再

44
00:00:18,719 --> 00:00:19,280
再聊聊这个

45
00:00:19,280 --> 00:00:20,960
我记得前一阵子那个Stanford

46
00:00:20,960 --> 00:00:22,920
出了一个paper是

47
00:00:23,120 --> 00:00:23,800
就是

48
00:00:24,160 --> 00:00:25,960
HF但是不用

49
00:00:26,120 --> 00:00:27,800
但是不用RL的这种方式

50
00:00:27,800 --> 00:00:29,399
其实业内武汉也有一些讨论

51
00:00:00,000 --> 00:00:06,000
就是说HF是不是就alignment是否一定要用RL的方式去做

52
00:00:06,000 --> 00:00:08,320
对 是否一定要用RL的这个方式

53
00:00:08,320 --> 00:00:10,640
我好奇就是你怎么看待这个话题的讨论

54
00:00:11,320 --> 00:00:14,960
我觉得alignment首先是一个比较broad的一个

55
00:00:14,960 --> 00:00:17,399
就是到底是什么叫alignment对吧

56
00:00:17,399 --> 00:00:18,640
就和什么东西align

57
00:00:18,640 --> 00:00:22,000
或者说和一个东西align是不是代表和另外一个东西就不align

58
00:00:22,000 --> 00:00:25,120
然后这我觉得就有点哲学的讨论

59
00:00:00,000 --> 00:00:04,480
那说我觉得RL更多的是我们觉得现在大家发现的一个

60
00:00:04,480 --> 00:00:09,359
能够更像人的一种比较有效的方法

61
00:00:09,359 --> 00:00:11,199
但未来是不是这是唯一的方法

62
00:00:11,199 --> 00:00:12,800
我觉得这也是不确定

63
00:00:12,800 --> 00:00:17,199
我更区分强化学习和普通的

64
00:00:17,199 --> 00:00:20,239
我们所说的这种就是微调模型或者这种

65
00:00:20,239 --> 00:00:21,839
或者说single turn模型

66
00:00:21,839 --> 00:00:22,760
就是最重要的一个

67
00:00:22,760 --> 00:00:24,519
我觉得那几个部分

68
00:00:24,519 --> 00:00:28,160
一个是你需不需要让模型去做一个sequence of decision

69
00:00:28,160 --> 00:00:29,679
然后你才知道这个reward

70
00:00:00,000 --> 00:00:02,879
如果你每一课都知道准确的reward的话

71
00:00:02,879 --> 00:00:05,759
那你不见得需要用强化学习

72
00:00:05,759 --> 00:00:08,480
你只有需要做一个sequence的时候你才需要reward

73
00:00:08,480 --> 00:00:10,320
第二个 这是我个人的观点

74
00:00:10,320 --> 00:00:12,160
我其实很少听到别人去这么说

75
00:00:12,160 --> 00:00:14,960
我也非常想知道是不是正确的

76
00:00:14,960 --> 00:00:17,039
但是我目前自己是这么理解的

77
00:00:17,039 --> 00:00:19,440
就是你需要做强化学习的时候

78
00:00:19,440 --> 00:00:21,519
你很有可能你得到reward

79
00:00:21,519 --> 00:00:23,679
它到模型上而不differentiable

80
00:00:23,679 --> 00:00:24,960
我举个例子

81
00:00:24,960 --> 00:00:26,480
比如说我们现在训练一个模型

82
00:00:26,480 --> 00:00:28,800
任何一个loss function

83
00:00:00,000 --> 00:00:01,600
它本身是defensible

84
00:00:01,600 --> 00:00:04,559
所以你可以根据这个loss去把

85
00:00:04,559 --> 00:00:07,679
这个weights update到每一个parameter到多少是知道的

86
00:00:07,679 --> 00:00:08,080
对

87
00:00:08,080 --> 00:00:10,720
因为你就是forward pass过去

88
00:00:10,720 --> 00:00:11,839
你获得了这个loss

89
00:00:11,839 --> 00:00:15,919
然后你这个整个模型和loss function都是可导的

90
00:00:15,919 --> 00:00:18,719
所以你才知道模型应该update成什么

91
00:00:18,719 --> 00:00:20,440
而强化学习当中

92
00:00:20,440 --> 00:00:22,839
你很多时候这个reward它不是可导的

93
00:00:22,839 --> 00:00:23,320
是的

94
00:00:23,320 --> 00:00:25,039
这个东西0或者1

95
00:00:25,039 --> 00:00:25,280
对

96
00:00:25,280 --> 00:00:26,120
成功没成功

97
00:00:26,120 --> 00:00:26,399
对

98
00:00:26,399 --> 00:00:28,600
或者甚至这个reward大小都是一个

99
00:00:00,000 --> 00:00:03,000
我们所谓说超参数 Hyperparameter

100
00:00:03,000 --> 00:00:05,679
那我们就没有办法

101
00:00:05,679 --> 00:00:07,559
如果你遇见了一个情况

102
00:00:07,559 --> 00:00:09,119
你的reward是不可打的

103
00:00:09,119 --> 00:00:10,519
你的loss方面是不可打的

104
00:00:10,519 --> 00:00:10,759
对

105
00:00:10,759 --> 00:00:11,679
那你是不是说

106
00:00:11,679 --> 00:00:15,199
我觉得就更适合去用强化学习去这个思路

107
00:00:15,199 --> 00:00:16,640
但同时同理来说

108
00:00:16,640 --> 00:00:17,839
如果是可打的话

109
00:00:17,839 --> 00:00:22,440
那你也不见得一定是要用强化学习去完成这件事情

110
00:00:22,440 --> 00:00:24,160
那我好奇一下

111
00:00:24,160 --> 00:00:26,519
我不知道这个是不是相关会我理解对不对

112
00:00:00,000 --> 00:00:03,960
比如说你刚才讲到一系列的决策

113
00:00:03,960 --> 00:00:06,040
就让我很容易想到像Auto-GPT

114
00:00:06,040 --> 00:00:09,359
这样的就是涉及一系列的行为

115
00:00:09,359 --> 00:00:11,279
就我们所谓的Agent

116
00:00:11,279 --> 00:00:14,400
现在我们看到一些Agent的一些实现

117
00:00:14,400 --> 00:00:16,640
虽然说大家可以当然有各种各样的问题

118
00:00:16,640 --> 00:00:20,839
但是它的确是在一系列的action之间

119
00:00:20,839 --> 00:00:22,320
在不断的去做自我调整

120
00:00:22,320 --> 00:00:25,440
这个属不属于你刚才所说的这种情况

121
00:00:25,440 --> 00:00:26,640
如果属于的话

122
00:00:00,000 --> 00:00:04,360
其实像什么BJHI什么OGBT

123
00:00:04,360 --> 00:00:10,320
其实他们也并没有涉及到RHF这个方向上的这种变动

124
00:00:10,320 --> 00:00:14,000
所以就我好奇就是你怎么看待这一块

125
00:00:14,000 --> 00:00:16,359
首先我觉得你这个说的特别好

126
00:00:16,359 --> 00:00:19,359
就是这些agent首先一定是做一个sequence of decision

127
00:00:19,359 --> 00:00:20,719
互相相互depend

128
00:00:20,719 --> 00:00:26,079
这个一定是一个很好的用来做强化学习的一个环境场景

129
00:00:26,079 --> 00:00:28,199
那你其实就要设计一下这个

130
00:00:00,000 --> 00:00:03,560
因为强化学有几个必须要完成的条件

131
00:00:03,560 --> 00:00:05,440
就比如说这个环境是什么样

132
00:00:05,440 --> 00:00:06,759
它的状态是什么样

133
00:00:06,759 --> 00:00:08,800
它们的状态之间是怎么样变化的

134
00:00:08,800 --> 00:00:10,199
或者是它的reward应该是什么

135
00:00:10,199 --> 00:00:11,759
如果你能把这些设计好

136
00:00:11,759 --> 00:00:15,199
你其实真是可以把这些feedback还到给模型的

137
00:00:15,199 --> 00:00:17,280
那你就回到我们刚刚那个话题

138
00:00:17,280 --> 00:00:18,719
就是如果你要还到这个模型

139
00:00:18,719 --> 00:00:20,839
它是不是还是变了一个更好的一个模型了

140
00:00:20,839 --> 00:00:24,559
我认为你通过这个RLHL的过程当中

141
00:00:24,559 --> 00:00:26,199
你的模型发生了一些变化

142
00:00:26,199 --> 00:00:27,800
那它就可以变得更好

143
00:00:27,800 --> 00:00:28,239
比如像

144
00:00:00,000 --> 00:00:01,679
但是可以这样agree

145
00:00:01,679 --> 00:00:04,040
就是模型不是必须要发生变化

146
00:00:04,440 --> 00:00:06,599
模型在不发生变化的情况下

147
00:00:06,599 --> 00:00:09,759
也能让它通过这两步达到

148
00:00:09,759 --> 00:00:13,039
就是完成任务的能力变得更强

149
00:00:13,599 --> 00:00:15,160
就是模型可以变化

150
00:00:15,160 --> 00:00:16,480
但是它不是一个必要条件

151
00:00:16,800 --> 00:00:17,879
我觉得可以这么说

152
00:00:17,879 --> 00:00:19,160
那这个如果我们

153
00:00:19,160 --> 00:00:20,039
你如果想拼一下

154
00:00:20,039 --> 00:00:23,800
我们可以聊关于所谓不同种类的

155
00:00:23,800 --> 00:00:26,199
fine tuning他们的做法不一样

156
00:00:26,199 --> 00:00:27,120
我觉得你说的这个东西

157
00:00:27,120 --> 00:00:29,719
可能更适合某一类 特类的

158
00:00:00,000 --> 00:00:02,240
我其实同意你那天吃饭的时候说的一个点

159
00:00:02,240 --> 00:00:04,679
就是你如果说纯参数的update

160
00:00:04,679 --> 00:00:06,360
就是和我们现在的做法

161
00:00:06,360 --> 00:00:08,560
我们现在最多就能发挥60%的效果

162
00:00:08,560 --> 00:00:10,439
我觉得让模型发生变化

163
00:00:10,439 --> 00:00:12,960
肯定最后是一个最optimal的方式

164
00:00:12,960 --> 00:00:14,919
但是我会觉得

165
00:00:14,919 --> 00:00:18,879
就是为了保证它现在的general

166
00:00:18,879 --> 00:00:21,239
所以说模型不发生变化

167
00:00:21,239 --> 00:00:23,600
而通过第二步去提高它的能力

168
00:00:23,600 --> 00:00:25,160
是一个更general的方式

169
00:00:25,160 --> 00:00:27,559
以及它已经远远超过其之前的能力了

170
00:00:27,559 --> 00:00:28,960
所以说这已经够了

171
00:00:00,000 --> 00:00:03,720
那其实你要完成你这个目标

172
00:00:03,720 --> 00:00:06,280
你模型的参数可以变化

173
00:00:06,280 --> 00:00:10,560
但是有可能每一个人会得获得自己一部分可调参数

174
00:00:10,560 --> 00:00:12,720
就是整个模型不变

175
00:00:12,720 --> 00:00:16,719
但是模型的每一层当中加一小块是可以调整的

176
00:00:16,719 --> 00:00:19,600
或者是最后一层加一小块是可以调整的

177
00:00:19,600 --> 00:00:21,600
那其实就跟你的这个例子是一样的

178
00:00:21,600 --> 00:00:23,879
虽然它是一个参数的形式存在

179
00:00:23,879 --> 00:00:26,399
但是它并不影响本身大模型的表现

180
00:00:26,399 --> 00:00:26,679
对

181
00:00:26,679 --> 00:00:27,480
我觉得这也是另外一个

182
00:00:27,480 --> 00:00:28,280
也可以

183
00:00:00,000 --> 00:00:01,800
我再把那个再说

184
00:00:01,800 --> 00:00:03,160
或者说这样吧

185
00:00:03,160 --> 00:00:04,000
你刚刚说的是

186
00:00:04,000 --> 00:00:07,559
我想下来两件事

187
00:00:07,559 --> 00:00:08,800
我抽象理解的话

188
00:00:08,800 --> 00:00:11,039
你刚刚说的是给模型做加法

189
00:00:11,039 --> 00:00:13,359
或者说减了以后加对吧

190
00:00:13,359 --> 00:00:14,720
就是它的参数有改变

191
00:00:14,720 --> 00:00:16,039
我说的是一个乘法

192
00:00:16,039 --> 00:00:18,120
就是你这个layer没有变

193
00:00:18,120 --> 00:00:19,920
但是你又加了一层layer

194
00:00:19,920 --> 00:00:21,239
然后乘以后

195
00:00:21,239 --> 00:00:23,079
你的模型的performance发生了变化

196
00:00:23,079 --> 00:00:24,079
我大概是这个意思

197
00:00:00,000 --> 00:00:06,360
就是alignment overloaded这一层

198
00:00:06,360 --> 00:00:10,720
它是其实是一个你可以把它理解成为另外一个matrix

199
00:00:10,720 --> 00:00:13,720
然后我通过alignment成了这个matrix

200
00:00:13,720 --> 00:00:15,519
然后我得到了更好的效果

201
00:00:15,519 --> 00:00:18,480
我不需要去改变模型本身的参数

202
00:00:18,480 --> 00:00:19,440
大概是这个意思

203
00:00:19,440 --> 00:00:22,160
你的意思就是说我说的这些东西

204
00:00:22,160 --> 00:00:26,000
每一个都是说在特定任务上加上了这个东西使得它成

205
00:00:26,000 --> 00:00:27,800
但是你说的是

206
00:00:00,000 --> 00:00:05,280
可能有一系列模型和一系列的这个alignment的方法

207
00:00:05,280 --> 00:00:07,280
然后他们可以互相就

208
00:00:07,280 --> 00:00:09,759
对或者就一个GPT

209
00:00:09,759 --> 00:00:12,400
因为GPT它这个本身的这个matrix太牛逼了

210
00:00:12,400 --> 00:00:16,640
然后我不同的任务我就去研究针对不同任务最optimal的matrix

211
00:00:16,640 --> 00:00:19,359
但是1乘n不就像和1加n没什么区别

212
00:00:20,800 --> 00:00:22,039
不是一个模型

213
00:00:22,039 --> 00:00:25,000
就是这模型里边的1751个参数不变

214
00:00:25,000 --> 00:00:28,960
而这里边可能我有一个10个亿的参数

215
00:00:28,960 --> 00:00:29,760
500万的参数

216
00:00:00,000 --> 00:00:03,279
然后就让它的task的效果变好了

217
00:00:03,720 --> 00:00:06,559
我只需要去focus在改变这里的参数就行了

218
00:00:06,559 --> 00:00:09,759
而不需要去对那1750一个参数做任何改变

219
00:00:09,759 --> 00:00:12,039
对对对 那这个其实我们就是说

220
00:00:12,039 --> 00:00:16,399
那这其实说到就是全参数微调和部分参数微调

221
00:00:16,399 --> 00:00:19,120
像你说这种更多是就有专门有一个部分

222
00:00:19,120 --> 00:00:21,719
有一个area of work叫adapter

223
00:00:21,719 --> 00:00:26,000
其实就是这个模型它可以插入一部分参数进去

224
00:00:26,000 --> 00:00:28,519
那你不用管它是插入在模型的中间

225
00:00:00,000 --> 00:00:01,600
还是在最后还是前面

226
00:00:01,600 --> 00:00:02,680
其实就是插入一部分

227
00:00:02,680 --> 00:00:03,839
然后它是可以替换的

228
00:00:03,839 --> 00:00:06,280
但其实你本身是一个基础模型

229
00:00:06,280 --> 00:00:07,280
或者一个底层模型

230
00:00:07,280 --> 00:00:10,960
你可以不断的插入不同的这种adapter

231
00:00:10,960 --> 00:00:11,800
但是这是很困难

232
00:00:11,800 --> 00:00:13,119
这差 这数值差也有区别

233
00:00:13,119 --> 00:00:13,560
对对对对

234
00:00:13,560 --> 00:00:14,240
是怎么差

235
00:00:14,240 --> 00:00:16,480
然后甚至说你插入的是参数

236
00:00:16,480 --> 00:00:17,839
还插入的是粒子

237
00:00:17,839 --> 00:00:18,280
对

238
00:00:18,280 --> 00:00:21,000
都是可以 这都是不同的一种思路

239
00:00:21,000 --> 00:00:21,480
或者是

240
00:00:21,480 --> 00:00:22,760
这个是在pre-train阶段吗

241
00:00:22,760 --> 00:00:23,000
还是

242
00:00:23,000 --> 00:00:24,079
这是在应用阶段的时候

243
00:00:24,079 --> 00:00:24,559
应用阶段

244
00:00:24,559 --> 00:00:27,640
就是你可以训练一个插入的adapter参数

245
00:00:27,640 --> 00:00:29,199
就像是比如说我这个模型

246
00:00:00,000 --> 00:00:03,480
本来有就是一个trillion的parameter

247
00:00:03,480 --> 00:00:05,639
那我可能就插入了一个一个billion

248
00:00:05,639 --> 00:00:07,040
或者half a billion的parameter

249
00:00:07,040 --> 00:00:09,400
但它分布在这个模型不同的位置

250
00:00:09,400 --> 00:00:10,640
但我模型知道

251
00:00:10,640 --> 00:00:13,039
哦 这些东西实际上它是可被替换的

252
00:00:13,039 --> 00:00:14,640
那你可以拿走

253
00:00:14,640 --> 00:00:17,320
你也可以换上另外一个去不断去替换

254
00:00:17,320 --> 00:00:19,600
那你们也可以说是我插入的是参数

255
00:00:19,600 --> 00:00:20,640
那有可能呢

256
00:00:20,640 --> 00:00:23,679
我只在最前头插入了一段文字

257
00:00:23,679 --> 00:00:25,800
那其实就有点像prompt

258
00:00:25,800 --> 00:00:27,399
或者说我们所谓说的in context

259
00:00:00,000 --> 00:00:02,560
或者再往前就说叫prefix tuning

260
00:00:02,560 --> 00:00:06,400
就是说我能不能在我说的之前加一段

261
00:00:06,400 --> 00:00:10,080
不管是文字就是hard prefix或者soft prefix

262
00:00:10,080 --> 00:00:11,400
就我增加一个vector

263
00:00:11,400 --> 00:00:14,279
那在我的文字当中那会不会有提高

264
00:00:14,279 --> 00:00:16,480
其实这就是这都是像你说的

265
00:00:16,480 --> 00:00:18,719
就是不改变大模型的本身的情况下

266
00:00:18,719 --> 00:00:21,920
去再让这个模型应用在不同的任务上

267
00:00:21,920 --> 00:00:23,480
好我先说观点二

268
00:00:23,480 --> 00:00:26,320
然后再打一个跟针对你刚才说的这东西比方

269
00:00:26,320 --> 00:00:27,440
观点二就是

270
00:00:00,000 --> 00:00:06,480
如果说我们说的开放reinforcement learning这一层出现了以后

271
00:00:06,480 --> 00:00:07,599
我觉得他们很快就没了

272
00:00:07,599 --> 00:00:12,080
因为这个sequence其实你在Lineman那一步是更好被调节的

273
00:00:12,080 --> 00:00:15,359
而且更可就是我们现在是

274
00:00:15,359 --> 00:00:20,079
如果大家去读InstructGPT或ChaiGPT的paper

275
00:00:20,079 --> 00:00:23,719
他们做的流程其实是非常透明和容易复制的

276
00:00:23,719 --> 00:00:25,879
就是你去对话

277
00:00:25,879 --> 00:00:26,800
然后人去打标

278
00:00:26,800 --> 00:00:29,320
打完标了以后去告诉他什么好什么不好

279
00:00:00,000 --> 00:00:00,720
然后去train

280
00:00:01,000 --> 00:00:04,719
然后人这个环节完全可以被机器去替代

281
00:00:04,719 --> 00:00:06,759
就是但是任务不一样了

282
00:00:06,759 --> 00:00:09,880
就是比如说我需要编出来一个什么样的系统

283
00:00:09,880 --> 00:00:11,599
比如说我要编Google的一个ranker

284
00:00:11,599 --> 00:00:11,839
对吧

285
00:00:11,839 --> 00:00:14,320
然后我要让他的ranking performance特别好

286
00:00:14,320 --> 00:00:17,559
那我是可以把这个任务拆解成几个重要的步骤

287
00:00:17,559 --> 00:00:21,480
然后就直接用这个结果去feedback给GPT

288
00:00:21,480 --> 00:00:22,760
然后让他去做就行了

289
00:00:22,879 --> 00:00:26,440
那最后他应该我觉得就是假设他的能力是到位的话

290
00:00:26,440 --> 00:00:28,280
他应该可以做出一个Google

291
00:00:00,000 --> 00:00:02,000
会不断的调整自己

292
00:00:02,000 --> 00:00:04,120
使得自己的ranking的效果会越来越好

293
00:00:04,120 --> 00:00:06,879
通过一些这online的一些feedback来讲

294
00:00:06,879 --> 00:00:09,880
对 问题是这feedback明确的情况下

295
00:00:09,880 --> 00:00:11,560
它的反馈效率

296
00:00:11,560 --> 00:00:13,880
远远不是人给他提供feedback能比的

297
00:00:13,880 --> 00:00:15,679
他可能10分钟就做出来了

298
00:00:16,960 --> 00:00:21,399
那你这门我想就是解释一下

299
00:00:21,399 --> 00:00:23,039
就是你觉得这个feedback是

300
00:00:23,039 --> 00:00:25,079
机器怎么提供这样的feedback

301
00:00:25,079 --> 00:00:26,160
就是你说的呀

302
00:00:26,160 --> 00:00:27,719
就是你们当时做的那个

303
00:00:00,000 --> 00:00:03,200
就是和其他就是和就是去对比嘛

304
00:00:03,200 --> 00:00:05,759
去benchmark其他的其他的那个

305
00:00:05,759 --> 00:00:07,280
就是我直接benchmark google

306
00:00:07,280 --> 00:00:08,800
然后你什么时候达到google performance

307
00:00:08,800 --> 00:00:09,560
然后就行了

308
00:00:09,560 --> 00:00:12,080
ok 那这个确实那你

309
00:00:12,080 --> 00:00:14,599
但是你希望去做这个强化学习

310
00:00:14,599 --> 00:00:16,960
你难道不是希望做一个比google更好的吗

311
00:00:17,399 --> 00:00:19,120
不我10分钟做一个google

312
00:00:19,120 --> 00:00:20,199
哦那你

313
00:00:20,199 --> 00:00:21,199
我10分钟做一个google

314
00:00:21,199 --> 00:00:23,679
然后我也可以去想方设法定义比google更好

315
00:00:23,679 --> 00:00:25,079
然后去给他提供feedback

316
00:00:25,079 --> 00:00:27,199
但是问题是我这10分钟做一个google

317
00:00:00,000 --> 00:00:03,660
不是说我的模型在已经人写好的情况下去

318
00:00:03,660 --> 00:00:05,700
去达到这样的performance

319
00:00:05,700 --> 00:00:08,699
而是他从零开始让他重新开始写代码

320
00:00:08,699 --> 00:00:09,339
对吧

321
00:00:09,339 --> 00:00:11,699
你就给我写代码写出来一个Google

322
00:00:11,699 --> 00:00:13,380
然后他10分钟可以做到这件事

323
00:00:14,179 --> 00:00:15,939
我觉得未来是有可能的

324
00:00:15,939 --> 00:00:17,660
这就是我觉得AGI可怕之处

325
00:00:17,660 --> 00:00:18,980
就是这就是为什么我觉得

326
00:00:18,980 --> 00:00:22,460
Chai GP OpenAI不敢随便开放reinforcement learning这一步

327
00:00:22,460 --> 00:00:24,500
因为其实我刚说的还是个简单的

328
00:00:24,500 --> 00:00:26,699
10分钟取代Google大家觉得是可行的

329
00:00:26,699 --> 00:00:29,420
但是如果说我是一个更高的目标

330
00:00:00,000 --> 00:00:01,120
如果我能想象出来

331
00:00:01,120 --> 00:00:03,160
且我能给他提供reward function的话

332
00:00:03,200 --> 00:00:05,400
他也可以好好的做到这件事

333
00:00:05,919 --> 00:00:09,800
我觉得从理想上讲肯定是这样的

334
00:00:09,800 --> 00:00:09,960
对

335
00:00:09,960 --> 00:00:13,000
这个让我想到Silicon Valley那个

336
00:00:13,039 --> 00:00:14,240
那个电视剧里面

337
00:00:14,240 --> 00:00:14,800
对吧

338
00:00:14,800 --> 00:00:16,679
就是从一个小的

339
00:00:16,719 --> 00:00:18,800
这个你只optimize for a small goal

340
00:00:18,800 --> 00:00:20,679
but ultimately就是他发现你

341
00:00:20,679 --> 00:00:23,440
其实你反正要optimize他

342
00:00:23,440 --> 00:00:25,399
其实花了一天的时间

343
00:00:25,399 --> 00:00:27,079
破解了世界上最难被的加密算法

344
00:00:27,079 --> 00:00:28,519
我当时在那个文章里面有说

345
00:00:00,000 --> 00:00:02,279
我就说skynet这种情况应该不会出现

346
00:00:02,279 --> 00:00:05,759
因为AGI它们就是模型它没有一个自己的

347
00:00:05,759 --> 00:00:06,599
motivation

348
00:00:06,599 --> 00:00:08,279
它没有一个intrinsic function

349
00:00:08,279 --> 00:00:09,919
它自己没有目标

350
00:00:09,919 --> 00:00:13,560
但是你让它去破解世界上加密算法

351
00:00:13,560 --> 00:00:16,120
它有可能把它高效的破解出来了

352
00:00:16,120 --> 00:00:17,480
这个是存在可能性的

353
00:00:17,480 --> 00:00:20,359
其实这个就其实这个是rule backed out

354
00:00:20,359 --> 00:00:22,480
我一开始问你的这个问题

355
00:00:22,480 --> 00:00:24,879
就是你觉得开放了LHF

356
00:00:24,879 --> 00:00:26,079
是可以使得我们做哪些

357
00:00:26,079 --> 00:00:27,399
我们现在做不了的这个事情

358
00:00:00,000 --> 00:00:02,819
而刚刚之所以讲到这个Auto-GBT其实也是

359
00:00:02,819 --> 00:00:04,259
我们都知道它只是一个demo

360
00:00:04,259 --> 00:00:07,900
但它提供了一个让更多人看到的一种可能性

361
00:00:07,900 --> 00:00:09,660
其实在这个可能性中

362
00:00:09,660 --> 00:00:11,660
其实大家就在讲说把它做到落地

363
00:00:11,660 --> 00:00:14,300
就是有可能有哪一些这个Bottleneck

364
00:00:14,300 --> 00:00:16,699
其中一个就是怎么样能够让他去

365
00:00:16,699 --> 00:00:18,500
自己知道怎么去收

366
00:00:18,500 --> 00:00:20,260
自己知道怎么去收敛中的一个东西

367
00:00:20,260 --> 00:00:24,140
其实就是刚才如意讲到的那个它的sequence里边

368
00:00:24,140 --> 00:00:26,820
就是sequence里边怎么样去帮他去优化

369
00:00:00,000 --> 00:00:03,720
能够帮他在每一个这个过程中去提供这个这个reward

370
00:00:03,720 --> 00:00:07,599
而似乎刚刚大家在想说要能够帮他很好做到这一点

371
00:00:07,599 --> 00:00:11,279
是要在可能在LHF这个环节去实现的

372
00:00:11,279 --> 00:00:13,320
我去打那个比方啊

373
00:00:13,320 --> 00:00:14,359
我先把那个比方打完

374
00:00:14,359 --> 00:00:17,239
就是跟你说的这个东西的关系是什么

375
00:00:17,239 --> 00:00:23,039
就是pre-train那个大模型能力这么多

376
00:00:23,039 --> 00:00:26,239
我们通过alignment发挥了这么多

377
00:00:26,239 --> 00:00:29,719
然后通过不同的prompt又发挥了这么多

378
00:00:00,000 --> 00:00:04,919
然后现在AutoGPT是在通过prompt去探索这里边的天花板

379
00:00:04,919 --> 00:00:07,639
然后呢最多就到这而已

380
00:00:07,639 --> 00:00:10,080
但是你开放了reinforcement learning之后

381
00:00:10,080 --> 00:00:11,919
你的天花板可能可以到这

382
00:00:13,000 --> 00:00:14,560
对大概就是这种感觉

383
00:00:14,560 --> 00:00:17,679
我的比方就是说你就把它比方成人

384
00:00:17,679 --> 00:00:20,199
这个人你给他读了世界上所有书

385
00:00:20,199 --> 00:00:21,480
请了最好的老师

386
00:00:21,480 --> 00:00:23,199
教了一个特别聪明的人

387
00:00:23,480 --> 00:00:26,000
这个时候如果用你的那个改参数的方式

388
00:00:26,000 --> 00:00:27,640
你可以给他再加点芯片

389
00:00:27,640 --> 00:00:29,280
然后给他一些特定的知识

390
00:00:00,000 --> 00:00:02,000
那它是可以变得更聪明更有效率

391
00:00:02,000 --> 00:00:03,600
但是另外的做法就是

392
00:00:03,600 --> 00:00:05,200
你给它一个很聪明的人

393
00:00:05,200 --> 00:00:08,640
然后去让他去研究一些任务

394
00:00:08,640 --> 00:00:10,839
然后去因为他有特别强的算力

395
00:00:10,839 --> 00:00:12,240
所以说他在一个任务上

396
00:00:12,240 --> 00:00:14,599
通过不同的调教和反馈

397
00:00:14,599 --> 00:00:15,599
第一手的反馈

398
00:00:15,599 --> 00:00:17,559
他能在这个任务上变得特别牛逼

399
00:00:17,559 --> 00:00:19,800
但是我们现在是说有一个人

400
00:00:19,800 --> 00:00:21,519
你只教他怎么跟人家对话

401
00:00:21,519 --> 00:00:23,519
然后在之后说不同的人给你对话

402
00:00:23,519 --> 00:00:24,640
你给他不同的反应

403
00:00:24,640 --> 00:00:26,760
我们在这上面已经看到了

404
00:00:26,760 --> 00:00:28,320
这个模型的这么多潜力了

405
00:00:00,000 --> 00:00:02,500
在開放前面的一層

406
00:00:02,500 --> 00:00:04,299
我只想到開放前面的那一層

407
00:00:04,299 --> 00:00:06,459
就很可怕了已經

408
00:00:06,459 --> 00:00:09,259
所以降臨派

409
00:00:09,259 --> 00:00:11,460
到時候一旦降臨了

410
00:00:11,460 --> 00:00:14,300
要記得我是降臨派的群主

411
00:00:14,300 --> 00:00:15,500
你不是靜音派的

412
00:00:15,500 --> 00:00:16,800
可以可以

413
00:00:16,800 --> 00:00:18,719
好呀好呀

414
00:00:18,719 --> 00:00:22,640
我們聊到了就是

415
00:00:22,640 --> 00:00:24,260
OpenEducate一長

416
00:00:24,260 --> 00:00:25,760
現在所有的人都要死

417
00:00:25,760 --> 00:00:29,420
如果開放了這種強化學習

418
00:00:00,000 --> 00:00:03,200
到底对这些应用上面到底有什么样的影响

419
00:00:03,200 --> 00:00:04,320
会开放什么样的新机会

420
00:00:04,320 --> 00:00:04,960
对正好

421
00:00:04,960 --> 00:00:05,480
对正好

422
00:00:05,480 --> 00:00:06,360
因为我想起来

423
00:00:06,360 --> 00:00:09,039
之前我在脑子里边ping的一个地方

424
00:00:09,039 --> 00:00:10,960
就是你提到这个

425
00:00:10,960 --> 00:00:12,199
如意现在做的公司

426
00:00:12,199 --> 00:00:14,359
你们是选择自己

427
00:00:14,359 --> 00:00:16,519
build一个自己的模型

428
00:00:16,519 --> 00:00:17,039
所以可以

429
00:00:17,039 --> 00:00:18,079
我觉得可以讲讲这个

430
00:00:18,079 --> 00:00:21,399
因为这个也是现在大家经常会讨论的一个东西

431
00:00:21,399 --> 00:00:22,440
就是你们怎么做

432
00:00:22,440 --> 00:00:25,000
我到底是自己build一个模型

433
00:00:25,000 --> 00:00:27,800
还是说用现有模型的一个决策

434
00:00:00,000 --> 00:00:03,200
是因为你们看到现有的模型哪一些限制

435
00:00:03,200 --> 00:00:05,400
那going forward就好像我们刚才提到的

436
00:00:05,400 --> 00:00:08,320
如果我们要准备好说

437
00:00:08,320 --> 00:00:10,800
那这个模型现在的能力

438
00:00:10,800 --> 00:00:12,839
还有很多我们不知道的这个地方

439
00:00:12,839 --> 00:00:17,239
你觉得我相信很多听众也是创业公司的小伙伴

440
00:00:17,239 --> 00:00:17,480
对吧

441
00:00:17,480 --> 00:00:19,440
我一方面希望现在能够尽快落地

442
00:00:19,440 --> 00:00:23,559
那另一方面我要为了未来可能的底层模型的变化

443
00:00:23,559 --> 00:00:24,760
需要做哪一些准备

444
00:00:24,760 --> 00:00:26,120
你的思考是怎么样

445
00:00:00,000 --> 00:00:04,759
OK 我觉得我先说一下我们为什么自己做自己的这些模型

446
00:00:05,000 --> 00:00:06,440
就是说当然了

447
00:00:06,440 --> 00:00:15,679
就是一方面我们想说就是如何让这个模型中获得专业专门是这种客服方面的知识

448
00:00:15,679 --> 00:00:18,280
就是这些agent上面是如何回答这些问题的

449
00:00:18,280 --> 00:00:20,199
我们其实做了很多这种评估

450
00:00:20,199 --> 00:00:22,679
就是说如果同样这个问题

451
00:00:22,679 --> 00:00:25,160
这用户提交了这么一个问题

452
00:00:25,160 --> 00:00:27,559
那就是他们的用户提交这么一个问题

453
00:00:27,559 --> 00:00:29,079
那模型应该去如何回答

454
00:00:00,000 --> 00:00:02,600
很多时候模型就算我们提供了一些

455
00:00:02,600 --> 00:00:04,160
比如说文章在其中

456
00:00:04,599 --> 00:00:06,320
文章有可能是详细

457
00:00:06,320 --> 00:00:07,639
有可能就缺少一些步骤

458
00:00:07,639 --> 00:00:10,640
那么他和agent

459
00:00:10,640 --> 00:00:12,839
就是说那些真正客服的那些人

460
00:00:12,839 --> 00:00:14,640
他们去完成那些事情是不一样的

461
00:00:14,919 --> 00:00:19,199
更多的是文章是让客户自己去troubleshoot自己

462
00:00:19,199 --> 00:00:20,039
或者怎么去做

463
00:00:20,039 --> 00:00:22,800
而并不是说agent应该去完成什么事情

464
00:00:22,800 --> 00:00:25,839
而agent他会回答我做了什么事

465
00:00:25,839 --> 00:00:27,800
然后你应该去做xyz

466
00:00:00,000 --> 00:00:04,679
这件事情上本身是模型没有的这方面知识

467
00:00:04,679 --> 00:00:07,040
那么如何把这方面知识放到模型当中

468
00:00:07,040 --> 00:00:08,720
让模型去生成的答案当中

469
00:00:08,720 --> 00:00:10,679
更像是一个agent去回答的东西

470
00:00:10,679 --> 00:00:13,320
这更像是我们的一个目标

471
00:00:13,640 --> 00:00:14,839
在做这方面的时候

472
00:00:14,839 --> 00:00:16,559
其中还一个就是说

473
00:00:17,280 --> 00:00:22,359
我们希望因为Chats B得回答的时候更多有些

474
00:00:23,640 --> 00:00:27,320
如果控制它的format去回答问题的方法

475
00:00:27,320 --> 00:00:28,120
我觉得这也是

476
00:00:00,000 --> 00:00:04,919
你当然也可以说我们可以通过更多的prompt去tuning去完成这些事情

477
00:00:05,160 --> 00:00:10,599
但如果你想有一个更加抗比较一致的体验的话

478
00:00:10,599 --> 00:00:13,720
觉得训练自己的模型会提高一些更加一致体验

479
00:00:13,720 --> 00:00:16,920
当然了做这件事情肯定是有它的代价的

480
00:00:17,600 --> 00:00:21,120
最明显的我目前看到几个明显的代价

481
00:00:21,120 --> 00:00:26,000
就除去所谓的工程成本或者说什么其他的成本

482
00:00:26,000 --> 00:00:27,399
包含这些都不提的话

483
00:00:00,000 --> 00:00:02,200
最明显的一个代价

484
00:00:02,200 --> 00:00:04,400
我认为就是文字质量

485
00:00:04,400 --> 00:00:08,679
这Chad GPT或者说其他大模型

486
00:00:08,679 --> 00:00:13,160
他们在大模型当中体现出一个特别和别人不一样

487
00:00:13,160 --> 00:00:15,439
就是他们的文字质量特别的高

488
00:00:15,439 --> 00:00:18,239
特别的像是一个人去说的东西

489
00:00:18,239 --> 00:00:19,920
而一些小的模型

490
00:00:19,920 --> 00:00:22,320
你去让他去完成一些短的东西

491
00:00:22,320 --> 00:00:23,879
或者说让去生成一些东西

492
00:00:23,879 --> 00:00:25,079
他会比较容易

493
00:00:25,079 --> 00:00:27,239
但是一旦生成比较长的时候

494
00:00:27,239 --> 00:00:29,600
他的文字质量或者说用词方法

495
00:00:00,000 --> 00:00:02,960
就会没有大模型用的那么好

496
00:00:02,960 --> 00:00:05,040
就是更大的模型用的那么好

497
00:00:05,040 --> 00:00:07,719
所以这是我发现的一个比较大的一个挑战

498
00:00:07,719 --> 00:00:10,199
其中一些做法可能也就是说

499
00:00:10,199 --> 00:00:14,880
像GPT模型学习或者是训练一个更大的模型

500
00:00:14,880 --> 00:00:19,000
然后从大的模型往小的模型去destill

501
00:00:19,000 --> 00:00:21,199
这些都是一些这样这方面的一些思路

502
00:00:21,199 --> 00:00:27,239
需要用大模型然后destill到小模型

503
00:00:00,000 --> 00:00:03,480
就是说明你的主要成本不是在训练模型上

504
00:00:03,480 --> 00:00:05,000
而是在使用模型inference上

505
00:00:05,000 --> 00:00:08,800
对主要成本将会是叫hosting cost

506
00:00:08,800 --> 00:00:12,679
就是因为这个大家可以算一算

507
00:00:12,679 --> 00:00:16,879
就是说一个模型它需要多少的GPU的RAM

508
00:00:16,879 --> 00:00:22,000
然后你其实如果要让这个模型一直能够available

509
00:00:22,000 --> 00:00:27,239
并且比如说你还要接受更长的sequence的话

510
00:00:00,000 --> 00:00:03,759
那可能他本身就是一个需要不是一个很便宜的机器

511
00:00:03,759 --> 00:00:09,080
如果一个56B和1B的可能这个成本就差的非常多了

512
00:00:09,080 --> 00:00:09,599
对

513
00:00:10,080 --> 00:00:10,640
对

514
00:00:10,640 --> 00:00:14,679
那这个说起来也就是说OpenAI他做的很聪明的一点

515
00:00:14,679 --> 00:00:17,399
就是我现在也觉得很神奇的地方

516
00:00:17,399 --> 00:00:20,559
就是他们能够把他们的hosting cost压的这么低

517
00:00:20,760 --> 00:00:23,480
让我觉得他们是我甚至怀疑他们

518
00:00:23,920 --> 00:00:26,559
你用OpenAI OpenAI要付给你钱使用的

519
00:00:26,559 --> 00:00:27,399
就是他们的

520
00:00:27,399 --> 00:00:27,879
对

521
00:00:00,000 --> 00:00:04,559
就是他们的host这些模型的成本实际上是相当高的

522
00:00:05,000 --> 00:00:06,519
但是对就两方面

523
00:00:06,519 --> 00:00:08,480
一方面它确实能压到很低

524
00:00:08,480 --> 00:00:13,480
比如说3.5就降价降了10倍

525
00:00:13,480 --> 00:00:18,079
对然后但是4很明显大家看到包括各种performance的问题

526
00:00:18,079 --> 00:00:20,280
肯定跟他的这个对

527
00:00:20,280 --> 00:00:22,600
这其实有一些大家说法就是说

528
00:00:22,600 --> 00:00:24,640
比如用甚至用GPS4的时候

529
00:00:24,640 --> 00:00:25,960
它虽然是一个大模型

530
00:00:25,960 --> 00:00:28,359
但是它最后它是生成的部分的时候

531
00:00:00,000 --> 00:00:02,399
他是用一些小模型尝试去做生成

532
00:00:02,399 --> 00:00:05,440
然后如果他叫speculative decoding

533
00:00:05,440 --> 00:00:07,480
这当然也是别人的一些猜测

534
00:00:07,480 --> 00:00:11,919
就是用一些小模型去做后面的几个步骤去做decoding的steps

535
00:00:11,919 --> 00:00:13,880
那去节省这个成本

536
00:00:13,880 --> 00:00:18,559
然后有些人也认为就是这个模型的效果变得更加的不好

537
00:00:18,559 --> 00:00:24,120
也是因为这个他让小的模型去speculate了更多

538
00:00:24,120 --> 00:00:26,199
而不是像原来那么保守

539
00:00:26,199 --> 00:00:28,960
都有这当时就是还是那句话

540
00:00:00,000 --> 00:00:01,120
就是大家都是猜测

541
00:00:01,120 --> 00:00:06,200
不过非常让人觉得震撼的就是他能够用这么便宜的价格

542
00:00:06,200 --> 00:00:07,000
就算是GPC

543
00:00:07,000 --> 00:00:11,000
我觉得也是一个非常便宜的价格去完成这件事情

544
00:00:11,000 --> 00:00:13,439
对因为他NPI收费也并不是这么贵

545
00:00:13,439 --> 00:00:15,000
对那即使他那么便宜

546
00:00:15,000 --> 00:00:18,120
你们仍然选择自己做

547
00:00:18,120 --> 00:00:23,719
对其实你刚才提到的为什么选自己做中的一个

548
00:00:23,719 --> 00:00:26,640
你提到一个是consistency

549
00:00:26,640 --> 00:00:27,719
然后另外一个

550
00:00:00,000 --> 00:00:02,560
我刚想到其实特别想跟大家讨论的

551
00:00:02,560 --> 00:00:04,879
其实就是大家经常诟病大模型的

552
00:00:04,879 --> 00:00:08,000
这个Hallucination这个问题

553
00:00:08,000 --> 00:00:10,800
当然我觉得支持者

554
00:00:10,800 --> 00:00:13,199
我说支持这个Hallucination是个硬伤的人

555
00:00:13,199 --> 00:00:16,079
总是能找出各种支持他的对吧

556
00:00:16,079 --> 00:00:19,199
他们在很多场景下他的不稳定

557
00:00:19,199 --> 00:00:21,519
然后会多么的mission critical

558
00:00:21,519 --> 00:00:23,600
但是我就好奇

559
00:00:23,600 --> 00:00:26,320
我相信柯代表在这方面肯定很有想法

560
00:00:26,320 --> 00:00:28,559
因为我经常在想说一个就是说

561
00:00:00,000 --> 00:00:04,960
首先这个是不是模型的一个硬伤

562
00:00:04,960 --> 00:00:07,480
就是它在不论是模型层面

563
00:00:07,480 --> 00:00:08,320
我现在应该怎么说

564
00:00:08,320 --> 00:00:09,839
就首先一个假设吧

565
00:00:09,839 --> 00:00:10,519
我们就不讨论那个

566
00:00:10,519 --> 00:00:13,560
就假设这个就是个统计模型的一个硬伤

567
00:00:13,560 --> 00:00:17,280
我们就是没有办法100%来去消灭这个

568
00:00:17,280 --> 00:00:18,559
Hallucination

569
00:00:18,559 --> 00:00:20,679
那么一个说从应用的角度

570
00:00:20,679 --> 00:00:22,519
我们是否可以在应用的层面

571
00:00:22,519 --> 00:00:25,079
其实可以把它降到它所在的那个

572
00:00:25,079 --> 00:00:27,160
场景里边其实一个可执行

573
00:00:27,160 --> 00:00:29,960
就是一个商用上已经make sense的一个地步

574
00:00:00,000 --> 00:00:01,399
另外一個就是說

575
00:00:01,399 --> 00:00:02,919
那我們應該怎麼看待

576
00:00:02,919 --> 00:00:03,799
hallucination這個問題

577
00:00:03,799 --> 00:00:04,559
就沒有hallucination

578
00:00:04,559 --> 00:00:05,879
就真的是更好嗎

579
00:00:05,879 --> 00:00:08,279
因為如果從人的角度來說

580
00:00:08,279 --> 00:00:09,119
我們覺得很多時候

581
00:00:09,119 --> 00:00:10,160
可能hallucination也是

582
00:00:10,160 --> 00:00:11,519
說實在人也有hallucination

583
00:00:11,519 --> 00:00:12,960
甚至可能hallucination也是

584
00:00:12,960 --> 00:00:15,160
我們有creativity

585
00:00:15,160 --> 00:00:16,239
就是創造力的

586
00:00:16,239 --> 00:00:19,320
是不是它也是一個硬幣的兩面

587
00:00:19,320 --> 00:00:20,719
那我們應該怎麼看待

588
00:00:20,719 --> 00:00:23,960
這個hallucination的這個問題

589
00:00:23,960 --> 00:00:24,679
所以

590
00:00:24,679 --> 00:00:25,559
要我可以嗎 現在

591
00:00:25,559 --> 00:00:27,079
你先說吧

592
00:00:27,079 --> 00:00:28,359
就是我剛笑

593
00:00:00,000 --> 00:00:02,000
就是因為人帶著hallucination太多了

594
00:00:02,000 --> 00:00:04,599
我覺得99%說

595
00:00:05,299 --> 00:00:07,400
GPT hallucination很有問題的人

596
00:00:07,400 --> 00:00:08,800
他們都在hallucination

597
00:00:09,199 --> 00:00:11,400
對 然後我自己還開玩笑說

598
00:00:11,400 --> 00:00:13,599
我這個項鏈戴在身上了以後

599
00:00:13,599 --> 00:00:15,199
可以prompting能力加5

600
00:00:15,199 --> 00:00:16,500
但是hallucination加10

601
00:00:16,899 --> 00:00:18,000
但是因為過於自信

602
00:00:18,000 --> 00:00:19,600
所以反而會顯得

603
00:00:20,000 --> 00:00:21,399
就是流量也可以增加

604
00:00:21,399 --> 00:00:22,699
因為hallucination太多

605
00:00:23,199 --> 00:00:24,899
包括我有一個很具體的例子

606
00:00:24,899 --> 00:00:27,600
就是我當時膝蓋踢球斷了

607
00:00:27,899 --> 00:00:29,199
然後其實第一次的時候

608
00:00:00,000 --> 00:00:01,219
只是一個小的撕裂

609
00:00:01,219 --> 00:00:02,220
然後去找醫生

610
00:00:02,220 --> 00:00:04,219
醫生說拍個X光

611
00:00:04,219 --> 00:00:05,459
沒事 骨頭沒事

612
00:00:05,459 --> 00:00:07,459
那你就休息兩個月就可以好

613
00:00:07,459 --> 00:00:08,419
我休息了兩個月

614
00:00:08,419 --> 00:00:10,259
然後再去踢5分鐘又斷了

615
00:00:10,259 --> 00:00:10,759
為什麼

616
00:00:10,759 --> 00:00:12,759
因為你需要拍那個MCR

617
00:00:12,759 --> 00:00:14,460
反而就是褐色公證

618
00:00:14,460 --> 00:00:15,759
你才能看到韌帶的情況

619
00:00:15,759 --> 00:00:17,059
韌帶其實當時已經撕裂了

620
00:00:17,059 --> 00:00:19,559
那我應該休息半年以上才行

621
00:00:19,559 --> 00:00:21,059
這就是一個醫生hallucinate

622
00:00:21,059 --> 00:00:22,519
然後導致了問題

623
00:00:22,519 --> 00:00:24,760
然後他也沒有任何的責任

624
00:00:24,760 --> 00:00:27,519
就是人類說什麼mission critical

625
00:00:27,519 --> 00:00:28,519
但是我覺得就是

626
00:00:00,000 --> 00:00:02,500
你如果看这个mission critical的上面各种各样的人

627
00:00:02,520 --> 00:00:03,859
能保证他们不hallucination吗

628
00:00:03,879 --> 00:00:04,700
我觉得没有

629
00:00:05,139 --> 00:00:07,700
所以我觉得那我们先不如说一下

630
00:00:07,700 --> 00:00:09,539
你认为什么叫hallucination

631
00:00:10,460 --> 00:00:12,580
就是他ok

632
00:00:13,140 --> 00:00:14,339
这是个好问题

633
00:00:14,339 --> 00:00:19,460
hallucination是我的这个答案是错的

634
00:00:19,460 --> 00:00:21,100
或者说不是最好的情况下

635
00:00:21,100 --> 00:00:22,379
我自我不知道

636
00:00:22,379 --> 00:00:23,780
我以为它是对的

637
00:00:23,780 --> 00:00:24,899
或者说是最好的

638
00:00:25,179 --> 00:00:29,300
那我们传统的积极学习的模型都会经常会出现

639
00:00:00,000 --> 00:00:05,599
比如说我们给了一个很高的confidence level

640
00:00:05,599 --> 00:00:06,679
然后是错的

641
00:00:06,679 --> 00:00:08,279
你认为这个是hallucination吗

642
00:00:08,279 --> 00:00:09,000
是

643
00:00:09,720 --> 00:00:11,640
还是你认为这只是犯了一个错误

644
00:00:12,759 --> 00:00:13,880
就是统计上的错误

645
00:00:13,880 --> 00:00:14,919
比如说我们举个例子

646
00:00:15,400 --> 00:00:18,199
这个东西是一个student t-test

647
00:00:18,600 --> 00:00:20,640
它的一个p-value达到这个东西

648
00:00:20,640 --> 00:00:21,920
但它实际上并不是

649
00:00:21,920 --> 00:00:22,800
明白了

650
00:00:22,800 --> 00:00:25,160
那你认为你做的这个决定

651
00:00:25,160 --> 00:00:27,320
说他们俩你reject或者accept

652
00:00:00,000 --> 00:00:02,879
这个non-hypothesis是不是hallucination

653
00:00:02,879 --> 00:00:03,359
不是

654
00:00:03,799 --> 00:00:07,000
不是因为它是带着就是它的p-value

655
00:00:07,000 --> 00:00:07,440
对吧

656
00:00:07,440 --> 00:00:08,720
p-value的意义就是说

657
00:00:08,720 --> 00:00:09,759
就是代表你很

658
00:00:09,759 --> 00:00:10,759
那就是

659
00:00:10,759 --> 00:00:12,080
但你根据这个p-value

660
00:00:12,080 --> 00:00:13,679
你很有信心

661
00:00:14,400 --> 00:00:15,960
然后你做出了一个错误的决定

662
00:00:15,960 --> 00:00:17,440
你认为你在hallucinate吗

663
00:00:17,600 --> 00:00:18,079
不觉得

664
00:00:18,079 --> 00:00:20,399
我觉得我的信心是带probability的

665
00:00:20,399 --> 00:00:22,879
就是我接受它出1%的错误

666
00:00:22,879 --> 00:00:24,440
模型也是这么觉得的

667
00:00:24,559 --> 00:00:25,000
对

668
00:00:25,000 --> 00:00:25,920
对啊

669
00:00:25,920 --> 00:00:28,920
模型在每一次生成一个新的token的时候

670
00:00:00,000 --> 00:00:02,879
它其实都会生成一个概率对吗

671
00:00:02,879 --> 00:00:04,360
就是说我有多少个概率

672
00:00:04,360 --> 00:00:06,599
生成的下一个token是这个token

673
00:00:06,599 --> 00:00:08,160
然后他犯了错误

674
00:00:08,160 --> 00:00:10,160
你为什么称他叫hallucination

675
00:00:10,160 --> 00:00:12,439
我觉得孟大军他是很自信的

676
00:00:12,439 --> 00:00:12,720
对吧

677
00:00:12,720 --> 00:00:13,880
很一本正经的

678
00:00:13,880 --> 00:00:14,160
很好的问题

679
00:00:14,160 --> 00:00:14,880
我没有这么想过

680
00:00:14,880 --> 00:00:16,320
但是我现在想的话就是说

681
00:00:16,320 --> 00:00:17,120
模型知道

682
00:00:17,120 --> 00:00:18,000
但是人不知道

683
00:00:18,000 --> 00:00:18,960
人很多

684
00:00:18,960 --> 00:00:21,679
就是人为什么我们会用hallucination去称这件事情

685
00:00:21,679 --> 00:00:23,280
因为它其实是一个人的行为

686
00:00:23,280 --> 00:00:24,640
人为什么会有这种行为呢

687
00:00:24,640 --> 00:00:28,280
因为人很多时候把opinion和facts给混淆起来

688
00:00:00,000 --> 00:00:03,000
把自己错误的观点非常有自信的给说出来

689
00:00:03,000 --> 00:00:06,759
然后他在用这个观点去说的时候

690
00:00:06,759 --> 00:00:10,480
其实imply的是我对这件事情的probability非常之高

691
00:00:10,480 --> 00:00:11,839
实际上可能非常之低

692
00:00:11,839 --> 00:00:15,000
但是Chai TPT在跟人进行alignment的时候

693
00:00:15,000 --> 00:00:18,800
他在学习人类说话的时候

694
00:00:18,800 --> 00:00:22,320
他哪怕对这件事情assign的事实概率是30%

695
00:00:22,320 --> 00:00:25,879
但是他的语气给你的感受是90%

696
00:00:25,879 --> 00:00:28,320
那你觉得如果他同样说这句话

697
00:00:00,000 --> 00:00:02,839
但是他说我其实可能没有那么确定

698
00:00:02,839 --> 00:00:04,719
我觉得加一个maybe

699
00:00:04,719 --> 00:00:06,679
你会觉得这个就不是hallucination了吗

700
00:00:07,360 --> 00:00:09,560
我觉得从这个就是这个词

701
00:00:09,560 --> 00:00:11,679
我没有精确定义的情况下

702
00:00:11,679 --> 00:00:15,080
我觉得我可以接受它不是hallucination

703
00:00:15,080 --> 00:00:16,120
明白你的意思

704
00:00:16,120 --> 00:00:18,039
以及我从头到尾我都觉得

705
00:00:18,039 --> 00:00:20,359
CHPT表现出来很多hallucination

706
00:00:20,359 --> 00:00:22,199
比我见到的人真的是少太多了

707
00:00:22,199 --> 00:00:23,719
就是对啊

708
00:00:23,719 --> 00:00:25,280
就比如说李彦宏说什么

709
00:00:25,280 --> 00:00:26,440
我们两个月可以做出来

710
00:00:26,440 --> 00:00:27,480
我就还是两个周

711
00:00:27,480 --> 00:00:28,280
我就他说就

712
00:00:00,000 --> 00:00:02,000
就是人類的

713
00:00:02,000 --> 00:00:04,000
或者我看網上的新聞

714
00:00:04,000 --> 00:00:05,000
對吧 天啊

715
00:00:05,000 --> 00:00:07,000
我覺得我們可以舉幾個

716
00:00:07,000 --> 00:00:09,000
就是關於這個所謂

717
00:00:09,000 --> 00:00:10,000
hallucination的幾個

718
00:00:10,000 --> 00:00:11,000
比較常見的例子

719
00:00:11,000 --> 00:00:12,000
我覺得一個就是

720
00:00:12,000 --> 00:00:13,000
比如說我們這樣

721
00:00:13,000 --> 00:00:14,000
但是我是站在就是

722
00:00:14,000 --> 00:00:16,000
hallucination不是那麼重要

723
00:00:16,000 --> 00:00:19,000
和這是一個可以被技術解決

724
00:00:19,000 --> 00:00:21,000
就是你去適配不同的situation

725
00:00:21,000 --> 00:00:24,000
去做不同的解決方案的這一派

726
00:00:24,000 --> 00:00:25,000
所以你可能你跟我

727
00:00:25,000 --> 00:00:26,000
我沒有

728
00:00:26,000 --> 00:00:27,000
我其實沒有什麼特別的觀點

729
00:00:27,000 --> 00:00:29,000
就是說hallucination好還是不好

730
00:00:00,000 --> 00:00:02,680
或者是能不能消灭

731
00:00:02,680 --> 00:00:05,040
其实我并没有一个特别确切的观点

732
00:00:05,040 --> 00:00:06,080
我只是有一些

733
00:00:06,080 --> 00:00:09,439
当然了我们讨论的就是探索这些想法

734
00:00:09,439 --> 00:00:11,960
我自己看到就是我们认为为什么说

735
00:00:11,960 --> 00:00:13,119
HelloSense非常的明显

736
00:00:13,119 --> 00:00:14,080
举个例子

737
00:00:14,080 --> 00:00:14,759
就是比如说

738
00:00:14,759 --> 00:00:17,079
AutoGPT或者LineChain在完成这件事情的时候

739
00:00:17,079 --> 00:00:19,480
它会去生成这个东西的

740
00:00:19,480 --> 00:00:23,359
这个这个tool或者这个function所需要的input

741
00:00:23,359 --> 00:00:23,719
对吧

742
00:00:23,719 --> 00:00:25,559
它需要的输入应该是什么

743
00:00:25,559 --> 00:00:27,600
很多时候它有的时候不能说很多时候

744
00:00:27,600 --> 00:00:29,800
就是有过人们发现过

745
00:00:00,000 --> 00:00:02,500
就是他会生成一些完全不存在的东西

746
00:00:02,500 --> 00:00:04,299
比如说医疗的paper

747
00:00:04,299 --> 00:00:05,299
根本就没有这个paper

748
00:00:05,299 --> 00:00:07,000
对就是什么johndoe到

749
00:00:07,000 --> 00:00:08,000
直播到com

750
00:00:08,000 --> 00:00:10,900
他会就真的是直接就说是johndoe

751
00:00:10,900 --> 00:00:13,900
然后就他不会说不是这是一种类型

752
00:00:13,900 --> 00:00:15,099
还有一种就是像你说的

753
00:00:15,300 --> 00:00:18,000
那种我在描述一件事情的时候

754
00:00:18,500 --> 00:00:19,899
不光我的观点是错的

755
00:00:20,100 --> 00:00:21,399
我还说了一些论据

756
00:00:21,399 --> 00:00:22,699
这些论据本身是不存在的

757
00:00:22,699 --> 00:00:25,100
对那这种也是合乳死年史对吧

758
00:00:25,100 --> 00:00:27,100
然后我觉得你说的第二种

759
00:00:27,100 --> 00:00:28,899
更像是人也会发生了一些问题

760
00:00:28,899 --> 00:00:29,899
就像记忆的时候

761
00:00:00,000 --> 00:00:01,919
我记得好像有这么一篇文章

762
00:00:01,919 --> 00:00:03,080
去说这件事情

763
00:00:03,080 --> 00:00:04,080
但实际上并没有

764
00:00:04,080 --> 00:00:05,960
我只是把两篇文章混在一起了

765
00:00:05,960 --> 00:00:06,480
对

766
00:00:06,480 --> 00:00:07,400
但他我非常

767
00:00:07,400 --> 00:00:08,560
那我就说

768
00:00:08,560 --> 00:00:09,880
就因为这么一篇文章

769
00:00:09,880 --> 00:00:11,359
Hello, CNN这个词本来就是一个

770
00:00:11,359 --> 00:00:12,199
Human Behavior

771
00:00:12,199 --> 00:00:14,279
然后Behavior就是我看到的

772
00:00:14,279 --> 00:00:15,839
是出现小人了是吧

773
00:00:15,839 --> 00:00:16,320
对

774
00:00:16,320 --> 00:00:17,000
就是这样的

775
00:00:17,000 --> 00:00:17,800
然后我

776
00:00:18,039 --> 00:00:19,160
他这个词就是

777
00:00:19,160 --> 00:00:21,199
我看到的出现小人了

778
00:00:21,199 --> 00:00:21,480
对

779
00:00:21,480 --> 00:00:22,839
就这个意思

780
00:00:22,839 --> 00:00:23,440
嗯

781
00:00:23,800 --> 00:00:25,679
那这个东西到底就是

782
00:00:25,679 --> 00:00:28,440
我觉得可能大家觉得它不好的原因

783
00:00:00,000 --> 00:00:03,359
就是因为我们对机器的期待并不希望他们做一些

784
00:00:03,359 --> 00:00:04,719
creativity task

785
00:00:04,719 --> 00:00:06,919
我们对机器的期待和习惯

786
00:00:06,919 --> 00:00:11,320
对我们和他们的习惯更多的是说机器就是有确定性的

787
00:00:11,320 --> 00:00:12,640
他在做的这些事情

788
00:00:12,640 --> 00:00:15,439
我用电脑去完成这件事情

789
00:00:15,439 --> 00:00:17,600
就是因为人也可以做

790
00:00:17,600 --> 00:00:19,079
但你做的效率更高

791
00:00:19,079 --> 00:00:20,320
而且你不会犯错

792
00:00:20,320 --> 00:00:22,160
所以我才让你去用电脑

793
00:00:22,160 --> 00:00:25,399
这可能是我们之前使用一些机器或者工具的习惯

794
00:00:25,399 --> 00:00:26,600
这导致我发现

795
00:00:26,600 --> 00:00:28,280
我现在用到这个工具

796
00:00:00,000 --> 00:00:02,799
我有一定概率這個工具會失敗

797
00:00:02,799 --> 00:00:05,500
變成了一件不是很好接受的事情

