1
00:00:00,000 --> 00:00:02,560
來分享他們的見解和經驗

2
00:00:02,560 --> 00:00:06,400
討論ChairGBT在不同領域中的應用和挑戰

3
00:00:06,400 --> 00:00:09,480
以及未來發展方向的可能性

4
00:00:09,480 --> 00:00:13,039
在這裡我希望大家能夠積極參與

5
00:00:13,039 --> 00:00:15,039
共同學習與交流

6
00:00:15,039 --> 00:00:17,039
謝謝大家

7
00:00:17,039 --> 00:00:19,039
開個玩笑

8
00:00:19,039 --> 00:00:21,920
那麼我剛剛念的就是ChairGBT

9
00:00:21,920 --> 00:00:24,879
為這一場分享會做的開場準備

10
00:00:24,879 --> 00:00:28,679
接下來就是我真人的開場白了

11
00:00:00,000 --> 00:00:01,800
就是我叫周恩傑

12
00:00:01,800 --> 00:00:04,299
騰訊IEG讀書協會

13
00:00:04,299 --> 00:00:10,199
終於就是邀請到了一位非常不錯的一個業內大咖

14
00:00:10,199 --> 00:00:11,199
來為我們做分享

15
00:00:11,199 --> 00:00:12,699
這是我們第一次嘗試

16
00:00:12,699 --> 00:00:20,699
那麼孫一正是我們騰訊IEG數據增長數據科學的副總監

17
00:00:20,699 --> 00:00:22,199
然後在B站上面的話

18
00:00:22,199 --> 00:00:25,800
會也有一個帳號叫科代表立正

19
00:00:25,800 --> 00:00:29,300
那麼大家可以就叫科代表立正

20
00:00:00,000 --> 00:00:06,599
然後非常感謝大佬能為我們做一個這樣的非常寶貴的分享

21
00:00:06,599 --> 00:00:11,000
然後話不多說就是我們即將開始

22
00:00:11,000 --> 00:00:15,000
那麼在會前的話我們說一下現場的一些流程跟秩序

23
00:00:15,000 --> 00:00:18,600
就是我們中間有十分鐘的中場休息

24
00:00:18,600 --> 00:00:21,399
這個的話由講師來自由去安排

25
00:00:21,399 --> 00:00:25,199
然後結束的時間也可以有一個QA環節

26
00:00:25,199 --> 00:00:27,199
就是大家有感興趣的問題的話

27
00:00:00,000 --> 00:00:03,799
可以自由的跟我們講師做一個互動

28
00:00:05,400 --> 00:00:07,559
然後茶水間的話有水和咖啡

29
00:00:07,559 --> 00:00:09,800
大家可以就是去自取

30
00:00:10,160 --> 00:00:12,800
會場期間的話也可以親身的走動

31
00:00:13,400 --> 00:00:13,900
OK

32
00:00:14,400 --> 00:00:14,900
好

33
00:00:15,300 --> 00:00:15,800
有請

34
00:00:20,800 --> 00:00:21,500
大家好

35
00:00:21,600 --> 00:00:23,559
對我剛剛在座位下面聽

36
00:00:23,559 --> 00:00:25,899
我想我怎麼有精神分裂了嗎

37
00:00:25,899 --> 00:00:28,300
怎麼我請他們專家們

38
00:00:28,300 --> 00:00:29,960
然後我一個人

39
00:00:00,000 --> 00:00:03,140
但是你說話得罪了一些人

40
00:00:03,140 --> 00:00:05,500
你剛剛說了一個終於請來了一位

41
00:00:05,500 --> 00:00:09,580
就顯得好像之前請的那些同學不是很行的樣子

42
00:00:09,580 --> 00:00:13,419
所以說不知道陳水扁聽的情商高還是你的情商高一點

43
00:00:13,419 --> 00:00:16,859
我今天想這個就是

44
00:00:16,859 --> 00:00:19,820
在群裡也有分享我寫的那個文章嘛

45
00:00:19,820 --> 00:00:21,660
其實我因為自己有一個頻道

46
00:00:21,660 --> 00:00:22,940
然後自己平時也愛寫作

47
00:00:22,940 --> 00:00:24,379
然後包括寫了一些文章

48
00:00:24,379 --> 00:00:27,019
我覺得科普校的東西其實我已經講得差不多了

49
00:00:00,000 --> 00:00:04,080
就是我觉得如果花大家的时间到了现场

50
00:00:04,120 --> 00:00:07,440
我再把我之前说的那些东西重新再给大家讲一遍

51
00:00:07,480 --> 00:00:08,839
我自己也觉得挺无聊的

52
00:00:08,839 --> 00:00:11,359
然后大家其实可以回去看

53
00:00:11,400 --> 00:00:14,960
也没有必要在这再去听我去讲一遍

54
00:00:15,080 --> 00:00:18,679
但是我也相信很多同学是不会去看那个文章的

55
00:00:18,679 --> 00:00:22,640
所以说我们想照顾一下大家的同学们的感觉

56
00:00:22,800 --> 00:00:25,239
那我想就是拆GPT是一个什么形式呢

57
00:00:25,440 --> 00:00:27,719
拆GPT它是背后有一个大模型

58
00:00:27,760 --> 00:00:29,280
然后这个大模型有很多知识

59
00:00:00,000 --> 00:00:01,360
然後他有很多能力

60
00:00:01,360 --> 00:00:03,399
大家通過對話的方式去激活

61
00:00:03,399 --> 00:00:05,240
然後得到你想要的東西對不對

62
00:00:05,240 --> 00:00:07,599
我今天在這就辦一個ChatsPT

63
00:00:07,599 --> 00:00:09,519
就是我會稍稍講一下

64
00:00:09,519 --> 00:00:13,119
就是我有一個更短的那個

65
00:00:13,119 --> 00:00:15,800
一個英文的就是PPT

66
00:00:15,800 --> 00:00:19,359
我會大概花10到15分鐘的時間講一下那個PPT

67
00:00:19,359 --> 00:00:20,480
然後講完了以後呢

68
00:00:20,480 --> 00:00:21,879
我就坐在這裡了

69
00:00:21,879 --> 00:00:23,120
然後我就是一個ChatsPT了

70
00:00:23,120 --> 00:00:25,199
然後請大家來問我問題

71
00:00:25,199 --> 00:00:26,719
包括我那個文檔裡邊

72
00:00:00,000 --> 00:00:02,359
我其實也有說在這個

73
00:00:02,359 --> 00:00:03,399
Chai GPT 紀元

74
00:00:03,399 --> 00:00:04,799
現在叫AGI紀元吧

75
00:00:04,799 --> 00:00:06,960
提問的能力會是一個非常非常重要的能力

76
00:00:06,960 --> 00:00:09,480
所以說我們期待大家提一些問題

77
00:00:09,480 --> 00:00:11,880
不管這個問題是什麼樣子的

78
00:00:11,880 --> 00:00:13,839
都我相信啊

79
00:00:13,839 --> 00:00:15,240
就是只要你提問

80
00:00:15,240 --> 00:00:16,199
你今天肯定是賺的

81
00:00:16,199 --> 00:00:17,039
就是你不提問的話

82
00:00:17,039 --> 00:00:18,480
這個問題在你的肚子裡邊

83
00:00:18,480 --> 00:00:19,839
然後你現在提出來了

84
00:00:19,839 --> 00:00:22,239
你起碼可以幫助你自己把這個問題想得清楚一點吧

85
00:00:22,239 --> 00:00:23,800
就是我的回答不一定有用

86
00:00:23,800 --> 00:00:26,000
但是你去提問了這件事情

87
00:00:26,000 --> 00:00:28,559
對你來說應該都是有好處的

88
00:00:28,559 --> 00:00:29,760
然後再多說一點點

89
00:00:00,000 --> 00:00:04,799
就是我也是之前我在這個公司裡邊也試過這樣的形式啊

90
00:00:04,799 --> 00:00:07,200
我在IEG講過一個DS的課

91
00:00:07,200 --> 00:00:12,599
然後我在KM講過一個就是直播講了一個寫作的課

92
00:00:12,599 --> 00:00:19,199
那兩個課我都試圖說我先把寫的東西給大家寫清楚

93
00:00:19,199 --> 00:00:21,600
然後大家之前看一下

94
00:00:21,600 --> 00:00:24,000
我甚至在這個課堂為了照顧大家不看

95
00:00:24,000 --> 00:00:27,699
我說我們在這個課的一開始的10分鐘15分鐘

96
00:00:27,699 --> 00:00:29,399
我們一起把這個文章讀完

97
00:00:00,000 --> 00:00:01,000
讀完了以後呢

98
00:00:01,000 --> 00:00:03,299
然後我們再根據文章的內容去提問

99
00:00:03,299 --> 00:00:04,700
我就不需要從頭過一遍了

100
00:00:04,700 --> 00:00:06,900
結果後來就得到了很多差評

101
00:00:06,900 --> 00:00:08,500
就大家說這個人怎麼這樣子

102
00:00:08,500 --> 00:00:11,099
就是他不講這個文章

103
00:00:11,099 --> 00:00:12,300
然後就讓我們直接問

104
00:00:12,300 --> 00:00:13,300
我們也不知道問什麼

105
00:00:13,300 --> 00:00:17,100
所以我就稍稍再多說一點點

106
00:00:17,100 --> 00:00:19,600
就是我為什麼就是在課前

107
00:00:19,600 --> 00:00:21,399
大家如果看時間的話就是兩分鐘

108
00:00:21,399 --> 00:00:22,699
可能上課之前兩分鐘

109
00:00:22,699 --> 00:00:23,899
我突然想起來了一件事

110
00:00:23,899 --> 00:00:25,399
就是我自己的

111
00:00:25,399 --> 00:00:27,699
我自己的這個視頻裡面

112
00:00:00,000 --> 00:00:03,799
我覺得頻道裡面我覺得有這樣一個視頻是很有意思的

113
00:00:03,799 --> 00:00:06,000
或者說我挺推薦大家看的

114
00:00:06,000 --> 00:00:09,000
他也被很多大佬們推薦過

115
00:00:09,000 --> 00:00:10,800
甚至就是他的播放量不高啊

116
00:00:10,800 --> 00:00:13,099
但是比如說兩周之前

117
00:00:13,099 --> 00:00:16,000
創夢天地就是在那個A1的

118
00:00:16,000 --> 00:00:19,500
就是那個A洞的一個公司

119
00:00:19,500 --> 00:00:21,600
他們CEO找我聊天

120
00:00:21,600 --> 00:00:23,399
然後說他從來不發朋友圈

121
00:00:23,399 --> 00:00:26,800
但是他分享了這個視頻給他們的員工看

122
00:00:26,800 --> 00:00:28,399
和發在他的朋友圈裡面

123
00:00:00,000 --> 00:00:01,639
就是他還是有點意思的

124
00:00:01,639 --> 00:00:02,439
他有點的

125
00:00:02,439 --> 00:00:03,759
他有點意思呢

126
00:00:03,759 --> 00:00:07,559
就是說我們在面對自己的每一個行為的時候

127
00:00:07,599 --> 00:00:11,800
其實都可以抱著一個固定思維或者成長思維去看這件事

128
00:00:12,039 --> 00:00:14,720
比如說我們如果說是一個固定思維去

129
00:00:15,000 --> 00:00:16,760
看自己的這個提問會覺得啊

130
00:00:16,760 --> 00:00:18,440
我是不是問了一個特別蠢的問題

131
00:00:18,559 --> 00:00:20,760
然後是不是別人會覺得我水平不行

132
00:00:20,960 --> 00:00:22,920
但是其實沒有人會關注的

133
00:00:22,920 --> 00:00:23,879
沒有人會記得的

134
00:00:23,920 --> 00:00:25,879
就是如果大家去想一下

135
00:00:25,960 --> 00:00:27,079
你之前開了會

136
00:00:27,120 --> 00:00:28,079
如果有一個人問的問題

137
00:00:28,079 --> 00:00:29,480
你還記不記得這個問題是誰問的

138
00:00:00,000 --> 00:00:02,120
不管他多麼的出彩和多麼的愚蠢

139
00:00:02,120 --> 00:00:03,319
你最後都不會記得的

140
00:00:04,000 --> 00:00:05,759
但成長性思維就是說

141
00:00:05,759 --> 00:00:06,719
我來了

142
00:00:06,759 --> 00:00:07,919
我花時間在這了

143
00:00:07,919 --> 00:00:09,919
我用了這個機會去問了一個問題

144
00:00:09,919 --> 00:00:11,480
然後這個問題對我來說是有用的

145
00:00:11,480 --> 00:00:12,679
那你就得到了成長

146
00:00:12,759 --> 00:00:16,640
這其實是一個我覺得起碼可以讓自己更快樂一點的方式

147
00:00:17,000 --> 00:00:21,160
然後第二個是我接下來的那個視頻的副標題

148
00:00:21,199 --> 00:00:23,800
那個不是接下來那個PPT的副標題

149
00:00:24,000 --> 00:00:28,280
那個PPT的副標題是我們三年之內是不是要去做一個喬久石

150
00:00:28,480 --> 00:00:29,920
我是認真的思考了這件事情

151
00:00:00,000 --> 00:00:02,279
所以说就是我去采访了乔九师

152
00:00:02,279 --> 00:00:05,000
然后去了解这个行业的各种各样的

153
00:00:05,280 --> 00:00:06,599
他到底是要干什么呀

154
00:00:06,599 --> 00:00:08,240
怎么样子做一个好的乔九师

155
00:00:08,519 --> 00:00:11,400
我是真的在很认真的去想这件事情啊

156
00:00:11,400 --> 00:00:14,560
所以说大家也可以就是

157
00:00:16,199 --> 00:00:19,640
就是现在昨天我还听了一个沐瑶的播客

158
00:00:19,879 --> 00:00:23,199
他说他观察到现在很多人在聊ChattyPT

159
00:00:23,199 --> 00:00:24,920
是一个看热闹的心态

160
00:00:25,320 --> 00:00:27,359
就是无论你是焦虑也好

161
00:00:27,359 --> 00:00:28,839
或者说是想了解也罢

162
00:00:00,000 --> 00:00:02,799
或者说是看自己对自己有什么意义

163
00:00:02,799 --> 00:00:04,799
其实还是抱着一个看热闹的心态

164
00:00:04,799 --> 00:00:08,279
没有觉得这个东西真真切切的跟自己那么有关

165
00:00:08,279 --> 00:00:09,439
而且在看热闹的过程中

166
00:00:09,439 --> 00:00:12,960
大家也会借题发挥的去抒发一些自己的焦虑啊

167
00:00:12,960 --> 00:00:13,919
对现实的不满啊

168
00:00:13,919 --> 00:00:15,080
或者说是一些想法

169
00:00:15,880 --> 00:00:16,920
但是这不是一个热闹

170
00:00:16,920 --> 00:00:18,519
这个是真实发生的事儿

171
00:00:19,359 --> 00:00:20,960
我反正是去

172
00:00:21,160 --> 00:00:24,399
就是我会真的去认真的思考这件事情的

173
00:00:24,399 --> 00:00:25,199
所以说

174
00:00:26,000 --> 00:00:26,800
也希望吧

175
00:00:26,800 --> 00:00:28,160
就是今天这个机会

176
00:00:00,000 --> 00:00:02,299
大家可以打破一點這種看熱鬧的心態

177
00:00:02,299 --> 00:00:05,259
去認真的去思考和認真的

178
00:00:05,259 --> 00:00:06,540
不管你的思考是什麼

179
00:00:06,540 --> 00:00:08,460
我覺得行動總比不行動好

180
00:00:08,859 --> 00:00:10,539
第三個呢是

181
00:00:10,539 --> 00:00:12,859
我在會場之前

182
00:00:12,859 --> 00:00:14,019
我記錯時間了

183
00:00:14,019 --> 00:00:15,140
我以為是三點鐘開始

184
00:00:15,140 --> 00:00:16,339
所以說我就很早就來了

185
00:00:16,339 --> 00:00:17,899
然後很早就來了就在那無聊

186
00:00:17,899 --> 00:00:19,579
然後就看這個第三個視頻

187
00:00:19,579 --> 00:00:21,140
這段視頻我沒有看完

188
00:00:21,140 --> 00:00:23,059
但是他說的這個內容

189
00:00:23,059 --> 00:00:25,019
我覺得就非常非常的有共鳴

190
00:00:25,019 --> 00:00:28,019
他說的他當中間引用了一句話

191
00:00:00,000 --> 00:00:03,480
就是說某個另外的大咖說的一句話是

192
00:00:03,480 --> 00:00:06,879
一百個說話的人不如一個思考的人

193
00:00:06,879 --> 00:00:10,320
但是一千個思考的人不如一個看見的人

194
00:00:10,320 --> 00:00:14,039
就是他覺得一個思想者能做的最重要的事情

195
00:00:14,039 --> 00:00:15,919
就是看到這個世界真實的情況

196
00:00:15,919 --> 00:00:18,800
並且把這個真實的情況給人風不動地說出來

197
00:00:20,679 --> 00:00:22,000
我在努力做這件事

198
00:00:22,000 --> 00:00:24,719
但是我也希望大家就是和我一起做這件事

199
00:00:24,719 --> 00:00:27,519
我希望今天的這個對話吧

200
00:00:27,519 --> 00:00:28,879
或者說是提問

201
00:00:00,000 --> 00:00:03,080
大家可以和我一起來去做這件事情

202
00:00:04,719 --> 00:00:06,360
這就是一個簡單的開場

203
00:00:11,919 --> 00:00:13,000
這是那個文章

204
00:00:14,919 --> 00:00:15,400
好的

205
00:00:15,400 --> 00:00:17,000
這個是PPT

206
00:00:17,000 --> 00:00:22,079
這個PPT的意義就是給大家來一個簡單的科普和介紹一下我的思考框架

207
00:00:22,079 --> 00:00:23,440
這些東西都會發在

208
00:00:23,440 --> 00:00:26,640
就是在那個群裡面是發了文章的

209
00:00:00,000 --> 00:00:03,600
然後文章的第一個第一行就是一個PPT的鏈接

210
00:00:03,600 --> 00:00:04,799
所以說大家都有這個PPT了

211
00:00:06,200 --> 00:00:08,800
對就是五個關於ChatshipT的問題

212
00:00:09,199 --> 00:00:12,160
那麼為什麼放英文

213
00:00:12,160 --> 00:00:15,400
因為很多時候發現討論還是需要在跟

214
00:00:15,900 --> 00:00:17,500
在一個英文的語境下討論

215
00:00:17,899 --> 00:00:18,800
對

216
00:00:19,800 --> 00:00:21,399
五個問題

217
00:00:22,000 --> 00:00:23,500
其實就這樣五個

218
00:00:23,500 --> 00:00:25,699
第一個就是我們要理解ChatshipT

219
00:00:25,699 --> 00:00:26,500
它到底是什麼

220
00:00:26,500 --> 00:00:28,800
它到底是一個平平無奇的技術

221
00:00:00,000 --> 00:00:02,200
還是一個真正不一樣的技術

222
00:00:02,200 --> 00:00:04,040
而且這個問題其實是很多大佬

223
00:00:04,040 --> 00:00:05,759
和大佬之間是有分歧的

224
00:00:05,759 --> 00:00:08,000
就是樂坤等等吧

225
00:00:08,000 --> 00:00:09,839
包括我自己認識的很多大佬

226
00:00:09,839 --> 00:00:12,160
他們都會對這件事情有不同的理解

227
00:00:12,160 --> 00:00:13,839
可是明顯大家也看到了

228
00:00:13,839 --> 00:00:15,000
就是越來越多的大佬

229
00:00:15,000 --> 00:00:17,480
會覺得它是一個很不一樣的技術突破

230
00:00:17,480 --> 00:00:18,600
所以說這個問題

231
00:00:18,600 --> 00:00:20,800
我們要有一個自己的判斷

232
00:00:20,800 --> 00:00:21,640
那第二個問題呢

233
00:00:21,640 --> 00:00:23,559
就是如何理解它的意義

234
00:00:23,559 --> 00:00:26,199
就是大家會打很多類比

235
00:00:26,199 --> 00:00:27,000
當然這些類比

236
00:00:27,000 --> 00:00:28,800
你如果不是真的理解它的意義的話

237
00:00:28,800 --> 00:00:29,960
類比是沒有意義的

238
00:00:00,000 --> 00:00:01,600
类比本身是没有意义的

239
00:00:01,600 --> 00:00:04,480
就比如说有的人会说这是第四次工业革命

240
00:00:04,480 --> 00:00:06,480
但是我们这句话听了100遍了对吧

241
00:00:06,480 --> 00:00:08,359
就是什么web story是第四次工业革命

242
00:00:08,359 --> 00:00:09,439
VR是第四次工业革命

243
00:00:09,439 --> 00:00:11,519
然后所有东西都是第四次工业革命

244
00:00:11,519 --> 00:00:13,759
那到底这个是不是第四次工业革命

245
00:00:13,759 --> 00:00:15,800
或者说前三次工业革命到底是什么

246
00:00:15,800 --> 00:00:18,800
我觉得这个我们要去真正的去理解一下

247
00:00:18,800 --> 00:00:22,359
第三个呢就是它容不容易复现

248
00:00:22,359 --> 00:00:23,960
这个其实我不知道

249
00:00:23,960 --> 00:00:26,039
但是我会给大家说一下我的

250
00:00:26,039 --> 00:00:29,000
就是想这个问题的决策框架吧

251
00:00:00,000 --> 00:00:02,000
或者是決策數,就是我看到了什麼

252
00:00:02,000 --> 00:00:03,339
我會覺得它容易浮現

253
00:00:03,339 --> 00:00:05,339
但是我現在默認狀態是我覺得什麼

254
00:00:05,339 --> 00:00:08,179
第四個就是我們怎麼樣去使用它

255
00:00:08,179 --> 00:00:11,720
第五個就是人和Chai GPT到底有什麼區別

256
00:00:13,720 --> 00:00:15,980
這裡有一個最最基本的科普

257
00:00:18,219 --> 00:00:20,519
第一個就是Chai GPT它的原理是什麼

258
00:00:20,519 --> 00:00:23,359
它的原理是它的這個底層的大模型

259
00:00:23,359 --> 00:00:27,440
是一個叫Generative Autoregressive Large Language Model

260
00:00:27,440 --> 00:00:29,440
這幾個關鍵詞

261
00:00:00,000 --> 00:00:01,639
Generative就是生成性

262
00:00:01,639 --> 00:00:04,480
生成性就是说它是在做一个生成任务

263
00:00:04,480 --> 00:00:05,679
我们看到了一个模型

264
00:00:05,679 --> 00:00:07,120
我们可以给它不同的任务

265
00:00:07,120 --> 00:00:10,439
比如说你把这个数据去进行分类

266
00:00:10,439 --> 00:00:11,640
这是一个分类模型

267
00:00:11,640 --> 00:00:12,759
你去理解它

268
00:00:12,759 --> 00:00:14,000
这是一个理解模型

269
00:00:14,000 --> 00:00:16,239
那ChHbt它是一个生成模型

270
00:00:16,239 --> 00:00:18,239
它所做的就是给你一堆数据以后

271
00:00:18,239 --> 00:00:20,280
你想方设法的去生成下一个词

272
00:00:20,280 --> 00:00:21,280
这个叫生成

273
00:00:21,280 --> 00:00:24,199
然后AutoRegressive是自回归

274
00:00:24,199 --> 00:00:25,920
就是说你生成了这个词以后

275
00:00:25,920 --> 00:00:27,519
你再把这些作为你的这个数据

276
00:00:00,000 --> 00:00:02,960
输入数据再去生成下一个词

277
00:00:02,960 --> 00:00:05,480
那这个大语言模型大家就知道了

278
00:00:05,480 --> 00:00:06,839
就是它数据量大参数量大

279
00:00:06,839 --> 00:00:09,439
它是一个非常大的关于语言的模型

280
00:00:09,439 --> 00:00:10,800
现在它有了多模态

281
00:00:10,800 --> 00:00:12,359
但是它的怎么说呢

282
00:00:12,359 --> 00:00:15,000
就是从历史或者它的重点来看的话

283
00:00:15,000 --> 00:00:16,280
它仍然是一个大语言模型

284
00:00:18,640 --> 00:00:21,719
第二个我觉得比较需要普及科普的点

285
00:00:21,719 --> 00:00:24,199
就是这件事情挺重要的

286
00:00:24,199 --> 00:00:26,000
所以说我还是决定把它拿出来

287
00:00:26,239 --> 00:00:27,280
跟大家讲一下

288
00:00:27,280 --> 00:00:29,079
就是虽然是个比较技术的东西

289
00:00:00,000 --> 00:00:01,879
但是還是值得一講

290
00:00:01,879 --> 00:00:03,299
就是過去的模型

291
00:00:03,299 --> 00:00:06,459
過去的模型你要去改變這個模型本身

292
00:00:06,459 --> 00:00:07,219
你要幹什麼

293
00:00:07,219 --> 00:00:10,380
你要去就是一個過去的模型

294
00:00:10,380 --> 00:00:12,800
你要去讓它做一個新任務

295
00:00:12,800 --> 00:00:18,600
你就需要讓這個模型改變自己

296
00:00:18,600 --> 00:00:20,600
就是我們比如說一個模型

297
00:00:20,600 --> 00:00:22,260
一個圖像識別的模型吧

298
00:00:22,260 --> 00:00:26,280
他說我們可以把現在這些同學們的臉給認出來

299
00:00:26,280 --> 00:00:28,100
那如果來了一個新的人怎麼辦

300
00:00:28,100 --> 00:00:29,640
你還是要給他標籤對吧

301
00:00:00,000 --> 00:00:01,300
你还是要给他标签

302
00:00:01,300 --> 00:00:03,600
然后他如果学习了人脸的特征

303
00:00:03,600 --> 00:00:05,700
你让他去认猴子的脸

304
00:00:05,700 --> 00:00:07,799
他还要去学习猴子脸的特征

305
00:00:07,799 --> 00:00:11,099
然后你这个拿人脸的模型去认猴子脸

306
00:00:11,099 --> 00:00:13,099
很有可能你训练出来这个模型

307
00:00:13,099 --> 00:00:14,699
他认人脸又认不准了

308
00:00:14,699 --> 00:00:17,000
所以说它是一个非常专的模型

309
00:00:17,000 --> 00:00:19,500
那GPT它是一个

310
00:00:19,500 --> 00:00:22,300
它背后的这个GPT是一个很通用的模型

311
00:00:22,300 --> 00:00:24,100
那通用的模型和这个专有模型

312
00:00:24,100 --> 00:00:25,800
就必须要有一个技术突破

313
00:00:25,800 --> 00:00:27,199
这个技术突破就是这个

314
00:00:00,000 --> 00:00:02,600
In Context Learning 叫上下文学习吧

315
00:00:02,600 --> 00:00:05,799
你这个上下文学习它的神奇之处呢

316
00:00:05,799 --> 00:00:08,400
就是在于你给了一个具备

317
00:00:08,400 --> 00:00:10,199
In Context Learning 模型

318
00:00:10,199 --> 00:00:11,400
新的数据

319
00:00:11,400 --> 00:00:13,199
它不需要修改这个模型本身

320
00:00:13,199 --> 00:00:15,000
它就能在新的数据上表现更好

321
00:00:15,000 --> 00:00:16,399
我就不多展开了

322
00:00:16,399 --> 00:00:17,600
大家知道这件事就行了

323
00:00:17,600 --> 00:00:19,199
总之是一个很神奇的事情

324
00:00:19,199 --> 00:00:21,800
那第三个概念就是涌现

325
00:00:21,800 --> 00:00:25,199
涌现呢就是我们现在看到了

326
00:00:25,199 --> 00:00:27,800
这些大语言模型里边它的一个现象

327
00:00:00,000 --> 00:00:03,799
這個現象就是我們並不知道這個能力要出現

328
00:00:03,799 --> 00:00:06,400
我們沒有辦法預測它在什麼時候出現

329
00:00:06,400 --> 00:00:09,400
但是它變大的時候或者說質量變高的時候

330
00:00:09,400 --> 00:00:10,400
它突然就出現了

331
00:00:10,400 --> 00:00:13,000
這也是一個很神奇的現象

332
00:00:15,000 --> 00:00:17,000
第四個就是這個

333
00:00:17,000 --> 00:00:20,399
這個術語叫 Reinforcement Learning with Human Feedback

334
00:00:20,399 --> 00:00:24,399
就是基於人類反饋的強化學習

335
00:00:24,399 --> 00:00:27,800
那這個基於人類反饋的強化學習

336
00:00:27,800 --> 00:00:29,399
我覺得技術上都不展開了

337
00:00:00,000 --> 00:00:01,199
大家如果感兴趣的话

338
00:00:01,199 --> 00:00:02,560
可以去读这个PPT

339
00:00:02,560 --> 00:00:03,560
或者读我的文章

340
00:00:03,560 --> 00:00:05,000
总之呢就是

341
00:00:05,000 --> 00:00:07,799
底层的那个大模显影是我刚刚说的

342
00:00:07,799 --> 00:00:08,880
它是生成式的

343
00:00:08,880 --> 00:00:10,080
自会归的大圆模显影

344
00:00:10,080 --> 00:00:10,480
对吧

345
00:00:10,480 --> 00:00:11,919
我们通过训练

346
00:00:11,919 --> 00:00:13,439
涌现出来一堆东西

347
00:00:13,439 --> 00:00:14,519
但是这些东西呢

348
00:00:14,519 --> 00:00:16,760
可能还是不能很好的被人类使用

349
00:00:16,760 --> 00:00:18,760
那通过这样的一个机制

350
00:00:18,760 --> 00:00:20,199
通过了这样一个

351
00:00:20,199 --> 00:00:23,320
就是从人类反馈中

352
00:00:23,320 --> 00:00:25,559
去重新学习吧的机制

353
00:00:25,559 --> 00:00:28,239
它跟人类的偏好对齐了

354
00:00:00,000 --> 00:00:02,960
就是他不是他能听懂人类的对话了

355
00:00:02,960 --> 00:00:04,040
而是他的对话

356
00:00:04,040 --> 00:00:07,440
他说出的东西符合我们人类的理解了

357
00:00:07,440 --> 00:00:09,560
符合我们人类的这个理解范式了

358
00:00:09,599 --> 00:00:11,560
所以说他就对人类变得有用了

359
00:00:13,279 --> 00:00:14,880
嗯这个我就不展开了

360
00:00:15,080 --> 00:00:16,079
这个我也不展开了

361
00:00:17,039 --> 00:00:18,600
就是如果打个比方的话

362
00:00:18,600 --> 00:00:21,000
就是大家如果看过钢铁侠

363
00:00:21,280 --> 00:00:22,079
GBT

364
00:00:22,640 --> 00:00:25,960
GBT那个大模型是钢铁侠的那个

365
00:00:26,640 --> 00:00:28,559
就是那个发电机

366
00:00:28,600 --> 00:00:29,960
就是它中间那个核

367
00:00:00,000 --> 00:00:01,439
那個盒是超級難的對吧

368
00:00:01,439 --> 00:00:03,399
如果看鋼鐵俠就是它是

369
00:00:03,399 --> 00:00:05,719
很難複製的

370
00:00:05,719 --> 00:00:07,280
這是鋼鐵俠的獨有技術

371
00:00:07,280 --> 00:00:09,919
然後鋼鐵俠身上有各種各樣的武器系統

372
00:00:09,919 --> 00:00:12,279
這些武器系統看上去都很牛逼很炫酷

373
00:00:12,279 --> 00:00:14,039
但是都是人類已有的科技

374
00:00:14,039 --> 00:00:15,960
我們如果記得鋼鐵俠2的時候

375
00:00:15,960 --> 00:00:17,039
它有一個競爭對手

376
00:00:17,039 --> 00:00:20,960
也有各種各樣的可以發導彈和掃機關槍的東西

377
00:00:20,960 --> 00:00:23,120
武器系統其實是容易複製的

378
00:00:23,120 --> 00:00:25,280
但是這個內盒其實是非常非常重要的

379
00:00:25,280 --> 00:00:28,000
所以說我們在研究XHPT的時候

380
00:00:28,000 --> 00:00:29,559
要去關心它的這個內盒

381
00:00:00,000 --> 00:00:02,759
而不是关注它那些各种各样的武器系统

382
00:00:05,599 --> 00:00:07,200
更多的技术我也不展开了

383
00:00:07,559 --> 00:00:11,759
我就简单说一下我的这个我自己的观点吧

384
00:00:11,759 --> 00:00:14,880
我这就不去展开过多的其他的观点了

385
00:00:14,880 --> 00:00:17,000
我希望在大家在问的问题的时候

386
00:00:17,199 --> 00:00:20,000
去来问我

387
00:00:20,559 --> 00:00:22,199
第一个就是

388
00:00:22,239 --> 00:00:25,320
ChaiCPT是不是只不过是一个更好的大语言模型

389
00:00:25,359 --> 00:00:27,640
就是它到底有没有和其他的大语言模型

390
00:00:27,719 --> 00:00:28,640
有本质的突破

391
00:00:00,000 --> 00:00:01,600
和过去的模型有本质的突破

392
00:00:02,040 --> 00:00:03,839
但是下面的这个子问题就是

393
00:00:03,839 --> 00:00:05,679
我们是不是一个更聪明的猴子

394
00:00:06,040 --> 00:00:10,199
这个是我觉得和其他的那些专家们

395
00:00:10,439 --> 00:00:12,679
我自己觉得很重要的一个不同

396
00:00:12,679 --> 00:00:15,800
就是如果按照那些专家们的逻辑

397
00:00:15,800 --> 00:00:18,640
去认为GPT只不过是一个更好的代言模型

398
00:00:18,920 --> 00:00:20,760
那根据类似的逻辑

399
00:00:20,760 --> 00:00:23,000
我们可能和猴子也没有那么大的不同

400
00:00:23,160 --> 00:00:25,199
而且这个是有科学依据的

401
00:00:26,239 --> 00:00:28,239
先说就是过去的模型是干什么的

402
00:00:00,000 --> 00:00:03,399
過去的模型他們尋找的是數據的對應關係

403
00:00:03,399 --> 00:00:08,000
所以說這個是一個簡單的illustration

404
00:00:08,000 --> 00:00:08,800
就是示範

405
00:00:08,800 --> 00:00:11,000
我們現在想訓練一個模型

406
00:00:11,000 --> 00:00:14,199
把藍色的點和紅色的點給區分開

407
00:00:14,199 --> 00:00:16,679
過去的模型如果你做的不開

408
00:00:16,679 --> 00:00:17,480
誇一刀切

409
00:00:17,480 --> 00:00:19,079
那肯定有時候很多誤傷

410
00:00:19,079 --> 00:00:19,519
對吧

411
00:00:19,519 --> 00:00:21,320
然後你這個綠色的

412
00:00:21,320 --> 00:00:23,719
你可以把它分得非常清楚

413
00:00:23,719 --> 00:00:28,280
但是如果我們再給他一個新的藍色和紅色的圖像的話

414
00:00:28,280 --> 00:00:29,280
他就分不清楚了

415
00:00:00,000 --> 00:00:01,760
所以说它这个叫overfit

416
00:00:01,760 --> 00:00:03,120
然后这个黑色的呢

417
00:00:03,120 --> 00:00:05,240
它就是一个比较有用的模型

418
00:00:05,240 --> 00:00:08,000
过去的这个深度学习

419
00:00:08,000 --> 00:00:10,599
反正机器学习深度学习做的事情

420
00:00:10,599 --> 00:00:13,519
就是在这个数据中想方设法的去找一个关系

421
00:00:13,519 --> 00:00:16,199
然后去满足一些条件优化一个东西

422
00:00:16,199 --> 00:00:17,039
但不管怎么样

423
00:00:17,039 --> 00:00:19,039
它就是寻找对应关系

424
00:00:19,039 --> 00:00:20,399
它可以寻找的很好

425
00:00:20,399 --> 00:00:23,519
就是这样做是你自己调出来的

426
00:00:23,519 --> 00:00:26,079
你把它调到了恰好的位置

427
00:00:26,079 --> 00:00:28,039
但是它其实是有能力给你

428
00:00:00,000 --> 00:00:02,000
把所有的關係找得非常非常清楚

429
00:00:02,000 --> 00:00:03,080
你給他一堆隨機數

430
00:00:03,080 --> 00:00:04,839
他也能給你找到對應關係

431
00:00:06,639 --> 00:00:09,119
可是找對應關係這件事情

432
00:00:09,119 --> 00:00:11,080
就是一個鸚鵡學舌的行為

433
00:00:11,080 --> 00:00:12,960
他只是把對應關係給到你

434
00:00:12,960 --> 00:00:15,279
他並沒有真正理解這個數據的意思

435
00:00:15,720 --> 00:00:18,079
但是GPT 3.5開始

436
00:00:18,079 --> 00:00:19,600
我們就發現了一個很不一樣的東西

437
00:00:19,600 --> 00:00:22,000
就是它有一個理解能力

438
00:00:22,000 --> 00:00:23,719
這個理解能力是在

439
00:00:23,719 --> 00:00:26,160
有一個朱松純教授

440
00:00:26,160 --> 00:00:27,920
他2017年的時候

441
00:00:00,000 --> 00:00:03,200
就是講人工智能的局限的時候講的

442
00:00:03,200 --> 00:00:04,400
就是他這個理解

443
00:00:04,400 --> 00:00:07,440
就是他就說過去的這個AI都是鸚鵡

444
00:00:07,440 --> 00:00:09,240
然後我們要尋找烏鴉的能力

445
00:00:09,240 --> 00:00:10,599
那烏鴉他幹了什麼呢

446
00:00:10,839 --> 00:00:12,759
烏鴉他在一個城市裡面

447
00:00:13,000 --> 00:00:15,759
他想打開堅果吃裡面的東西

448
00:00:15,759 --> 00:00:17,120
但是他發現掉到地上啊

449
00:00:17,120 --> 00:00:18,399
或者拿石頭砸都不行

450
00:00:18,719 --> 00:00:20,399
他就進一步發現

451
00:00:20,399 --> 00:00:22,600
汽車是能把堅果給壓開的

452
00:00:22,719 --> 00:00:24,519
紅綠燈是能控制汽車的

453
00:00:24,519 --> 00:00:26,559
但是汽車對我是有傷害的

454
00:00:26,559 --> 00:00:27,559
汽車可以壓死我

455
00:00:27,679 --> 00:00:28,800
那他怎麼辦呢

456
00:00:00,000 --> 00:00:04,000
他把这个坚果扔到了红绿灯的前面

457
00:00:04,200 --> 00:00:07,719
然后让汽车去把它压碎以后

458
00:00:07,719 --> 00:00:09,919
再等那个红绿灯红灯亮了

459
00:00:09,919 --> 00:00:11,880
汽车停了去把这个坚果给拿起来

460
00:00:12,880 --> 00:00:14,119
这件事情就让我们觉得

461
00:00:14,119 --> 00:00:15,679
乌鸦一定是有理解能力的

462
00:00:15,800 --> 00:00:17,320
不然的话他没有办法把这三个

463
00:00:17,320 --> 00:00:18,719
不相关的东西给串到一起

464
00:00:18,719 --> 00:00:19,719
然后完成这个任务

465
00:00:20,160 --> 00:00:21,120
拆GPT

466
00:00:21,679 --> 00:00:23,280
我文章里边我更详细的展开

467
00:00:23,440 --> 00:00:24,920
但是总之我们觉得拆GPT

468
00:00:24,960 --> 00:00:27,079
我觉得拆GPT是有这个能力的

469
00:00:00,000 --> 00:00:06,599
那接下來大家可能就會問到一個更哲學的問題

470
00:00:06,599 --> 00:00:09,699
或者說是那個更難回答的問題

471
00:00:09,699 --> 00:00:11,900
就是拆GPT有沒有意識

472
00:00:11,900 --> 00:00:14,500
對 包括左下角這個圖

473
00:00:14,500 --> 00:00:16,500
大家如果對哲學史比較了解的話

474
00:00:16,500 --> 00:00:18,100
就知道這是一個肛中之腦

475
00:00:18,100 --> 00:00:20,600
對吧 就是我們接下來會問的另外一個問題

476
00:00:20,600 --> 00:00:22,600
不是 就是在問拆GPT的時候

477
00:00:22,600 --> 00:00:23,899
大家不會問這個問題

478
00:00:23,899 --> 00:00:26,199
但是在哲學史上有一個沒有答案的問題

479
00:00:00,000 --> 00:00:04,400
就是我們是不是一個浴缸裡的大腦

480
00:00:04,400 --> 00:00:07,719
然後我們所有的這些東西都是我們大腦想像出來的

481
00:00:07,719 --> 00:00:09,919
而不是我們真實感受到的

482
00:00:09,919 --> 00:00:13,800
我們是不是一個計算機在不斷的給我們刺激

483
00:00:13,800 --> 00:00:15,839
包括《黑客帝國》等等的文學作品

484
00:00:15,839 --> 00:00:18,440
都是在這個觀點上出現的

485
00:00:19,039 --> 00:00:20,559
那為什麼這兩個是有聯繫的

486
00:00:20,559 --> 00:00:24,920
為什麼ChaiJPT的意識和肛中之腦這個問題是有聯繫的呢

487
00:00:25,199 --> 00:00:27,960
就是我們並不知道ChaiJPT有沒有意識

488
00:00:00,000 --> 00:00:04,160
这个是我跟很多大佬的很大的分析

489
00:00:04,160 --> 00:00:06,320
大佬们就是一些大佬们吧

490
00:00:06,320 --> 00:00:07,599
越来越少的大佬们

491
00:00:07,599 --> 00:00:10,800
他们会觉得我们知道CHAPT是怎么做出来的

492
00:00:10,800 --> 00:00:11,279
对吧

493
00:00:11,279 --> 00:00:14,240
他们的科学上没有什么特别大的突破

494
00:00:14,240 --> 00:00:17,920
我们知道它是一个自回归生成式的大圆模型

495
00:00:17,920 --> 00:00:19,199
那在这种范式下

496
00:00:19,199 --> 00:00:20,480
你是不可能产生意识的

497
00:00:20,480 --> 00:00:21,839
因为我们知道你是怎么造的

498
00:00:21,839 --> 00:00:24,719
但别忘了那个涌现的那件事情啊

499
00:00:24,719 --> 00:00:26,559
涌现是一个很重要的关键词

500
00:00:26,559 --> 00:00:28,079
还有另外一个

501
00:00:28,079 --> 00:00:29,320
还有另外一件事情

502
00:00:00,000 --> 00:00:01,000
就是

503
00:00:02,879 --> 00:00:03,879
這是個什麼

504
00:00:04,740 --> 00:00:05,740
先不管了

505
00:00:11,720 --> 00:00:13,720
就是在我們的認知科學裡面

506
00:00:13,720 --> 00:00:15,220
Cognitive Science裡面

507
00:00:16,179 --> 00:00:18,719
其實第一我們

508
00:00:18,719 --> 00:00:21,719
並不知道意識是什麼怎麼回事

509
00:00:22,600 --> 00:00:25,260
大概是在就是21世紀剛開始的時候

510
00:00:25,260 --> 00:00:26,500
有一些

511
00:00:26,500 --> 00:00:29,559
有人提出來20世紀21世紀的20代

512
00:00:00,000 --> 00:00:01,000
科學問題吧

513
00:00:01,000 --> 00:00:02,919
可能大概一半是跟意識有關的

514
00:00:02,919 --> 00:00:04,559
就是我們為什麼

515
00:00:04,559 --> 00:00:06,040
這第一個是宇宙的起源

516
00:00:06,040 --> 00:00:06,960
宇宙是怎麼起源的

517
00:00:06,960 --> 00:00:08,199
這是未解之謎

518
00:00:08,199 --> 00:00:09,519
然後當然還有很多

519
00:00:09,519 --> 00:00:11,000
就是我們為什麼會做夢

520
00:00:11,000 --> 00:00:13,080
我們為什麼和其他的動物不一樣

521
00:00:13,080 --> 00:00:14,679
意識是什麼

522
00:00:14,679 --> 00:00:15,960
很多這些問題都是

523
00:00:15,960 --> 00:00:16,839
我們都是不知道的

524
00:00:16,839 --> 00:00:19,440
我們對人腦的理解是非常非常淺的

525
00:00:19,440 --> 00:00:21,280
那在這種情況下

526
00:00:21,280 --> 00:00:23,480
其實我們去非常怎麼說呢

527
00:00:23,480 --> 00:00:24,920
非常傲慢的去說

528
00:00:24,920 --> 00:00:26,359
因為我把你造出來

529
00:00:26,359 --> 00:00:28,760
所以說我覺得你肯定沒有意識

530
00:00:00,000 --> 00:00:02,799
我覺得這個邏輯不一定成立

531
00:00:02,799 --> 00:00:05,599
而且在這個認知科學裡面

532
00:00:05,599 --> 00:00:08,439
還有一本很著名的書

533
00:00:08,439 --> 00:00:10,640
就是The Path to Consciousness

534
00:00:10,640 --> 00:00:12,000
這就不展開了

535
00:00:12,000 --> 00:00:14,480
它其實也是很久很久以前寫的書

536
00:00:14,480 --> 00:00:16,039
那裡面就是說人腦

537
00:00:16,039 --> 00:00:17,920
其實和其他動物的大腦

538
00:00:17,920 --> 00:00:19,079
沒有本質的區別

539
00:00:19,079 --> 00:00:20,760
就是我們神經元更多

540
00:00:20,760 --> 00:00:22,120
我們皮層更豐富

541
00:00:22,120 --> 00:00:23,679
但是沒有一個數量級的差別

542
00:00:23,679 --> 00:00:24,480
就是確實多

543
00:00:24,480 --> 00:00:27,760
但是沒有多到就是差那麼大

544
00:00:27,760 --> 00:00:28,920
就是你很明顯一個猴子

545
00:00:00,000 --> 00:00:02,240
和一個螞蟻的大腦差的是非常非常大的

546
00:00:02,240 --> 00:00:03,500
但是我們和一個猴子的大腦

547
00:00:03,500 --> 00:00:04,500
其實差的沒有那麼大

548
00:00:04,500 --> 00:00:06,000
那在這種情況下

549
00:00:06,000 --> 00:00:07,500
我們的意識是怎麼來的呢

550
00:00:07,500 --> 00:00:09,259
然後那個書裡面就用了這個

551
00:00:09,259 --> 00:00:10,259
湧現這個詞

552
00:00:10,259 --> 00:00:12,140
他就覺得我們的意識是湧現出來的

553
00:00:12,140 --> 00:00:13,720
我們的智力是湧現出來的

554
00:00:13,720 --> 00:00:16,179
所以說我們不知道我們的大腦有沒有

555
00:00:16,980 --> 00:00:18,600
意識和我們的

556
00:00:18,600 --> 00:00:20,679
看似有的這個智力是怎麼來的

557
00:00:20,679 --> 00:00:21,940
我這就覺得

558
00:00:21,940 --> 00:00:23,480
第一我們不知道

559
00:00:23,480 --> 00:00:24,780
Chagpity到底有沒有

560
00:00:25,160 --> 00:00:26,320
意識或者智力

561
00:00:26,320 --> 00:00:27,620
但是這個東西不重要

562
00:00:27,620 --> 00:00:28,899
這個東西一點都不重要

563
00:00:00,000 --> 00:00:01,540
因為為什麼呢

564
00:00:01,540 --> 00:00:05,000
因為在哲學史上其實就是有一個他心問題啊

565
00:00:05,000 --> 00:00:07,200
這兒我沒放

566
00:00:07,200 --> 00:00:09,919
但是我在文檔裡面有放一些拓展閱讀

567
00:00:09,919 --> 00:00:11,320
就大家如果感興趣的話

568
00:00:11,320 --> 00:00:13,640
就會看到它是貫穿哲學史

569
00:00:13,640 --> 00:00:16,960
所有的著名哲學家都會去說一嘴的這個問題

570
00:00:16,960 --> 00:00:20,320
就是我到底是不是NPC

571
00:00:20,320 --> 00:00:21,839
你們到底是不是NPC

572
00:00:21,839 --> 00:00:24,000
就是我見到了其他人到底是不是NPC

573
00:00:24,000 --> 00:00:25,879
我到底是不是一個剛中之腦

574
00:00:25,879 --> 00:00:28,559
這個問題在哲學史上是一個沒有答案

575
00:00:00,000 --> 00:00:03,960
但是每個人都會借題發揮去講很多重要哲學觀點的東西

576
00:00:04,320 --> 00:00:07,040
但是他對我們來說有用的答案是什麼呢

577
00:00:07,040 --> 00:00:08,039
就是也不重要

578
00:00:08,039 --> 00:00:10,039
我不需要去管你們是不是NPC

579
00:00:10,039 --> 00:00:14,320
我在看到一個同學他能不能完成工作

580
00:00:14,519 --> 00:00:15,960
我是看他的工作結果對吧

581
00:00:15,960 --> 00:00:17,920
我不需要知道他腦子裡邊

582
00:00:17,920 --> 00:00:20,440
我不會去想他腦子裡邊是在發生什麼

583
00:00:20,440 --> 00:00:23,239
我知道他哦你做的這個結果挺不錯的

584
00:00:23,239 --> 00:00:25,120
那我就認為你是一個可以勝任的人

585
00:00:25,320 --> 00:00:28,000
我建議就是對ChaiGBT也抱這樣的觀點

586
00:00:00,000 --> 00:00:02,600
就是ChangeBT交给你一个工作能不能做好

587
00:00:02,600 --> 00:00:04,400
能做好OK你可以做好这个工作

588
00:00:06,480 --> 00:00:07,599
这是第一个问题

589
00:00:07,879 --> 00:00:09,359
那第二个问题就是

590
00:00:09,359 --> 00:00:11,800
ChangeBT到底是一个什么样的意义

591
00:00:11,800 --> 00:00:13,279
就是怎么去理解它的意义

592
00:00:13,480 --> 00:00:15,080
我一开始我写了以后我觉得

593
00:00:15,080 --> 00:00:15,400
嗯

594
00:00:16,199 --> 00:00:17,039
说得有点大

595
00:00:17,160 --> 00:00:18,039
但是后来呢

596
00:00:18,440 --> 00:00:19,600
比尔盖茨写了一个文章

597
00:00:19,600 --> 00:00:21,199
然后我就去翻了这个SamUltimate

598
00:00:21,199 --> 00:00:23,199
就是那个OpenAI CEO

599
00:00:23,399 --> 00:00:24,640
他写的文章我发现

600
00:00:24,640 --> 00:00:24,920
嗯

601
00:00:25,199 --> 00:00:26,719
他们的理解和我是差不多的

602
00:00:26,719 --> 00:00:28,640
所以说我就对这个事情多了很多信

603
00:00:28,640 --> 00:00:29,440
呃信任

604
00:00:00,000 --> 00:00:03,040
就是比爾蓋茲說這是一個GUI時刻

605
00:00:03,040 --> 00:00:05,879
然後奧特曼說的是這是一個萬物馬爾定律

606
00:00:07,519 --> 00:00:09,000
對那

607
00:00:11,119 --> 00:00:12,560
GUI時刻怎麼理解

608
00:00:12,560 --> 00:00:15,320
就是在這個計算機的歷史上

609
00:00:15,320 --> 00:00:17,960
其實我們就是在三件事情上去做進步

610
00:00:17,960 --> 00:00:20,399
第一個是算力和存儲硬件

611
00:00:20,399 --> 00:00:22,920
第二個是數據的產生和使用

612
00:00:24,320 --> 00:00:26,120
比如說我們在刷抖音的時候

613
00:00:26,480 --> 00:00:28,519
抖音的那個視頻是一個數據

614
00:00:00,000 --> 00:00:01,720
你的浏览行为是一个数据

615
00:00:01,720 --> 00:00:05,040
抖音你和其他人的关系都能演示出去

616
00:00:05,040 --> 00:00:06,400
所以抖音把这些数据用完了以后

617
00:00:06,400 --> 00:00:08,160
就可以给你推荐你想刷的视频

618
00:00:08,160 --> 00:00:10,880
而且是让用户去产生这些东西去给你使用

619
00:00:10,880 --> 00:00:12,880
最后就形成了一个这么大的商业模式

620
00:00:12,880 --> 00:00:13,279
对吧

621
00:00:13,279 --> 00:00:15,839
这个是数据的使用和生产

622
00:00:16,320 --> 00:00:20,960
第三个就是把上面的算力存储和数据进行更好的组合

623
00:00:20,960 --> 00:00:22,640
然后更好的去使用它

624
00:00:23,120 --> 00:00:26,960
之前我们使用的方法就是写代码

625
00:00:00,000 --> 00:00:03,459
但是我們在日常正常人消費不會寫代碼的時候怎麼辦

626
00:00:03,459 --> 00:00:05,299
我們就是用這個GUI

627
00:00:05,299 --> 00:00:08,640
其實比爾蓋茲就是大家都知道比爾蓋茲

628
00:00:08,640 --> 00:00:12,439
他在那個文章裡面第一句話寫的是

629
00:00:12,439 --> 00:00:15,480
他這輩子只見過兩個顛覆性的科技

630
00:00:15,480 --> 00:00:17,679
第一個是GUI第二個是柴脂筆貼

631
00:00:17,679 --> 00:00:18,719
包括GPT

632
00:00:18,719 --> 00:00:19,320
對

633
00:00:19,320 --> 00:00:22,120
就在他的角度來說這不是一個iPhone時刻

634
00:00:22,120 --> 00:00:23,179
這不是一個電腦時刻

635
00:00:23,179 --> 00:00:24,519
這不是一個互聯網時刻

636
00:00:24,519 --> 00:00:25,960
這是一個GUI時刻

637
00:00:25,960 --> 00:00:28,859
就是他在他這輩子之前只見過GUI

638
00:00:00,000 --> 00:00:02,000
現在見到GPT

639
00:00:02,000 --> 00:00:04,000
這兩個是最重要的

640
00:00:04,000 --> 00:00:06,000
那怎麼理解它跟GUI的關係呢

641
00:00:06,000 --> 00:00:08,000
就是我們在刷抖音

642
00:00:08,000 --> 00:00:10,000
大家想一想如果說我們沒有這個

643
00:00:10,000 --> 00:00:12,000
GUI就是那個圖形交互介面

644
00:00:12,000 --> 00:00:14,000
就是按鈕啊這些東西

645
00:00:14,000 --> 00:00:16,000
如果我們沒有手機上的這些按鈕

646
00:00:16,000 --> 00:00:18,000
可以打開抖音APP然後去

647
00:00:18,000 --> 00:00:20,000
看到抖音然後去這樣刷

648
00:00:20,000 --> 00:00:22,000
那我們想去看到這些短視頻怎麼辦

649
00:00:22,000 --> 00:00:24,000
就寫代碼是吧

650
00:00:24,000 --> 00:00:26,000
瘋狂寫代碼可能我們要寫

651
00:00:26,000 --> 00:00:28,000
不知道從這擺到那那麼長的代碼

652
00:00:00,000 --> 00:00:02,120
它有可能刷出來幾個視頻

653
00:00:02,120 --> 00:00:04,320
但是我們現在只需要點開

654
00:00:04,320 --> 00:00:05,320
就是我們不會去想

655
00:00:05,320 --> 00:00:07,120
然後直接就可以去刷這個視頻了

656
00:00:07,120 --> 00:00:09,400
所以說GUI是特別特別牛逼的

657
00:00:09,400 --> 00:00:11,560
它讓一些就是這個

658
00:00:11,560 --> 00:00:15,199
算力存儲和這個數據的這個交互

659
00:00:15,199 --> 00:00:16,719
變得簡單了很多

660
00:00:16,719 --> 00:00:18,879
對人每個人都可以去使用它

661
00:00:18,879 --> 00:00:21,559
對 大家出現了這個東西以後

662
00:00:21,559 --> 00:00:22,559
就覺得它很正常

663
00:00:22,559 --> 00:00:24,399
這包括搜索

664
00:00:24,399 --> 00:00:26,320
在Google出來的之前

665
00:00:26,320 --> 00:00:28,239
我相信全世界沒有任何一個人

666
00:00:00,000 --> 00:00:02,560
比如說美國總統啊 然後什麼皇帝啊

667
00:00:02,560 --> 00:00:05,000
他都沒有我們現在手上這個信息量

668
00:00:05,000 --> 00:00:08,000
就是美國總統那個時候想知道一個信息

669
00:00:08,000 --> 00:00:09,500
應該是很麻煩的吧

670
00:00:09,500 --> 00:00:10,699
他要去問很多專家

671
00:00:10,699 --> 00:00:13,400
這些專家要去找很多這個圖書

672
00:00:13,400 --> 00:00:14,800
就是我讀書的時候

673
00:00:14,800 --> 00:00:16,000
暴露年齡啊

674
00:00:16,000 --> 00:00:18,500
就是還要去學怎麼樣子去查書

675
00:00:18,500 --> 00:00:21,300
我相信大家現在都不需要去查書了吧

676
00:00:21,300 --> 00:00:24,500
就是圖書檢索本來是一門很嚴肅的科學

677
00:00:24,500 --> 00:00:28,000
就是你想快速檢索出你想要的信息

678
00:00:00,000 --> 00:00:02,799
你要把这个信息组织起来是个很难很难的事情

679
00:00:02,799 --> 00:00:04,200
但是搜索出来以后

680
00:00:04,200 --> 00:00:06,200
每个人随随便便天天都可以搜索

681
00:00:06,200 --> 00:00:09,800
这件事情是一个很不可思议的技术进步

682
00:00:09,800 --> 00:00:11,599
当然大家已经习以为常了

683
00:00:12,400 --> 00:00:12,800
对

684
00:00:12,800 --> 00:00:16,399
我们接下来就会遇到另外一个方向的

685
00:00:16,399 --> 00:00:17,399
很不可思议的

686
00:00:17,399 --> 00:00:19,600
今天大家完全不可想象的技术进步

687
00:00:19,600 --> 00:00:22,800
就是GUI它可以刚说了是很厉害

688
00:00:22,800 --> 00:00:25,199
但是它有一个问题就是它特别专

689
00:00:25,199 --> 00:00:27,399
它一个按钮只能干一件事情

690
00:00:27,399 --> 00:00:29,500
它可以让这件事情干得特别的高效

691
00:00:00,000 --> 00:00:01,600
然後特別特別的符合直覺

692
00:00:01,600 --> 00:00:03,299
但是他只能幹這麼一件事

693
00:00:03,299 --> 00:00:03,799
對吧

694
00:00:03,799 --> 00:00:06,500
我們其實日常生活中要幹很多事

695
00:00:06,500 --> 00:00:08,300
我們今天之所以沒有這個按鈕去做

696
00:00:08,300 --> 00:00:09,699
是因為做這個按鈕不經濟

697
00:00:09,699 --> 00:00:12,099
或者說這個事情就是很難通過按鈕去做

698
00:00:12,099 --> 00:00:13,300
在JPT呢

699
00:00:13,300 --> 00:00:15,500
你可以通過跟計算機的對話

700
00:00:15,500 --> 00:00:18,100
讓計算機去調動算力存儲和數據

701
00:00:18,100 --> 00:00:19,699
幫你去做你想做的事

702
00:00:19,699 --> 00:00:23,000
所以這是為什麼提問的能力變得這麼重要了

703
00:00:23,000 --> 00:00:25,500
你要真的去看到生活中的問題

704
00:00:25,500 --> 00:00:27,300
而且這個生活中的問題一定不是說

705
00:00:27,300 --> 00:00:28,500
我今天寫了一個PPT

706
00:00:28,500 --> 00:00:29,699
我明天怎麼寫得更快一點

707
00:00:00,000 --> 00:00:03,000
它一定是你之前從來沒有幹過的一件事

708
00:00:03,000 --> 00:00:04,400
然後你突然發現

709
00:00:04,400 --> 00:00:08,000
這件事我有沒有可能用XGBT來解決

710
00:00:08,000 --> 00:00:10,500
這也不多說了

711
00:00:10,500 --> 00:00:14,000
然後第二個那個萬物摩爾定律的意思是什麼呢

712
00:00:14,000 --> 00:00:20,000
就是摩爾定律我們手機啊

713
00:00:20,000 --> 00:00:21,500
然後電腦啊

714
00:00:21,500 --> 00:00:22,500
然後電視啊

715
00:00:22,500 --> 00:00:24,000
它是被摩爾定律影響的

716
00:00:24,000 --> 00:00:26,000
我們看到它的價格一直在往下走

717
00:00:26,000 --> 00:00:29,500
就是今天的電視比10年前的電視性能好很多

718
00:00:00,000 --> 00:00:01,340
當然價格也要便宜

719
00:00:01,340 --> 00:00:03,339
可是我們的人

720
00:00:03,339 --> 00:00:05,040
就是跟治理相關的

721
00:00:05,040 --> 00:00:06,639
不能被墨爾丁利所影響的

722
00:00:06,639 --> 00:00:08,939
比如說醫生 教師

723
00:00:08,939 --> 00:00:11,980
和這個就是法律等等

724
00:00:11,980 --> 00:00:14,179
它其實價格是在往上走的

725
00:00:14,179 --> 00:00:17,420
那這個最重要的原因是

726
00:00:17,420 --> 00:00:18,620
我們的人力資本

727
00:00:18,620 --> 00:00:20,420
其實是需要花很多很多錢

728
00:00:20,420 --> 00:00:21,719
才能建立起來

729
00:00:21,719 --> 00:00:25,420
但是我們分發的這個成本是極高的

730
00:00:25,420 --> 00:00:27,260
我今天過來跟大家聊這些東西

731
00:00:27,260 --> 00:00:28,699
我就不能出現在一個別的地方

732
00:00:28,699 --> 00:00:29,460
跟其他人聊

733
00:00:00,000 --> 00:00:01,199
我也不能去干别的事

734
00:00:01,199 --> 00:00:05,679
所以说就是这一小时对我来说是很贵的

735
00:00:05,679 --> 00:00:09,080
可是如果有了XGBT

736
00:00:09,080 --> 00:00:11,359
我让大家就是稍稍想象一下

737
00:00:11,359 --> 00:00:14,599
就是今天的XGBT还做不到

738
00:00:14,599 --> 00:00:17,839
但是在它的能力范围之内

739
00:00:17,839 --> 00:00:22,719
还没有开放的是它假设可以记住你一些句话

740
00:00:22,719 --> 00:00:26,480
就是大家今天知道XGBT可以记住你很多句话

741
00:00:26,480 --> 00:00:27,719
但是它的开放

742
00:00:00,000 --> 00:00:02,560
他现在他那个产品只不过是一个小的demo

743
00:00:02,560 --> 00:00:03,560
大家记住这一点

744
00:00:03,560 --> 00:00:05,879
就是他的产品只不过他连正式产品都没有

745
00:00:05,879 --> 00:00:07,679
他的现在的产品只不过是个demo

746
00:00:07,679 --> 00:00:10,640
然后他这个demo的情况下他能记住你一些话

747
00:00:10,640 --> 00:00:12,240
但是假设有一天开放了

748
00:00:12,240 --> 00:00:13,800
可以记住你一千句话一万句话

749
00:00:13,800 --> 00:00:15,560
然后你的这个权重是可调的

750
00:00:15,839 --> 00:00:17,559
你这一万句话你可以干什么

751
00:00:17,839 --> 00:00:19,519
你可以把你的知识交给他

752
00:00:19,519 --> 00:00:21,399
你可以跟他通过对话告诉他

753
00:00:21,399 --> 00:00:23,120
你应该做什么什么什么

754
00:00:23,120 --> 00:00:25,960
比如说有写这个市场方案的同学

755
00:00:25,960 --> 00:00:27,559
有做数据分析的同学

756
00:00:00,000 --> 00:00:02,960
那你就把你知道的这些知识全都跟他讲

757
00:00:02,960 --> 00:00:05,200
然后你还可以把一些数据喂给他

758
00:00:05,200 --> 00:00:08,119
你还可以告诉他怎么去使用工具去查询很多东西

759
00:00:08,480 --> 00:00:10,400
之后他做了这些结果

760
00:00:10,400 --> 00:00:11,599
你还可以给他提供反馈

761
00:00:11,720 --> 00:00:12,800
你耐心的教他

762
00:00:12,800 --> 00:00:14,279
我觉得这个好那个不好

763
00:00:14,279 --> 00:00:15,679
为什么我觉得这个好那个不好

764
00:00:15,880 --> 00:00:17,039
一万句话之后

765
00:00:17,399 --> 00:00:20,519
他的能力有没有可能达到你做这件事情的80%到

766
00:00:20,559 --> 00:00:21,719
我不知道百分之八百

767
00:00:22,079 --> 00:00:23,800
我觉得完全是可以的

768
00:00:24,559 --> 00:00:25,480
那在这种情况下

769
00:00:25,480 --> 00:00:28,600
你的这个GPT就是你的这个智力的一个分发工具

770
00:00:00,000 --> 00:00:04,400
比如說今天我去醫院去看醫生

771
00:00:04,400 --> 00:00:05,559
醫生給我的診斷

772
00:00:05,559 --> 00:00:07,960
我只能相信這邊的醫生是一個懂的人

773
00:00:07,960 --> 00:00:11,000
但是其實一半的醫生是不到平均值的

774
00:00:11,000 --> 00:00:11,279
對吧

775
00:00:11,279 --> 00:00:13,599
這個是一個不到中位數的

776
00:00:13,599 --> 00:00:15,119
就是我可能運氣不好

777
00:00:15,119 --> 00:00:16,559
就遇到了一個不好的醫生

778
00:00:16,559 --> 00:00:20,239
但是假設今天有一個GPT出來說

779
00:00:20,239 --> 00:00:24,239
這是世界上最牛逼的醫院的專家們

780
00:00:24,239 --> 00:00:26,440
調教了十萬句話

781
00:00:00,000 --> 00:00:03,799
然後調教了半年

782
00:00:03,799 --> 00:00:05,280
然後來給你做診斷

783
00:00:05,280 --> 00:00:07,799
他會問你足夠細緻的問題

784
00:00:08,199 --> 00:00:10,679
他會有最新的科學理論

785
00:00:10,720 --> 00:00:12,279
他來幫你做一下診斷

786
00:00:12,320 --> 00:00:13,720
你願不願意去使用它

787
00:00:14,039 --> 00:00:16,800
如果說它的效果你真的發現

788
00:00:16,800 --> 00:00:20,000
比我去醫院的醫生要好的時候

789
00:00:20,440 --> 00:00:24,120
那是不是醫療這件事情就完全被民主化

790
00:00:24,120 --> 00:00:28,600
和它的編輯成本就極大的下降了呢

791
00:00:00,000 --> 00:00:02,319
我觉得这一天就是很快就会到来的

792
00:00:02,319 --> 00:00:04,639
就是他今天能力完全是可以做到这件事情的

793
00:00:07,080 --> 00:00:09,519
第三个问题就是它有多难

794
00:00:09,839 --> 00:00:12,199
这个我也不多详细展开了吧

795
00:00:12,199 --> 00:00:14,439
总之我会觉得不要觉得它很简单

796
00:00:14,439 --> 00:00:16,920
就是觉得它很简单可能会有几个原因

797
00:00:16,920 --> 00:00:19,839
第一个是我们之前的模型开源都是

798
00:00:20,239 --> 00:00:21,359
之前的模型是开源的

799
00:00:21,359 --> 00:00:24,000
然后之前复现这些开源模型调个包

800
00:00:24,000 --> 00:00:25,800
然后在自己设置上用一下调一调

801
00:00:25,879 --> 00:00:26,600
没有什么难度

802
00:00:26,600 --> 00:00:28,719
所以说大家都觉得那件事情是很简单的

803
00:00:00,000 --> 00:00:01,720
可是今天模型是必然的

804
00:00:01,720 --> 00:00:04,919
關鍵是它的這個工程難度很高的情況下

805
00:00:04,919 --> 00:00:07,919
它需要一個月到兩個月才能迭代一次

806
00:00:07,919 --> 00:00:10,000
所以說不要低估這個

807
00:00:10,000 --> 00:00:11,800
複現這件事情的難度

808
00:00:11,800 --> 00:00:12,800
就這句話吧

809
00:00:12,800 --> 00:00:15,199
然後我的這個決策路徑是

810
00:00:15,199 --> 00:00:17,800
我會看谷歌什麼時候能複現出來

811
00:00:17,800 --> 00:00:19,719
就是谷歌是有

812
00:00:19,719 --> 00:00:21,120
就是提出了Transformer

813
00:00:21,120 --> 00:00:23,440
提出了T5等等所有

814
00:00:23,440 --> 00:00:25,719
這裡邊大約模型裡面重要的模型

815
00:00:25,719 --> 00:00:27,120
它有足夠的算力

816
00:00:27,120 --> 00:00:28,440
有足夠的工程人才

817
00:00:28,440 --> 00:00:29,960
然後它有足夠的商業動機

818
00:00:00,000 --> 00:00:01,280
去把这件事情搞定

819
00:00:01,639 --> 00:00:05,759
但是谷歌Bart可能离拆GPT还差了一年以上

820
00:00:06,160 --> 00:00:08,080
如果谷歌差一年以上的话

821
00:00:08,320 --> 00:00:10,439
我希望有人告诉我为什么我们可以

822
00:00:10,880 --> 00:00:12,320
一年之内就搞定这件事

823
00:00:12,320 --> 00:00:13,279
不然的话我就不信了

824
00:00:14,279 --> 00:00:16,719
但是我觉得也有可能就是拆这件事情不难

825
00:00:16,839 --> 00:00:17,519
我不知道

826
00:00:17,679 --> 00:00:19,879
如果说谷歌三个月之内搞定了

827
00:00:19,879 --> 00:00:22,039
那我就说这件事情没有我想象的这么难

828
00:00:22,039 --> 00:00:24,239
所以说大家去复刻这件事情

829
00:00:24,239 --> 00:00:25,559
我觉得是更加有意义

830
00:00:25,800 --> 00:00:26,719
不然的话

831
00:00:27,079 --> 00:00:27,839
大家想一下

832
00:00:27,839 --> 00:00:29,079
就是浏览器出来的时候

833
00:00:00,000 --> 00:00:01,659
然后我们真的有很多浏览器吗

834
00:00:01,659 --> 00:00:02,660
操作系统出来的时候

835
00:00:02,660 --> 00:00:03,660
我们有很多SOLID系统吗

836
00:00:03,660 --> 00:00:06,960
然后这个iPhone出来的时候

837
00:00:06,960 --> 00:00:09,460
我都还记得一大堆几十个神仔机

838
00:00:09,460 --> 00:00:10,660
都是我们做iPhone

839
00:00:10,660 --> 00:00:11,960
酷拍iPhone什么的

840
00:00:11,960 --> 00:00:14,160
但是最后全都没有留下来

841
00:00:14,160 --> 00:00:14,859
对吧

842
00:00:14,859 --> 00:00:15,660
就这种感觉

843
00:00:17,859 --> 00:00:19,960
第四个问题是我们怎么使用它

844
00:00:21,859 --> 00:00:22,460
不说了吧

845
00:00:23,460 --> 00:00:26,160
就太抽象了

846
00:00:28,660 --> 00:00:29,460
感兴趣的话

847
00:00:00,000 --> 00:00:02,000
看這個和我的文章裡都有

848
00:00:04,000 --> 00:00:06,000
但是一個我覺得歷史

849
00:00:06,000 --> 00:00:08,000
我現在正在上傳

850
00:00:08,000 --> 00:00:10,000
就是我來之前正在往B站上上傳

851
00:00:10,000 --> 00:00:12,000
可能現在已經上傳好了

852
00:00:12,000 --> 00:00:14,000
就是這個歷史的教訓

853
00:00:14,000 --> 00:00:16,000
歷史的教訓或者經驗是什麼呢

854
00:00:16,000 --> 00:00:20,000
就是我們在一個新技術剛出現的時候

855
00:00:20,000 --> 00:00:22,000
會發生兩件事

856
00:00:22,000 --> 00:00:26,000
第一個是我們會嚴重高估它的短期影響

857
00:00:26,000 --> 00:00:28,000
且嚴重低估它的長期影響

858
00:00:00,000 --> 00:00:02,520
所以说比如说互联网刚出来的时候

859
00:00:02,520 --> 00:00:03,839
那个.com bubble对吧

860
00:00:03,839 --> 00:00:05,639
就是一大堆的人去想象

861
00:00:05,639 --> 00:00:08,519
我们把所有线下所有东西搬到一个什么.com上

862
00:00:08,519 --> 00:00:11,119
然后它就估值涨10倍1万倍

863
00:00:11,119 --> 00:00:13,039
最后发现全都是泡沫

864
00:00:13,039 --> 00:00:16,519
我们今天就是移动互联网出现的时候也会这样子

865
00:00:16,519 --> 00:00:17,399
然后等等等等吧

866
00:00:17,399 --> 00:00:19,079
我觉得今天Chashpity也一定会这样子的

867
00:00:19,079 --> 00:00:20,280
就是我们现在出的

868
00:00:20,280 --> 00:00:22,960
大家对它的想法很多都是高估的

869
00:00:22,960 --> 00:00:25,879
它不会那么快的对我们的生活产生那么大的影响

870
00:00:00,000 --> 00:00:04,200
但是他可能三年五年十年對人們產生的影響

871
00:00:04,200 --> 00:00:05,400
我們都嚴重低估了

872
00:00:05,679 --> 00:00:09,640
就是為什麼我會去真的去看調酒這件事情

873
00:00:09,679 --> 00:00:12,679
我真的是覺得三年之後我的工作存不存在

874
00:00:12,679 --> 00:00:13,800
不一定真的不一定

875
00:00:15,000 --> 00:00:18,000
我當然我更希望的是我調教出來的一個

876
00:00:18,000 --> 00:00:19,519
XGBT幫我打工

877
00:00:19,559 --> 00:00:21,039
然後我自己去調酒

878
00:00:21,079 --> 00:00:22,600
這樣是比較好的

879
00:00:23,359 --> 00:00:25,199
大家在笑啊大家在笑

880
00:00:25,879 --> 00:00:27,640
我覺得要不這樣子啊

881
00:00:00,000 --> 00:00:02,960
就是如果大家愿意的话可以打开手机

882
00:00:02,960 --> 00:00:04,559
然后打开你的日历

883
00:00:04,559 --> 00:00:06,080
今天是4月几号

884
00:00:06,080 --> 00:00:07,480
16号

885
00:00:07,480 --> 00:00:11,519
两年之后就是2025年的4月16号

886
00:00:11,519 --> 00:00:12,880
大家在上面留一条

887
00:00:13,320 --> 00:00:15,679
说回来看一下这个视频

888
00:00:15,679 --> 00:00:18,320
我给大家一个建议就是大家去学一个手艺

889
00:00:18,320 --> 00:00:20,879
大家可以两年之后回来看一下

890
00:00:21,719 --> 00:00:23,960
有没有后悔没有听我今天的这个建议

891
00:00:28,280 --> 00:00:29,879
好吧

892
00:00:00,000 --> 00:00:03,000
然後就是怎麼抓住那個

893
00:00:03,000 --> 00:00:05,000
真正大的和重要的一個機會

894
00:00:05,000 --> 00:00:06,500
就是怎麼抓住那個長期的機會

895
00:00:06,500 --> 00:00:07,500
這是我剛剛說的

896
00:00:07,500 --> 00:00:09,000
它不是在於怎麼樣子

897
00:00:09,000 --> 00:00:10,000
讓我們今天的這個工作

898
00:00:10,000 --> 00:00:11,500
工作得更高效一點

899
00:00:11,500 --> 00:00:12,500
而是在於怎麼樣子解決

900
00:00:12,500 --> 00:00:15,000
我們今天完全不可能解決的問題

901
00:00:15,000 --> 00:00:17,000
因為我們今天這些問題

902
00:00:17,000 --> 00:00:18,500
完全不可能得到解決

903
00:00:18,500 --> 00:00:20,000
所以說我們根本就沒有去

904
00:00:20,000 --> 00:00:21,500
思考這些問題

905
00:00:21,500 --> 00:00:24,500
但是真正的機會是在這裡邊的

906
00:00:00,000 --> 00:00:08,000
给大家半分钟的时间去写一下那个日历

907
00:00:08,000 --> 00:00:12,919
然后如果要去洗手间什么的休息的话

908
00:00:12,919 --> 00:00:13,960
我觉得随时来吧

909
00:00:13,960 --> 00:00:15,720
因为我们到时候也是个提问的形式

910
00:00:15,759 --> 00:00:16,800
以及都会录下来

911
00:00:16,800 --> 00:00:18,679
然后大家回头想看的话可以看的

912
00:00:18,679 --> 00:00:21,239
所以说就随意一点

913
00:00:28,440 --> 00:00:29,600
这边是一些个人观点

914
00:00:00,000 --> 00:00:01,340
也不用太在意了

915
00:00:02,220 --> 00:00:06,379
然後第五個就是人類和Chai GPT的區別到底是什麼

916
00:00:10,259 --> 00:00:11,220
暫時先不展開吧

917
00:00:11,220 --> 00:00:13,019
可能到時候提問的時候來提問

918
00:00:13,820 --> 00:00:14,519
行

919
00:00:14,519 --> 00:00:16,219
這是最後一個一頁

920
00:00:16,219 --> 00:00:22,820
就是我們當時在做一件事情的時候呢

921
00:00:22,820 --> 00:00:26,320
人們的反應會是一個偵探分佈

922
00:00:26,320 --> 00:00:27,420
最傻逼的左邊那個

923
00:00:00,000 --> 00:00:03,640
就是做点人们想要的就行了

924
00:00:03,640 --> 00:00:06,139
然后中间就会有一个非常复杂的分析

925
00:00:06,139 --> 00:00:07,120
互称盒是什么呀

926
00:00:07,120 --> 00:00:08,779
这个商业模式的颠覆性是什么呀

927
00:00:08,779 --> 00:00:11,099
然后我们怎么样子去看我们的竞争对手啊

928
00:00:11,099 --> 00:00:12,119
等等等等

929
00:00:12,119 --> 00:00:16,440
然后最后面就是大师会说做个人们想要的东西就行了

930
00:00:16,440 --> 00:00:17,239
对

931
00:00:21,440 --> 00:00:22,199
好

932
00:00:22,199 --> 00:00:25,399
我我的东西就讲完了

933
00:00:25,399 --> 00:00:26,800
现在我就是一个拆纸别提了

934
00:00:26,800 --> 00:00:27,559
大家来问问题吧

935
00:00:00,000 --> 00:00:03,279
我先提一个问题

936
00:00:08,279 --> 00:00:14,199
首先人类它为什么走到今天

937
00:00:14,199 --> 00:00:17,480
并不是因为人类的发展是最先进的

938
00:00:17,480 --> 00:00:21,480
因为曾经有过直立人和智人同时存在

939
00:00:21,480 --> 00:00:24,800
但是直立人有唯一的一个优势就是

940
00:00:24,800 --> 00:00:27,079
我们的语言系统更先进

941
00:00:00,000 --> 00:00:04,799
曾经科学家一直认为我们人类跟其他动物的区别是

942
00:00:04,799 --> 00:00:06,799
我们的大脑有语言中枢

943
00:00:06,799 --> 00:00:10,300
这就是因为这个现象而来的一个误区

944
00:00:10,300 --> 00:00:13,000
所以首先我不觉得人类有什么优势

945
00:00:13,000 --> 00:00:17,199
但其实就是我觉得人类包括其他动物乌鸦

946
00:00:17,199 --> 00:00:21,699
最大的优势就是具有这个抽象任何物体的能力

947
00:00:21,699 --> 00:00:24,800
这是我们随时随地都在做的事情

948
00:00:24,800 --> 00:00:28,100
包括所谓的刻板印象等等等等

949
00:00:00,000 --> 00:00:03,000
就是人類的抽象能力是非常強的

950
00:00:03,000 --> 00:00:04,519
那我想問就是

951
00:00:04,519 --> 00:00:09,199
TreadGBT是否具有這種高度抽象物體的能力

952
00:00:10,640 --> 00:00:16,160
你前面那個結論我不確定是你想的還是別人說的

953
00:00:16,160 --> 00:00:20,359
就是人類和其他動物的本質區別是人類具有抽象的能力

954
00:00:20,359 --> 00:00:25,239
我是說人類和其他動物都具有這種能力

955
00:00:25,239 --> 00:00:26,320
都具有抽象能力

956
00:00:26,320 --> 00:00:26,760
對對對

957
00:00:26,760 --> 00:00:28,719
但是TreadGBT是否具有這種能力

958
00:00:00,000 --> 00:00:02,160
我觉得如果他还没有的话

959
00:00:02,160 --> 00:00:05,240
那他距离彻底取代人类还有一定的距离

960
00:00:05,240 --> 00:00:06,799
他不可能彻底取代人类的

961
00:00:06,799 --> 00:00:09,919
就是首先就我没有说他能彻底取代人类

962
00:00:09,919 --> 00:00:12,039
我是那要不我再说一下这个吧

963
00:00:12,039 --> 00:00:13,039
就是呃

964
00:00:13,039 --> 00:00:14,800
拆GBT和人是有很多区别的

965
00:00:14,800 --> 00:00:17,399
包括那个自己的文章列了七个

966
00:00:17,760 --> 00:00:18,640
很重要的区别

967
00:00:18,920 --> 00:00:20,600
就拆GBT的其实是个工具

968
00:00:20,640 --> 00:00:22,879
他不是什么取代人的东西

969
00:00:23,120 --> 00:00:25,120
就是他没有自己的目标

970
00:00:25,120 --> 00:00:26,160
他也没有自己的

971
00:00:26,440 --> 00:00:27,039
啊你要说

972
00:00:27,199 --> 00:00:29,000
可能我没表达很清楚

973
00:00:00,000 --> 00:00:03,200
因为我觉得抽象能力是人类最重要的一个能力

974
00:00:03,200 --> 00:00:07,400
就是我想了解你这个抽象能力是人类最重要的能力

975
00:00:07,400 --> 00:00:08,679
这句话的来源是什么

976
00:00:09,240 --> 00:00:11,759
就从人类的进化史来看就是这样的呀

977
00:00:11,759 --> 00:00:12,839
这是你的观点

978
00:00:12,919 --> 00:00:13,519
对对对

979
00:00:13,640 --> 00:00:14,240
个人观点

980
00:00:14,240 --> 00:00:16,839
我想知道就是Chain-Gb是否有这种能力呢

981
00:00:16,879 --> 00:00:20,039
就是他能否把一件很复杂的事情

982
00:00:20,079 --> 00:00:21,719
描述成很定的很复杂的事情

983
00:00:21,719 --> 00:00:23,640
或者是进行某种对应

984
00:00:23,679 --> 00:00:26,120
而不是他自己总结出一种抽象

985
00:00:27,199 --> 00:00:29,280
我不知道我表达是否清楚

986
00:00:00,000 --> 00:00:06,240
首先我對你那個結論抱有一個懷疑態度

987
00:00:06,240 --> 00:00:10,039
我不認為人類最重要的能力是抽象能力

988
00:00:10,039 --> 00:00:12,919
我不知道啊 可能是 但是我不知道

989
00:00:12,919 --> 00:00:16,280
就是我還沒有足夠的辦法去判斷你的這個結論

990
00:00:16,280 --> 00:00:17,960
然後你剛剛問的問題是

991
00:00:17,960 --> 00:00:20,000
Chai GPT是否具有抽象能力

992
00:00:20,000 --> 00:00:21,879
我原來想直接回答有

993
00:00:21,879 --> 00:00:25,559
但是你好像又提了一個抽象能力有不同的層次

994
00:00:25,559 --> 00:00:26,399
這件事兒

995
00:00:00,000 --> 00:00:06,299
就是你不覺得XGBT今天表現出來的這個歸納等等是抽象能力

996
00:00:06,299 --> 00:00:08,500
我也用過,我深度用過

997
00:00:08,500 --> 00:00:12,660
因為我感覺它就是一種對數據的一種生成

998
00:00:12,660 --> 00:00:15,660
它並不具備所謂人類這種帶有

999
00:00:15,660 --> 00:00:18,019
就是我們理解成這種意識的抽象

1000
00:00:18,019 --> 00:00:19,980
你能不能舉一個具體的例子

1001
00:00:19,980 --> 00:00:23,379
就是你認為人類具備的這個抽象能力是什麼

1002
00:00:23,379 --> 00:00:24,859
比方說數學

1003
00:00:24,859 --> 00:00:28,780
數學它的最基礎就是幾條公理幾條東西

1004
00:00:00,000 --> 00:00:04,440
然後人就可以根據此去不斷的推演各種各種定律

1005
00:00:04,440 --> 00:00:06,599
甚至可以應用到現實生活中

1006
00:00:06,599 --> 00:00:10,560
但是這一件事情我不確定確確確確是否有這個能力

1007
00:00:11,800 --> 00:00:13,519
能取一個就是我們日常

1008
00:00:13,519 --> 00:00:15,199
你說我們每天都在抽象是吧

1009
00:00:15,199 --> 00:00:17,640
能取一個更具體的嗎

1010
00:00:17,640 --> 00:00:20,399
比方說我們比方說廣東人

1011
00:00:20,399 --> 00:00:22,160
大家都會覺得幾種印象

1012
00:00:22,160 --> 00:00:24,120
大家已經腦袋就浮出來了

1013
00:00:24,120 --> 00:00:25,480
比方說東北人

1014
00:00:25,480 --> 00:00:27,960
我說出這三個字大家已經有一個概念了

1015
00:00:27,960 --> 00:00:29,079
對不對

1016
00:00:00,000 --> 00:00:02,000
標籤化我覺得是

1017
00:00:02,000 --> 00:00:04,000
嗯

1018
00:00:04,000 --> 00:00:06,000
實在不好意思啊

1019
00:00:06,000 --> 00:00:08,000
我對這個詞不是很了解

1020
00:00:08,000 --> 00:00:10,000
因為我剛剛想你這個

1021
00:00:10,000 --> 00:00:12,000
比如說大家說廣東人

1022
00:00:12,000 --> 00:00:14,000
想到了幾個對應的東西

1023
00:00:14,000 --> 00:00:16,000
第一我們是標籤化

1024
00:00:16,000 --> 00:00:18,000
第二我們是把每一個人的具體

1025
00:00:18,000 --> 00:00:20,000
每個人都具備了抽象能力

1026
00:00:20,000 --> 00:00:22,000
我想說這個問題

1027
00:00:22,000 --> 00:00:24,000
就是人類的這一種抽象能力

1028
00:00:24,000 --> 00:00:26,000
Quality是否具備呢

1029
00:00:26,000 --> 00:00:28,000
我是比較懷疑

1030
00:00:00,000 --> 00:00:01,000
是這樣想的

1031
00:00:02,640 --> 00:00:05,080
我只能具體的說就是

1032
00:00:05,080 --> 00:00:08,119
你問他廣東人有什麼特性

1033
00:00:08,119 --> 00:00:09,839
他可以給你回答廣東人什麼特性

1034
00:00:11,320 --> 00:00:11,759
對吧

1035
00:00:11,759 --> 00:00:14,599
然後你問他大家對廣東人有什麼刻板印象

1036
00:00:14,599 --> 00:00:15,480
他也能給你回答

1037
00:00:15,480 --> 00:00:17,760
廣東人什麼刻板印象

1038
00:00:20,000 --> 00:00:22,440
但是我不知道這是不是你想表達那個抽象能力

1039
00:00:23,879 --> 00:00:24,640
或者你可以問一下

1040
00:00:24,640 --> 00:00:26,920
大家有沒有人就是能理解更好

1041
00:00:26,920 --> 00:00:28,839
就是能換一種方式表示你的

1042
00:00:00,000 --> 00:00:01,600
表述你说的这个抽象能力

1043
00:00:01,600 --> 00:00:02,600
表达不太清楚

1044
00:00:02,600 --> 00:00:05,000
不是不是 我觉得我很难理解

1045
00:00:05,000 --> 00:00:06,599
因为我抽象能力可能不够

1046
00:00:06,599 --> 00:00:07,799
那个就 对

1047
00:00:09,400 --> 00:00:10,599
好 我理解的话

1048
00:00:10,599 --> 00:00:12,599
这个问题应该是说

1049
00:00:12,599 --> 00:00:16,000
AI能不能自己做特征工程这方面的事情

1050
00:00:16,000 --> 00:00:16,399
能

1051
00:00:16,399 --> 00:00:18,399
比如说现在一堆人

1052
00:00:18,399 --> 00:00:20,600
有的是东北人 有的是东南人

1053
00:00:20,600 --> 00:00:22,000
东北人这些特征

1054
00:00:22,000 --> 00:00:25,000
现在的模型训练是人类给到标签

1055
00:00:25,000 --> 00:00:27,000
然后包括给到已有的特征

1056
00:00:27,399 --> 00:00:29,800
没有 现在也是自动的呀

1057
00:00:00,000 --> 00:00:02,000
就是之前的機器學習

1058
00:00:02,000 --> 00:00:04,400
就不用拆GPT的話

1059
00:00:04,400 --> 00:00:06,080
就像Neural Network

1060
00:00:06,080 --> 00:00:07,360
就是Unsupervised Learning

1061
00:00:07,360 --> 00:00:08,960
不就是自己去做標籤

1062
00:00:08,960 --> 00:00:10,640
所以我想補充的是

1063
00:00:10,640 --> 00:00:15,279
我個人覺得是已經可以做到類似的學習

1064
00:00:16,199 --> 00:00:18,079
然後其實我拿麥克風

1065
00:00:18,079 --> 00:00:20,000
其實我自己有兩個問題想問

1066
00:00:20,000 --> 00:00:21,519
不知道那個同學

1067
00:00:21,519 --> 00:00:23,120
但剛剛回答一下

1068
00:00:23,120 --> 00:00:25,079
就是在拆GPT之前

1069
00:00:25,079 --> 00:00:27,440
機器已經能做這種層次的抽象

1070
00:00:27,440 --> 00:00:29,120
且它的抽象和人類的抽象

1071
00:00:00,000 --> 00:00:01,600
完全不是一個

1072
00:00:01,600 --> 00:00:03,520
就是我們是沒有辦法理解機器

1073
00:00:03,520 --> 00:00:05,000
去理解那些feature的對吧

1074
00:00:05,000 --> 00:00:06,559
就是所以說我們在這

1075
00:00:06,559 --> 00:00:08,800
這是IED工作的一個非常奇怪的點

1076
00:00:08,800 --> 00:00:10,720
就是我回來以後就會覺得

1077
00:00:10,720 --> 00:00:13,000
就明明機器在做很有用的feature

1078
00:00:13,000 --> 00:00:15,759
但是我們經常在工作溝通的時候

1079
00:00:15,759 --> 00:00:18,199
一定要把它總結成人類可以理解的畫像

1080
00:00:18,199 --> 00:00:21,359
最後就會導致我們的這個算法的效果

1081
00:00:21,359 --> 00:00:23,120
不如理想中的好

1082
00:00:23,120 --> 00:00:24,960
你沒有必要把它強行總結成畫像

1083
00:00:24,960 --> 00:00:28,079
但是總之就是機器是有自己去抽象

1084
00:00:28,079 --> 00:00:29,440
和歸納人的方式的

1085
00:00:00,000 --> 00:00:01,879
如果就是能回答你的问题的话

1086
00:00:01,879 --> 00:00:04,480
反正不用拆GPT机器就能干这件事了

1087
00:00:04,480 --> 00:00:05,599
好

1088
00:00:05,599 --> 00:00:08,320
那接下来是我个人的两个问题

1089
00:00:08,320 --> 00:00:12,679
第一个就是假如说前提在一个知识领域

1090
00:00:12,679 --> 00:00:16,199
然后消费者在使用大模型的过程中

1091
00:00:16,199 --> 00:00:18,160
他不知道大模型这些原理

1092
00:00:18,160 --> 00:00:20,679
只知道输入和输出

1093
00:00:20,679 --> 00:00:23,960
然后面对90%的查询的问题

1094
00:00:23,960 --> 00:00:26,519
比如说今天历史上发生了什么事

1095
00:00:26,519 --> 00:00:29,920
那各家的大模型过拆除结果都一样的话

1096
00:00:00,000 --> 00:00:06,440
那消费者会不会更加在乎说品牌价值这一些人类更理解的事情

1097
00:00:06,879 --> 00:00:08,759
那作为上一层的创业机会的话

1098
00:00:08,759 --> 00:00:12,640
我们是否可以从现在开始更加注重品牌价值

1099
00:00:12,640 --> 00:00:14,480
就比如说这个大模型

1100
00:00:14,519 --> 00:00:17,280
我就是融入了我这样一个品牌

1101
00:00:17,280 --> 00:00:21,199
然后消费者在我这里可以得到同样的答案

1102
00:00:21,239 --> 00:00:24,519
但是我的答案是带有我的品牌价值的一个思考的

1103
00:00:24,559 --> 00:00:26,679
是否会有这样的趋势出现

1104
00:00:28,320 --> 00:00:28,879
谢谢啊

1105
00:00:28,879 --> 00:00:29,800
很好的问题

1106
00:00:00,000 --> 00:00:03,680
第一我不觉得会有很多个大模型

1107
00:00:03,680 --> 00:00:05,879
我觉得可能就那么一两家就像云计算一样

1108
00:00:09,519 --> 00:00:10,320
不好意思

1109
00:00:10,320 --> 00:00:14,279
然后第二就是应该大家给的答案是不一样的

1110
00:00:14,279 --> 00:00:16,160
不然的话确实就没什么区别了

1111
00:00:16,160 --> 00:00:16,719
对吧

1112
00:00:17,239 --> 00:00:19,679
但是第三品牌的价值是不是很重要

1113
00:00:19,679 --> 00:00:20,719
我觉得是重要的

1114
00:00:21,640 --> 00:00:24,320
但是它未必体现在是哪一家的大模型上

1115
00:00:24,320 --> 00:00:27,120
而是就比如说我刚刚说的智力分发

1116
00:00:00,000 --> 00:00:03,399
那不同的人不調教出來了不同的GPT

1117
00:00:03,399 --> 00:00:05,000
只教你GPT好了

1118
00:00:05,000 --> 00:00:07,000
有可能有不同家的這個大模型

1119
00:00:07,000 --> 00:00:11,400
那最後這個結果就是我選擇相信誰的大模型的結果

1120
00:00:11,400 --> 00:00:16,000
選擇相信誰基於同樣的大模型調教出來的不同的結果的

1121
00:00:16,000 --> 00:00:18,800
那估計還是相信背後的這個人

1122
00:00:18,800 --> 00:00:21,399
而且我相信就是很多東西都是主觀判斷

1123
00:00:21,399 --> 00:00:25,300
舉個例子就是大眾點評出了一個推薦這個

1124
00:00:25,300 --> 00:00:28,000
就是基於他的各種各樣數據出了一個推薦

1125
00:00:00,000 --> 00:00:03,000
给你推荐餐馆的对话机器人

1126
00:00:03,000 --> 00:00:07,000
然后某小红书APP主出了一个

1127
00:00:07,000 --> 00:00:09,000
然后不知道腾讯出了一个

1128
00:00:09,000 --> 00:00:11,000
那你最后选择谁

1129
00:00:11,000 --> 00:00:12,000
你恐怖派还是选择

1130
00:00:12,000 --> 00:00:14,000
那个人的推荐是不是合你的胃口

1131
00:00:14,000 --> 00:00:16,000
他不是一个基于能力的

1132
00:00:16,000 --> 00:00:18,000
而是基于这种match的

1133
00:00:18,000 --> 00:00:20,000
OK 我还有第二个问题

1134
00:00:20,000 --> 00:00:23,000
就是这是一个非常个人化有趣的问题

1135
00:00:23,000 --> 00:00:26,000
然后我直接想听一下孙老师您的意见

1136
00:00:00,000 --> 00:00:04,799
我在前一段时间跟一个朋友聊天的时候说

1137
00:00:04,799 --> 00:00:06,519
我们都比较喜欢喝酒

1138
00:00:06,519 --> 00:00:09,720
那假如说我们有一天自己有了小孩

1139
00:00:09,720 --> 00:00:13,240
那我们会不会愿意让一个AI在家里带小孩

1140
00:00:13,240 --> 00:00:16,320
给我们时间让我们去喝酒去调酒

1141
00:00:16,320 --> 00:00:19,879
假如说孙老师您现在遇到这样一个场景

1142
00:00:19,879 --> 00:00:21,199
就是说有自己小孩

1143
00:00:21,199 --> 00:00:24,399
但你今晚特别想去调酒特别想去喝酒

1144
00:00:24,399 --> 00:00:28,199
那您愿不愿意让AI来去在家里带这个小孩呢

1145
00:00:00,000 --> 00:00:02,000
這是個陷阱問題

1146
00:00:02,000 --> 00:00:04,000
這是什麼呢

1147
00:00:04,000 --> 00:00:06,000
我當然願意讓AI去取代我的工作了

1148
00:00:06,000 --> 00:00:08,000
當然我可能讓AI去幹活

1149
00:00:08,000 --> 00:00:10,000
然後我去調酒

1150
00:00:10,000 --> 00:00:12,000
然後我再花很多時間在小孩上

1151
00:00:12,000 --> 00:00:14,000
對 我不會去

1152
00:00:14,000 --> 00:00:16,000
讓AI去教小孩

1153
00:00:16,000 --> 00:00:18,000
是為了讓我可以去調酒

1154
00:00:18,000 --> 00:00:20,000
這是另外的取捨 但是你可能 你問題的本質是

1155
00:00:20,000 --> 00:00:22,000
我願不願意讓AI帶小孩

1156
00:00:22,000 --> 00:00:24,000
對吧 願意

1157
00:00:24,000 --> 00:00:26,000
我有啥不願意的

1158
00:00:26,000 --> 00:00:28,000
就我們今天 讓孩子看電視

1159
00:00:00,000 --> 00:00:00,920
還是用互聯網

1160
00:00:00,920 --> 00:00:01,919
這都是工具對吧

1161
00:00:01,919 --> 00:00:02,640
他只是另外

1162
00:00:02,640 --> 00:00:04,639
在我看來只是另外一個工具而已

1163
00:00:06,120 --> 00:00:07,080
我問題結束了

1164
00:00:11,720 --> 00:00:12,560
都有機會

1165
00:00:12,839 --> 00:00:14,439
您好我有個問題就是

1166
00:00:14,640 --> 00:00:17,280
我在現在在用這個Chunk GP的時候

1167
00:00:17,280 --> 00:00:20,079
我發現他不能分清哪些是基本事實

1168
00:00:20,079 --> 00:00:21,839
哪些是一些

1169
00:00:21,839 --> 00:00:23,879
可能他的預料中會有一些很多網友

1170
00:00:23,879 --> 00:00:25,160
一些胡謅的一些

1171
00:00:25,440 --> 00:00:26,640
一些開玩笑的很多說法

1172
00:00:26,640 --> 00:00:28,160
發現他分不清這個東西

1173
00:00:00,000 --> 00:00:03,339
在我拿一些問題去問他的時候

1174
00:00:03,339 --> 00:00:07,339
他可能給我一個偏離事實很遠的回答

1175
00:00:07,339 --> 00:00:10,539
或者說我向他問一些論文的一些

1176
00:00:10,539 --> 00:00:13,539
所以他給我都是一些胡謅的一些回答

1177
00:00:13,539 --> 00:00:14,539
如何避免這個問題

1178
00:00:14,539 --> 00:00:17,839
這個就是很典型的那個hallucination

1179
00:00:17,839 --> 00:00:18,839
就是說胡話的問題

1180
00:00:18,839 --> 00:00:20,839
然後這個說胡話的問題是一個

1181
00:00:20,839 --> 00:00:21,839
很容易解決的問題

1182
00:00:21,839 --> 00:00:23,339
其實病已經把它解決了

1183
00:00:23,339 --> 00:00:24,839
就是如果你用那個

1184
00:00:24,839 --> 00:00:26,839
就是微軟的那個Neo病

1185
00:00:26,839 --> 00:00:29,339
它是帶TGPG對話在搜索是吧

1186
00:00:00,000 --> 00:00:03,040
它上面給你的答案都是它搜出來的回答

1187
00:00:03,040 --> 00:00:05,440
就是你起碼可以去驗證它的好壞

1188
00:00:05,440 --> 00:00:07,240
然後出現這個問題是什麼呢

1189
00:00:07,240 --> 00:00:08,839
第一是個Demo

1190
00:00:08,839 --> 00:00:09,119
對吧

1191
00:00:09,119 --> 00:00:10,119
它只是一個Demo

1192
00:00:10,119 --> 00:00:14,000
然後它的機制是產生下一個詞和你對話

1193
00:00:14,000 --> 00:00:15,720
它不是為了給你準確的信息

1194
00:00:15,720 --> 00:00:18,960
所以說不應該把它當成一個搜索引擎去使用它

1195
00:00:18,960 --> 00:00:22,839
而是把它當成一個這種對話機器和這個叫Reasoning Machine

1196
00:00:22,839 --> 00:00:24,760
就是它可以給你輸出一些

1197
00:00:24,760 --> 00:00:26,600
就是思考

1198
00:00:26,600 --> 00:00:27,839
它可以給你輸出一些理解

1199
00:00:27,839 --> 00:00:29,679
它可以幫你總結歸納知識

1200
00:00:00,000 --> 00:00:02,560
但是你不是把它当成一个搜索引擎去使用

1201
00:00:02,560 --> 00:00:04,799
它也没有针对这方面进行优化

1202
00:00:04,799 --> 00:00:08,560
但是你如果想针对这方面进行优化是一个很简单的事情

1203
00:00:08,560 --> 00:00:10,119
比如说你有病就感到了

1204
00:00:10,119 --> 00:00:13,240
然后你比如说我想在医学领域去做一个

1205
00:00:13,240 --> 00:00:15,919
那我就把高质量的医学的事实给他

1206
00:00:15,919 --> 00:00:19,519
然后跟GPT说你在跟人家说话的时候

1207
00:00:19,519 --> 00:00:21,000
一定要对一下这里面的事实

1208
00:00:21,000 --> 00:00:24,199
然后我教你怎么样子去对这里面的事实就行了

1209
00:00:24,199 --> 00:00:25,839
我想补充一个问题

1210
00:00:25,839 --> 00:00:29,719
就是Query GPT就是3.5版本

1211
00:00:00,000 --> 00:00:01,740
經常有胡亂說話

1212
00:00:01,740 --> 00:00:04,259
就是你問他一些事實錯誤的問題

1213
00:00:04,259 --> 00:00:05,940
他也會接著瞎編

1214
00:00:05,940 --> 00:00:09,720
就是他瞎編這個情況有沒有得到改善

1215
00:00:09,720 --> 00:00:11,339
就是你和他問的是一個問題

1216
00:00:11,339 --> 00:00:12,259
我剛剛回答了

1217
00:00:12,259 --> 00:00:14,939
他已經是通過牛病的問題解決了嗎

1218
00:00:15,419 --> 00:00:15,939
對呀

1219
00:00:16,899 --> 00:00:17,899
就是他可以解決

1220
00:00:17,899 --> 00:00:19,339
就是牛病沒有解決百分之百

1221
00:00:19,339 --> 00:00:21,059
因為他有三立合格各方面的限制

1222
00:00:21,059 --> 00:00:23,339
但是我是說這是一個簡單的

1223
00:00:23,339 --> 00:00:24,739
很容易被解決的問題

1224
00:00:27,859 --> 00:00:28,739
那邊哦

1225
00:00:00,000 --> 00:00:07,000
我想先回應一下,不是回應,我想先幫第一位同學解釋一下

1226
00:00:07,000 --> 00:00:13,000
就是說我理解的,他的抽象問題應該是指的是來源於赫拉利的《本人類簡史》的書

1227
00:00:13,000 --> 00:00:18,000
然後赫拉利的原書的意思應該是人類有討論虛構物的能力

1228
00:00:18,000 --> 00:00:22,000
就是虛構物的對象的能力,而不是說我有抽象的能力

1229
00:00:22,000 --> 00:00:25,000
因為一般,比如說老鼠看到蛇,牠會跑

1230
00:00:00,000 --> 00:00:04,799
不可能說老鼠就沒有抽象能力,牠不能抽象蛇這個動物

1231
00:00:04,799 --> 00:00:09,000
所以說我想討論

1232
00:00:09,000 --> 00:00:13,000
當然這會帶出一個問題

1233
00:00:13,000 --> 00:00:18,000
其實GPT,生存式的預訓練模型

1234
00:00:18,000 --> 00:00:20,000
它所基於的語料都是符號的

1235
00:00:20,000 --> 00:00:25,000
我們的文字本身就是一個抽象的符號

1236
00:00:25,000 --> 00:00:29,000
比如說我是蛇,我不可能表述牠是哪一樣蛇

1237
00:00:00,000 --> 00:00:02,640
比如說每一片樹葉都是不一樣的

1238
00:00:02,640 --> 00:00:07,679
所以說GPT的輸入已經是一個高度抽象跟符號化的結果

1239
00:00:07,679 --> 00:00:11,279
那麼我想帶出來的問題是

1240
00:00:11,279 --> 00:00:15,919
您這個presentation裡面問到的問題

1241
00:00:15,919 --> 00:00:17,920
就是說它是否是一個烏鴉

1242
00:00:17,920 --> 00:00:22,640
我看了您的長文啊

1243
00:00:22,640 --> 00:00:25,920
我的觀點跟周老師的觀點是類似的

1244
00:00:25,920 --> 00:00:28,480
我覺得它不是烏鴉,它只是一個巨鷹

1245
00:00:00,000 --> 00:00:05,000
那我分享一下我的觀點,其實跟周老師基本上一樣,他沒有實踐的能力

1246
00:00:05,000 --> 00:00:12,000
那麼我讀的書裡面有一本是那個為什麼,就是那個Perl,博爾寫的那個為什麼

1247
00:00:12,000 --> 00:00:17,000
基於因果推理的新科學,有這本書

1248
00:00:17,000 --> 00:00:21,000
然後它裡面說到了三個因果推理的階段

1249
00:00:21,000 --> 00:00:28,000
第一個就是通過這種數據的關聯進行推理

1250
00:00:00,000 --> 00:00:02,000
第二個就是通過實踐能力推理

1251
00:00:02,000 --> 00:00:04,000
第三個就是通過What if

1252
00:00:04,000 --> 00:00:06,000
就是說反式實踐能力推理

1253
00:00:06,000 --> 00:00:08,000
那麼實際上

1254
00:00:08,000 --> 00:00:10,000
就是

1255
00:00:10,000 --> 00:00:12,000
GPT嘛就是Per Training

1256
00:00:12,000 --> 00:00:14,000
它其實

1257
00:00:14,000 --> 00:00:16,000
已經預訓練了,它沒有任何的

1258
00:00:16,000 --> 00:00:18,000
實踐的能力在

1259
00:00:18,000 --> 00:00:20,000
除非你對後期在做

1260
00:00:20,000 --> 00:00:22,000
那個Instruct,可能它會

1261
00:00:22,000 --> 00:00:24,000
有一些feedback,但是

1262
00:00:24,000 --> 00:00:26,000
我覺得它並不是一個

1263
00:00:26,000 --> 00:00:28,000
烏鴉,就是它不能

1264
00:00:00,000 --> 00:00:03,240
因為他是pre-training的東西

1265
00:00:03,240 --> 00:00:05,040
然後他也沒有實踐的能力

1266
00:00:05,040 --> 00:00:07,599
就是說我去擊一個台球

1267
00:00:07,599 --> 00:00:09,039
那麼我去擊了這個白球

1268
00:00:09,039 --> 00:00:10,480
我撞到一個紅球

1269
00:00:10,480 --> 00:00:11,640
他沒有這種能力

1270
00:00:11,640 --> 00:00:13,039
就是他沒有感知器

1271
00:00:13,039 --> 00:00:15,439
他的所有語料都是文字

1272
00:00:15,439 --> 00:00:18,480
OK 所以這是我自己的觀點

1273
00:00:21,960 --> 00:00:24,440
我覺得很精彩

1274
00:00:24,440 --> 00:00:26,839
然後我在想怎麼樣子去

1275
00:00:26,839 --> 00:00:28,039
因為你沒問題吧

1276
00:00:28,039 --> 00:00:29,079
沒有我問一個問題

1277
00:00:00,000 --> 00:00:02,040
我就想怎么评价一下你刚刚说

1278
00:00:02,040 --> 00:00:05,000
就是或者说我来讨论一下

1279
00:00:05,000 --> 00:00:07,240
就是第一个点我觉得很有趣

1280
00:00:07,240 --> 00:00:11,720
就是你把它变成了就是抽象

1281
00:00:11,720 --> 00:00:13,519
但是这个我就更容易理解了

1282
00:00:13,519 --> 00:00:14,800
就是我们可以去讨论概念

1283
00:00:14,800 --> 00:00:17,000
但是其他人不能讨论概念对吧

1284
00:00:17,000 --> 00:00:18,800
然后GPT都是来自于符号的

1285
00:00:18,800 --> 00:00:20,199
所以说它只是在概念上

1286
00:00:20,199 --> 00:00:24,440
它反而今天缺的就是这个现实世界的感知

1287
00:00:24,440 --> 00:00:25,839
我觉得这个是很有道理的

1288
00:00:25,839 --> 00:00:29,199
以及这可能也是所谓的AGI

1289
00:00:00,000 --> 00:00:01,740
就是我們今天像SAM

1290
00:00:01,740 --> 00:00:03,540
我覺得CHPT是AGI

1291
00:00:03,540 --> 00:00:04,540
因為他已經能

1292
00:00:04,540 --> 00:00:07,419
就是在很多事情上表現得像一個

1293
00:00:07,419 --> 00:00:09,039
優秀的人類一樣了

1294
00:00:09,039 --> 00:00:11,039
我覺得他就是AGI

1295
00:00:11,039 --> 00:00:13,300
但是SAM他自己不覺得是AGI

1296
00:00:13,300 --> 00:00:15,460
對吧 他覺得他沒有到那個程度

1297
00:00:15,460 --> 00:00:17,260
那但是大家都會覺得

1298
00:00:17,260 --> 00:00:19,379
你想從今天的CHPT到一個

1299
00:00:19,379 --> 00:00:20,800
那個大家想像中的AGI

1300
00:00:20,800 --> 00:00:22,879
最重要的就是增加動脈態

1301
00:00:22,879 --> 00:00:24,679
增加動脈態最重要的目標

1302
00:00:24,679 --> 00:00:27,260
就是為了在現實生活中

1303
00:00:27,260 --> 00:00:29,379
或者說是那些具體的東西中

1304
00:00:00,000 --> 00:00:02,359
得到具體的信息和具體的反饋

1305
00:00:02,359 --> 00:00:04,639
所以說我覺得對這個點很重要

1306
00:00:04,639 --> 00:00:07,280
然後確實是現在模型的短板

1307
00:00:07,280 --> 00:00:09,880
但是希望未來可以照這個方向去解決

1308
00:00:09,880 --> 00:00:13,240
那第二個你說的是不是烏鴉

1309
00:00:13,240 --> 00:00:15,560
還是我還是就是我聽懂了

1310
00:00:15,560 --> 00:00:16,320
我覺得我聽懂了

1311
00:00:16,320 --> 00:00:20,480
就是它按照那個三個因果關係的方式

1312
00:00:20,480 --> 00:00:20,679
是吧

1313
00:00:20,679 --> 00:00:22,879
它缺第二個和第三個的只有第一個

1314
00:00:22,879 --> 00:00:24,440
可是在這種情況下

1315
00:00:24,440 --> 00:00:26,600
就是我們之前是

1316
00:00:26,600 --> 00:00:28,519
就沒有一種生物

1317
00:00:00,000 --> 00:00:03,240
是可以在不接觸現實

1318
00:00:03,240 --> 00:00:05,639
不接觸具體的時候直接接觸抽象的

1319
00:00:05,639 --> 00:00:08,960
就是人在形成抽象的時候必須要從具體來

1320
00:00:08,960 --> 00:00:11,640
所以說我們其實並沒有認真去思考

1321
00:00:11,640 --> 00:00:15,839
你的這個具體是不是因果關係的必備條件

1322
00:00:17,120 --> 00:00:19,160
但是GPT沒有接觸現實

1323
00:00:19,160 --> 00:00:20,800
對呀就是你是不是一個

1324
00:00:20,800 --> 00:00:22,199
假設我們今天有一個人

1325
00:00:22,199 --> 00:00:23,679
今天這個人是不存在的

1326
00:00:23,679 --> 00:00:26,320
因為他必須要先接觸具體才能學習語言

1327
00:00:26,320 --> 00:00:27,519
然後才能去思考

1328
00:00:27,519 --> 00:00:29,399
如果今天這個人他只思考

1329
00:00:00,000 --> 00:00:02,819
就是這個鋼鐘大腦它不需要接觸任何的GPT

1330
00:00:02,819 --> 00:00:05,440
它能不能產生因果關係

1331
00:00:05,440 --> 00:00:07,679
就是這個鋼鐘大腦能不能產生因果關係

1332
00:00:07,679 --> 00:00:08,640
是這個問題

1333
00:00:08,640 --> 00:00:11,000
它不存在所以說我們沒法回答

1334
00:00:11,000 --> 00:00:13,720
但是我覺得它不能排除這樣的可能性吧

1335
00:00:13,720 --> 00:00:16,320
我最後抽象一下

1336
00:00:16,320 --> 00:00:17,800
就是我對GPT的理解

1337
00:00:17,800 --> 00:00:20,559
就是我抽象成一個這個思維實驗

1338
00:00:20,559 --> 00:00:22,399
就是哲學經常搞的這種思維實驗

1339
00:00:22,399 --> 00:00:24,399
就是其實就是一個小女孩

1340
00:00:24,399 --> 00:00:26,600
她在一個封閉的房間裡面

1341
00:00:26,600 --> 00:00:29,719
然後她手頭上有大量的無限的書籍

1342
00:00:00,000 --> 00:00:02,439
當然這些書籍可能沒有圖像

1343
00:00:02,439 --> 00:00:05,200
因為我只是基於GPT 3.5

1344
00:00:05,200 --> 00:00:06,160
那麼他沒有圖像

1345
00:00:06,160 --> 00:00:09,839
那麼他能夠對外部的人做出任何的回答

1346
00:00:09,839 --> 00:00:12,919
他可以有色彩學完整的一套色彩學知識

1347
00:00:12,919 --> 00:00:14,199
他讀的世界上所有書

1348
00:00:14,199 --> 00:00:16,679
對他不知道紅色是什麼顏色

1349
00:00:16,679 --> 00:00:18,879
對他這個是最核心的問題

1350
00:00:18,879 --> 00:00:21,559
他沒有實踐的能力

1351
00:00:21,559 --> 00:00:24,079
我覺得這個是GPT的一個侷限性

1352
00:00:24,079 --> 00:00:25,320
當然我不確定

1353
00:00:25,320 --> 00:00:25,800
等等等等

1354
00:00:25,800 --> 00:00:27,600
剛才你那個問題接下來呢

1355
00:00:27,600 --> 00:00:29,600
就是你本來想說的是

1356
00:00:00,000 --> 00:00:02,399
它有沒有烏鴉的那種

1357
00:00:02,439 --> 00:00:04,200
就是 reasoning comprehension

1358
00:00:04,200 --> 00:00:05,040
deduction

1359
00:00:05,040 --> 00:00:08,240
就是我自己用具體的詞去理解

1360
00:00:08,240 --> 00:00:10,039
它就是它有推理能力

1361
00:00:10,160 --> 00:00:11,279
它有理解能力

1362
00:00:11,400 --> 00:00:13,279
然後它有演繹的能力

1363
00:00:13,560 --> 00:00:14,320
對

1364
00:00:14,320 --> 00:00:17,160
它甚至可能會有一些這個隱身的能力

1365
00:00:17,320 --> 00:00:17,839
對

1366
00:00:18,039 --> 00:00:21,120
這些東西跟現實其實我不覺得

1367
00:00:21,160 --> 00:00:23,039
就是剛剛你說的那個小女孩

1368
00:00:23,160 --> 00:00:25,679
你本來的問題是它有沒有這些

1369
00:00:25,679 --> 00:00:28,440
就是邏輯抽象或者是等等是吧

1370
00:00:00,000 --> 00:00:03,600
但是沒有辦法認識到紅色是什麼顏色

1371
00:00:03,600 --> 00:00:04,799
這個問題重要嗎

1372
00:00:04,799 --> 00:00:07,799
就是它可以給你完美的描述紅色

1373
00:00:07,799 --> 00:00:09,800
它不是一個

1374
00:00:09,800 --> 00:00:12,599
我覺得它這樣的一個東西

1375
00:00:12,599 --> 00:00:14,599
它不能夠稱為一個 AGI

1376
00:00:14,599 --> 00:00:16,000
當然我不知道 AGI 這個定義

1377
00:00:16,000 --> 00:00:20,000
AGI 就是那個微軟最近出了一個

1378
00:00:20,000 --> 00:00:22,000
就是 Evaluate GPT

1379
00:00:22,000 --> 00:00:23,600
GPT-4 的

1380
00:00:23,600 --> 00:00:26,000
然後它在那裡邊開篇

1381
00:00:26,000 --> 00:00:29,199
以長篇磊讀的去講我們怎麼定義 AGI

1382
00:00:00,000 --> 00:00:03,720
他說他舉了這個市面上所有的

1383
00:00:03,720 --> 00:00:06,280
就是主流的去定義AGI的方式

1384
00:00:06,280 --> 00:00:07,519
都是有問題的

1385
00:00:07,519 --> 00:00:09,880
然後他們選擇了一個可能爭議最小的

1386
00:00:09,880 --> 00:00:12,000
那應該是上世紀90年代

1387
00:00:12,000 --> 00:00:13,039
還是具體什麼時間忘了

1388
00:00:13,039 --> 00:00:14,240
一堆心理學家

1389
00:00:14,240 --> 00:00:16,879
然後放到一起去做了定義

1390
00:00:16,879 --> 00:00:18,519
其實大概就是

1391
00:00:19,679 --> 00:00:24,280
他能不能像人一樣去做人類的任務

1392
00:00:24,879 --> 00:00:25,440
對

1393
00:00:25,440 --> 00:00:26,480
那在這種情況下

1394
00:00:26,480 --> 00:00:29,960
就是我知道他不知道紅色

1395
00:00:00,000 --> 00:00:02,399
或者說他不能像我一樣認識紅色

1396
00:00:02,799 --> 00:00:05,000
但是他能給你完整的描述紅色

1397
00:00:05,299 --> 00:00:08,699
他能基於這個顏色的描述去做所有

1398
00:00:08,900 --> 00:00:10,800
顏色描述需要做到的任務

1399
00:00:11,199 --> 00:00:13,099
那他現實的他沒有辦法

1400
00:00:13,199 --> 00:00:14,699
他沒有辦法識別紅色是嗎

1401
00:00:14,900 --> 00:00:15,900
他沒有感受器

1402
00:00:16,399 --> 00:00:17,600
就是現在的3.5

1403
00:00:17,899 --> 00:00:21,000
對你在描述一個事實

1404
00:00:21,000 --> 00:00:22,300
但是這個事實我就說

1405
00:00:22,300 --> 00:00:23,899
那他的implication是什麼

1406
00:00:23,899 --> 00:00:24,399
就是

1407
00:00:25,699 --> 00:00:27,000
比如說他要去調酒

1408
00:00:28,000 --> 00:00:29,199
他當然不能去調酒了

1409
00:00:00,000 --> 00:00:02,960
我不認為調酒是我去認識他的

1410
00:00:02,960 --> 00:00:05,160
我去判斷他的任何的重要的條件

1411
00:00:05,879 --> 00:00:07,679
就是所以說認不認識紅色

1412
00:00:07,679 --> 00:00:10,560
也不是我判斷他能力的一個條件

1413
00:00:10,880 --> 00:00:13,759
就是他他為什麼需要認識紅色呢

1414
00:00:13,759 --> 00:00:16,800
就是無法完成完成跟色彩相關的任務

1415
00:00:16,960 --> 00:00:17,760
問題就是這樣子

1416
00:00:17,760 --> 00:00:20,199
那他可以不需要完成需要必須我要

1417
00:00:20,199 --> 00:00:23,719
那您剛剛的定義相違背了

1418
00:00:23,719 --> 00:00:27,199
就是說您需要AGI去幫您完成某一項任務

1419
00:00:27,280 --> 00:00:29,000
但是我的我的觀點

1420
00:00:00,000 --> 00:00:01,679
也就是说他没有实践的能力

1421
00:00:01,679 --> 00:00:05,759
所以说他只能够作为一个我的智库这样的一个角色

1422
00:00:05,759 --> 00:00:09,560
但是他无法帮我去做动作

1423
00:00:09,580 --> 00:00:10,800
我是这么一个观点

1424
00:00:10,800 --> 00:00:13,720
我写一个PPT是具体的做动作吗

1425
00:00:13,740 --> 00:00:14,320
对对的

1426
00:00:14,320 --> 00:00:16,879
我知道他现在确实有很多

1427
00:00:16,879 --> 00:00:20,320
不就是我在想我的这个公司是怎么来的

1428
00:00:20,320 --> 00:00:22,800
一大半都是来自于我的PPT

1429
00:00:22,800 --> 00:00:25,120
那他有没有做动作呢

1430
00:00:25,120 --> 00:00:26,640
PPT他

1431
00:00:00,000 --> 00:00:06,519
首先PPT它是一個文字性的工作

1432
00:00:06,519 --> 00:00:08,480
我還是回到色彩學

1433
00:00:08,480 --> 00:00:11,000
就是他沒有辦法認識到紅色

1434
00:00:11,000 --> 00:00:14,279
他能不能操作我的電腦

1435
00:00:14,279 --> 00:00:16,320
然後給我的PPT做出美觀

1436
00:00:16,320 --> 00:00:17,800
我說什麼樣的東西是美觀的

1437
00:00:17,800 --> 00:00:19,719
然後他操作我的電腦

1438
00:00:19,739 --> 00:00:22,399
通過顏色把我的PPT調到一個好看的

1439
00:00:23,679 --> 00:00:24,120
可以吧

1440
00:00:24,120 --> 00:00:24,679
類似吧

1441
00:00:24,679 --> 00:00:28,160
但是當然計算機內肯定是有符號

1442
00:00:00,000 --> 00:00:02,060
他計算機可以就是計算機

1443
00:00:02,060 --> 00:00:04,280
就是您發出一個紅色指令

1444
00:00:04,280 --> 00:00:07,919
他計算機可能他會能夠識別這個指令

1445
00:00:07,919 --> 00:00:11,199
就是說GPT給計算機發一個紅色指令

1446
00:00:11,199 --> 00:00:14,240
對他可能可以會是可以識別

1447
00:00:14,240 --> 00:00:15,720
對就是

1448
00:00:15,720 --> 00:00:19,839
所以就是剛剛回到我們兩個可能有那麼一細微的不同

1449
00:00:19,839 --> 00:00:23,199
就是你覺得他必須要像我一樣理解紅色

1450
00:00:23,199 --> 00:00:24,800
他才能有用

1451
00:00:24,800 --> 00:00:26,000
他才能實踐

1452
00:00:26,000 --> 00:00:26,760
他才能有用

1453
00:00:00,000 --> 00:00:02,720
現實社會互動 現實空間

1454
00:00:02,720 --> 00:00:04,719
好 我再說一個

1455
00:00:04,719 --> 00:00:06,919
我可能背後有一個另外的理解

1456
00:00:06,919 --> 00:00:09,279
就是有一個App主是老蔣聚靠普

1457
00:00:09,279 --> 00:00:10,640
然後他有說我們這個

1458
00:00:10,640 --> 00:00:13,039
其實我們是活在四個世界裡面

1459
00:00:13,039 --> 00:00:14,759
一個是現實世界

1460
00:00:14,759 --> 00:00:17,120
一個是感知世界

1461
00:00:17,120 --> 00:00:18,440
就是現實世界是現實

1462
00:00:18,440 --> 00:00:20,399
但是我睜開眼看到了以後

1463
00:00:20,399 --> 00:00:21,760
它變成了我的感知

1464
00:00:21,760 --> 00:00:23,120
這是我看到的東西

1465
00:00:23,120 --> 00:00:25,039
然後第三個是意義世界

1466
00:00:25,039 --> 00:00:27,519
然後說在這個計算機發現了以後

1467
00:00:27,519 --> 00:00:29,039
有一個數字世界

1468
00:00:00,000 --> 00:00:02,000
然后这四个世界会互相挤占

1469
00:00:02,520 --> 00:00:03,240
我现在说呢

1470
00:00:03,240 --> 00:00:05,160
就是我的绝大多数工作

1471
00:00:05,160 --> 00:00:07,960
其实是在数字世界和意义世界里面完成的

1472
00:00:08,199 --> 00:00:11,519
这是我拿到工资的绝大多数的来源

1473
00:00:11,800 --> 00:00:15,000
就是我也不需要去现实世界中改变任何事

1474
00:00:15,640 --> 00:00:18,760
我的PPT是我的工资的来源

1475
00:00:20,320 --> 00:00:25,920
Chai GPT它的这个能力是可以在这个意义世界和

1476
00:00:26,320 --> 00:00:29,399
这个数字世界里面去进行操作的对吧

1477
00:00:00,000 --> 00:00:02,759
它沒有辦法去觸碰到那個真實世界

1478
00:00:02,759 --> 00:00:03,839
它也沒有感知

1479
00:00:03,839 --> 00:00:05,559
或者說它的感知方式和我們不一樣

1480
00:00:05,559 --> 00:00:07,080
它只能通過我們的符號

1481
00:00:07,080 --> 00:00:09,359
和我們通過其他的知識去進行感知

1482
00:00:09,359 --> 00:00:11,160
但是它能在這裡邊去完成任務

1483
00:00:11,160 --> 00:00:13,439
它能在上兩層世界完成任務

1484
00:00:13,439 --> 00:00:15,160
這是我的可能和你的區別

1485
00:00:15,160 --> 00:00:18,399
就是在我看來這樣的東西

1486
00:00:18,399 --> 00:00:20,920
就已經是一個在這兩個世界上

1487
00:00:20,920 --> 00:00:23,800
足夠有用且足夠能幫助到人類的方式了

1488
00:00:23,800 --> 00:00:27,079
它不需要去跟真實世界去產生交互

1489
00:00:27,079 --> 00:00:29,559
可能我倆對於AGI的定義有些不一樣

1490
00:00:00,000 --> 00:00:04,000
沒有人定義是一樣的 這是問題

1491
00:00:04,000 --> 00:00:09,000
或者說我也不想就是去用AGI這樣一個

1492
00:00:09,000 --> 00:00:12,000
大家沒有準確定義的東西去說它

1493
00:00:12,000 --> 00:00:15,000
我說的是我會去思考它能做到什麼

1494
00:00:15,000 --> 00:00:17,000
然後我會思考

1495
00:00:17,000 --> 00:00:19,000
它已經能賺我70%的薪水了

1496
00:00:19,000 --> 00:00:23,000
我帶線上的同學問一下

1497
00:00:00,000 --> 00:00:11,000
GVT有人類普遍認知範圍內的審美能力嗎?

1498
00:00:11,000 --> 00:00:16,000
在文學、繪畫、音樂等等方面有可能爆發出emergency嗎?

1499
00:00:16,000 --> 00:00:19,000
什麼是人類普遍認知的審美能力?

1500
00:00:19,000 --> 00:00:26,000
這個孫老師可以以您的理解來回答

1501
00:00:00,000 --> 00:00:02,000
我也只是個代問

1502
00:00:02,000 --> 00:00:03,000
我也只是個代問

1503
00:00:03,000 --> 00:00:06,000
這是一個非常之深刻的哲學問題

1504
00:00:06,000 --> 00:00:08,000
就是人類普遍

1505
00:00:08,000 --> 00:00:10,000
審美是主觀還是客觀的

1506
00:00:10,000 --> 00:00:11,000
這個有答案嗎

1507
00:00:14,000 --> 00:00:16,000
我只是個代問

1508
00:00:16,000 --> 00:00:20,000
我希望他能回答一下

1509
00:00:20,000 --> 00:00:22,000
那我們現場問題優先一些

1510
00:00:22,000 --> 00:00:23,000
好的

1511
00:00:24,000 --> 00:00:26,000
話說剛才那個問題

1512
00:00:26,000 --> 00:00:27,000
我自己的回答就是

1513
00:00:27,000 --> 00:00:29,000
審美是主觀的還是客觀的

1514
00:00:00,000 --> 00:00:04,799
最後的答案是主觀和客觀是一個錯誤的分類方式

1515
00:00:04,799 --> 00:00:07,099
就是審美才是唯一的

1516
00:00:07,099 --> 00:00:09,000
然後主觀和客觀其實不重要

1517
00:00:09,000 --> 00:00:11,800
你好 孫老師你好

1518
00:00:11,800 --> 00:00:13,500
然後我是一個就是

1519
00:00:13,500 --> 00:00:15,500
因為我不像其他同學那樣

1520
00:00:15,500 --> 00:00:17,500
就那麼高深的去想一些

1521
00:00:17,500 --> 00:00:18,800
裡面深入一些知識

1522
00:00:18,800 --> 00:00:20,600
我做一個普通的普通人

1523
00:00:20,600 --> 00:00:22,600
我想關注的是一個

1524
00:00:22,600 --> 00:00:24,600
我們都是狗

1525
00:00:24,600 --> 00:00:27,100
對 就是一個開發領域

1526
00:00:00,000 --> 00:00:04,500
或者是一個manly的角度去想AI

1527
00:00:04,500 --> 00:00:07,500
然後我這裡有三個小問題

1528
00:00:07,500 --> 00:00:13,300
第一個是說最近湧現出大量的魔法寫作者

1529
00:00:13,300 --> 00:00:17,859
類似於說怎麼樣好利用那個指令去

1530
00:00:17,859 --> 00:00:19,859
吩咐AI為我們做事情

1531
00:00:19,859 --> 00:00:21,859
那這個語言的話

1532
00:00:21,859 --> 00:00:26,260
我們有沒有必要去深入學習

1533
00:00:00,000 --> 00:00:01,740
或者是在

1534
00:00:01,740 --> 00:00:03,779
因為以後的平台會越來越多

1535
00:00:03,779 --> 00:00:04,740
4.0也好

1536
00:00:04,740 --> 00:00:08,279
然後Google的Gamma或者Newbeam什麼

1537
00:00:08,279 --> 00:00:09,339
就越來越多平台

1538
00:00:09,339 --> 00:00:11,939
那我們現在現階段有沒有必要去說

1539
00:00:11,939 --> 00:00:13,640
去學這個魔法語言

1540
00:00:13,640 --> 00:00:18,339
這個魔法語言有很多大量工作機會

1541
00:00:18,339 --> 00:00:19,440
在市場中

1542
00:00:19,440 --> 00:00:20,179
特別在美國

1543
00:00:20,179 --> 00:00:23,239
可能現在中國可能稍微沒那麼流行

1544
00:00:23,239 --> 00:00:26,379
但是我看到已經很多那種機會在裡面

1545
00:00:26,379 --> 00:00:28,899
所以我想這是第一個問題

1546
00:00:00,000 --> 00:00:02,799
然後我是一個一個回還是三個問題是相關的

1547
00:00:02,799 --> 00:00:04,000
所以我聽完三個再回

1548
00:00:04,639 --> 00:00:06,559
哦就就看看看老師念

1549
00:00:06,559 --> 00:00:07,280
我怕記不住

1550
00:00:07,280 --> 00:00:08,000
哈哈對

1551
00:00:08,800 --> 00:00:10,359
有相關的話我就聽完三個

1552
00:00:10,359 --> 00:00:12,080
不是那麼相關的話我就一個一個回

1553
00:00:12,400 --> 00:00:14,960
呃可能還是先算一下吧

1554
00:00:14,960 --> 00:00:16,079
我先簡單回一下吧

1555
00:00:16,079 --> 00:00:19,280
然後就是然後再你可以到時候你再一起問

1556
00:00:19,399 --> 00:00:21,079
啊就第一他沒有賺那麼多錢

1557
00:00:21,079 --> 00:00:22,760
那些那些新聞是一些

1558
00:00:23,280 --> 00:00:24,239
博眼球的新聞

1559
00:00:24,440 --> 00:00:25,960
就沒有出現那麼多工作細回

1560
00:00:25,960 --> 00:00:27,000
然後那些照片

1561
00:00:27,199 --> 00:00:27,800
可能可能

1562
00:00:00,000 --> 00:00:02,560
也不知道就是他可能今天照片就没有了

1563
00:00:02,560 --> 00:00:05,400
但是更重要的就是他的这个prompting

1564
00:00:05,400 --> 00:00:06,879
对吧就是你怎么样去跟他对话

1565
00:00:06,879 --> 00:00:09,720
然后去我们很明显看到不同人跟他对话

1566
00:00:09,720 --> 00:00:11,560
他的质量会非常的差的非常大

1567
00:00:11,560 --> 00:00:13,359
甚至我跟他用不同的方式对话

1568
00:00:13,359 --> 00:00:14,919
我得到的答案也会差的非常大

1569
00:00:14,919 --> 00:00:18,079
然后我这更深入的一个思考就是

1570
00:00:18,079 --> 00:00:19,839
他到底是一个更工程向的能力

1571
00:00:19,839 --> 00:00:21,920
还是一个更PM向的能力

1572
00:00:21,920 --> 00:00:24,280
就是你需要用产品经营的方式去跟他对话

1573
00:00:24,280 --> 00:00:26,160
还是用工程师的方式去跟他对话

1574
00:00:26,160 --> 00:00:27,600
区别是什么呢

1575
00:00:00,000 --> 00:00:02,200
那就是工程师问的是

1576
00:00:02,200 --> 00:00:04,799
去跟他对话的方式是教他怎么做

1577
00:00:04,799 --> 00:00:07,400
就是我在这有这样的几个做法

1578
00:00:07,400 --> 00:00:08,300
我告诉你怎么做

1579
00:00:08,300 --> 00:00:11,300
然后产品经理呢是我要什么东西

1580
00:00:11,300 --> 00:00:13,400
我告诉你什么是我想要的

1581
00:00:13,400 --> 00:00:14,400
什么是我不想要的

1582
00:00:14,400 --> 00:00:17,899
今天绝大多数的好的这个prompting

1583
00:00:17,899 --> 00:00:18,699
都是工程能力

1584
00:00:18,699 --> 00:00:19,699
都是告诉他怎么做

1585
00:00:19,699 --> 00:00:21,500
我相信未来会越来越多的

1586
00:00:21,500 --> 00:00:23,399
我告诉你我要什么

1587
00:00:23,399 --> 00:00:25,300
因为他自己模型能力在上升

1588
00:00:25,300 --> 00:00:27,899
大概是一个这种感觉

1589
00:00:27,899 --> 00:00:28,899
谢谢

1590
00:00:00,000 --> 00:00:06,780
然後,然後孟老師第二個問題是說,如果就是老師您以後要創業的話

1591
00:00:06,780 --> 00:00:07,580
就結合……

1592
00:00:07,580 --> 00:00:08,380
沒有啊

1593
00:00:08,380 --> 00:00:13,380
就打個比方,就打個比方,就是副業也好,什麼也好,就是anyway

1594
00:00:13,380 --> 00:00:20,780
然後結合如果現在AI的話,以老師您的這個現在的認知或者是您的高度

1595
00:00:20,780 --> 00:00:24,379
在未來十年的話,對AI這個領域結合

1596
00:00:00,000 --> 00:00:02,960
因為我的個人觀點是

1597
00:00:02,960 --> 00:00:05,679
我認為的上一個起點應該是

1598
00:00:05,679 --> 00:00:08,439
Internet 就是互聯網家

1599
00:00:08,439 --> 00:00:11,480
那我覺得以後的未來市場應該是AI家

1600
00:00:11,480 --> 00:00:13,380
那有什麼行業是

1601
00:00:13,380 --> 00:00:15,919
孫老師您覺得如果您要創業

1602
00:00:15,919 --> 00:00:19,960
您覺得對於我們一般要有什麼領域

1603
00:00:19,960 --> 00:00:22,160
可以覺得前提是比較好的

1604
00:00:22,160 --> 00:00:22,920
我

1605
00:00:22,920 --> 00:00:27,920
對 然後例如我現在有一些領域上的

1606
00:00:00,000 --> 00:00:04,320
例如AI結合股票、AI結合彩票

1607
00:00:04,320 --> 00:00:06,320
就是這種

1608
00:00:06,320 --> 00:00:08,320
腦洞

1609
00:00:08,320 --> 00:00:10,320
然後結合這種應用開發

1610
00:00:10,320 --> 00:00:12,320
如果是對於

1611
00:00:12,320 --> 00:00:16,559
因為我不清楚AI對於預測能力的一些發展

1612
00:00:16,559 --> 00:00:18,559
或者是它的一些能力

1613
00:00:18,559 --> 00:00:22,800
所以我在這個領域上會有點想要問孫老師您的

1614
00:00:22,800 --> 00:00:24,800
然後還有一個相關

1615
00:00:24,800 --> 00:00:26,800
就是跟這個一樣的

1616
00:00:26,800 --> 00:00:28,800
這幾天出來一個叫auto

1617
00:00:00,000 --> 00:00:06,240
跟現在GDP 4.0具體有什麼差別?

1618
00:00:06,240 --> 00:00:07,839
就這麼樣

1619
00:00:07,839 --> 00:00:10,320
我先回答第三個吧,簡單一點

1620
00:00:10,320 --> 00:00:14,080
它是基於GPT的能力的一個應用方式

1621
00:00:14,080 --> 00:00:18,640
對,就是你需要調GPT或GPT 4的API

1622
00:00:18,640 --> 00:00:20,960
你如果沒有GPT 4的API,你用不了那個東西

1623
00:00:20,960 --> 00:00:24,800
你也不能用GPT 4的方式去用那個東西

1624
00:00:24,800 --> 00:00:26,320
那個東西所謂做的東西

1625
00:00:00,000 --> 00:00:05,719
他做的就是去把你的任务用他的东西去拆解

1626
00:00:05,719 --> 00:00:07,839
然后不断的去问GPT怎么做

1627
00:00:07,839 --> 00:00:08,919
然后再去执行

1628
00:00:09,199 --> 00:00:11,560
其实所以叫Auto GPT

1629
00:00:11,679 --> 00:00:12,119
对

1630
00:00:12,119 --> 00:00:16,760
就是你原来可能是就是让一个人在没有想清楚怎么做的时候

1631
00:00:16,760 --> 00:00:18,239
让GPT帮他想怎么做

1632
00:00:18,280 --> 00:00:19,559
大概是这样的一个东西

1633
00:00:19,839 --> 00:00:21,559
回到第二点

1634
00:00:21,760 --> 00:00:26,079
我自己没有去思考这个问题

1635
00:00:26,079 --> 00:00:26,719
为什么

1636
00:00:26,760 --> 00:00:28,920
因为我觉得创业最重要的一点

1637
00:00:00,000 --> 00:00:02,500
最重要的兩點,一個是Parallel Market Fit

1638
00:00:02,500 --> 00:00:04,799
就是你市場和這個產品是要結合的

1639
00:00:04,799 --> 00:00:07,799
當然還有一個同樣重要的點就是Founder Market Fit

1640
00:00:07,799 --> 00:00:10,500
就是你自己要適合做這件事

1641
00:00:10,500 --> 00:00:12,300
股票加AI跟我有啥關係

1642
00:00:12,300 --> 00:00:13,800
就根本不是我的機會

1643
00:00:13,800 --> 00:00:16,500
彩票加AI更不是我的這個機會了對吧

1644
00:00:16,500 --> 00:00:18,500
所以說我今天看到的所有東西

1645
00:00:18,500 --> 00:00:20,500
我不覺得那些東西屬於我

1646
00:00:20,500 --> 00:00:22,500
如果我看到了我可能會去創業

1647
00:00:22,500 --> 00:00:24,500
但是我沒有看到任何屬於我的東西

1648
00:00:24,500 --> 00:00:27,300
就其實想要了解那個

1649
00:00:00,000 --> 00:00:05,519
AI對預測性就是這種預測或者基於大數據會對未來預測那個

1650
00:00:05,519 --> 00:00:10,960
呃判斷或他能力能去到一個現階段能去到一個哪裡的一個總和

1651
00:00:10,960 --> 00:00:12,320
預測股價嗎

1652
00:00:12,320 --> 00:00:16,320
呃可能打個比方可能有一些小項目可能是

1653
00:00:16,320 --> 00:00:20,120
大家一起拼團去買一個什麼六二彩

1654
00:00:20,120 --> 00:00:21,120
那

1655
00:00:21,120 --> 00:00:22,519
預測不了

1656
00:00:22,519 --> 00:00:23,719
預測不了

1657
00:00:23,719 --> 00:00:24,600
是完全不可能

1658
00:00:24,600 --> 00:00:28,320
除非他的那個彩票本身的那個就是

1659
00:00:00,000 --> 00:00:03,200
生成彩票號碼的機制本身是有規律的

1660
00:00:03,200 --> 00:00:06,540
但是六合彩最基本的大家會去買的核心假設

1661
00:00:06,540 --> 00:00:08,160
就是它的那個是沒有規律的

1662
00:00:08,740 --> 00:00:10,759
所以說如果不存在這個規律

1663
00:00:10,759 --> 00:00:12,160
他也沒有辦法抓到這個規律

1664
00:00:14,880 --> 00:00:18,000
對 剛剛沒有說完的就是

1665
00:00:18,000 --> 00:00:19,079
不是我的機會

1666
00:00:19,079 --> 00:00:21,000
但是我覺得我要做的很重要的事情

1667
00:00:21,000 --> 00:00:23,579
剛給大家建議就是學一門手藝

1668
00:00:25,500 --> 00:00:26,920
學手藝是很重要的

1669
00:00:26,920 --> 00:00:29,379
再一個就是如果說GPT真的帶來了

1670
00:00:00,000 --> 00:00:01,340
那提高自己的判斷力

1671
00:00:01,340 --> 00:00:02,839
提高自己的平凡性思維

1672
00:00:02,839 --> 00:00:04,339
會非常非常重要

1673
00:00:04,339 --> 00:00:05,540
因為只有這個東西

1674
00:00:05,540 --> 00:00:07,540
才是你和其他人的區別

1675
00:00:07,540 --> 00:00:08,839
不然的話你只是知識

1676
00:00:08,839 --> 00:00:10,000
或者簡單的性能

1677
00:00:10,000 --> 00:00:11,339
絕對是大家都一樣的

1678
00:00:11,339 --> 00:00:12,500
很快就會被

1679
00:00:12,500 --> 00:00:14,339
只要GPT不是在做那個

1680
00:00:14,339 --> 00:00:15,380
現實世界中的東西

1681
00:00:15,380 --> 00:00:16,379
是吧 在異議世界裡面

1682
00:00:16,379 --> 00:00:17,539
很快都可以取代的

1683
00:00:17,539 --> 00:00:19,539
那你和別人的區別

1684
00:00:19,539 --> 00:00:21,039
和為什麼你調教出來

1685
00:00:21,039 --> 00:00:22,339
GPT和別人不一樣

1686
00:00:22,339 --> 00:00:23,339
那就是你的判斷力

1687
00:00:23,339 --> 00:00:24,339
和平凡性思維了

1688
00:00:24,339 --> 00:00:25,339
好 謝謝

1689
00:00:25,339 --> 00:00:26,339
謝謝書德兄

1690
00:00:00,000 --> 00:00:10,000
老師你好,就是可能剛才咱們聊的可能是一些偏理論的一些東西,可能就是對於我來說,我可能想請教幾個就是偏應用側的一些問題。

1691
00:00:10,000 --> 00:00:19,000
其實我的第一個問題就是說,既然GPT它是基於咱們的一些內容去學習,先得到一個答案,可以這樣說。

1692
00:00:19,000 --> 00:00:25,000
那麼是否會存在就是說,當人們大量應用GPT的時候,大家產出的內容都是一致的。

1693
00:00:00,000 --> 00:00:02,000
那么这个时候他再去学习

1694
00:00:02,000 --> 00:00:04,000
那他这个内容是否能产生

1695
00:00:04,000 --> 00:00:06,000
其实我的一个观点就是说

1696
00:00:06,000 --> 00:00:11,000
他是否会对人类现有的一些可能普通的真理性的一些内容

1697
00:00:11,000 --> 00:00:13,000
产生了不一样的一些看法

1698
00:00:13,000 --> 00:00:16,000
但是因为觉得这个是对的人变多了

1699
00:00:16,000 --> 00:00:17,000
他们就变成了真理

1700
00:00:17,000 --> 00:00:19,000
会不会有这种可能性

1701
00:00:19,000 --> 00:00:21,000
我一个一个回答还是

1702
00:00:21,000 --> 00:00:22,000
啊好啊

1703
00:00:22,000 --> 00:00:23,000
我觉得这个也是个很好的问题

1704
00:00:23,000 --> 00:00:26,000
我也经过几次的认知的想法吧

1705
00:00:26,000 --> 00:00:28,000
就是第一我第一次一开始

1706
00:00:00,000 --> 00:00:02,759
一開始我其實是個GPT降臨派

1707
00:00:02,759 --> 00:00:04,320
就是立場盛名

1708
00:00:04,320 --> 00:00:07,480
我是很希望GPT來多取代一些人的

1709
00:00:07,480 --> 00:00:08,000
為什麼

1710
00:00:08,000 --> 00:00:09,640
因為我看內容

1711
00:00:09,640 --> 00:00:10,720
我看小紅書

1712
00:00:10,720 --> 00:00:12,240
出來了一條爆款內容

1713
00:00:12,240 --> 00:00:13,720
誇全都是類似的爆款內容

1714
00:00:13,720 --> 00:00:15,519
然後又加很多假的

1715
00:00:15,519 --> 00:00:17,839
就比如說你要上面去搜減肥搜健身

1716
00:00:17,839 --> 00:00:19,359
一大半的人是騙你的吧

1717
00:00:19,359 --> 00:00:19,839
對吧

1718
00:00:19,839 --> 00:00:21,640
所以說我覺得取代這些內容

1719
00:00:21,640 --> 00:00:22,600
那是一件好事

1720
00:00:22,600 --> 00:00:23,440
功德無量

1721
00:00:23,440 --> 00:00:25,079
然後後來我又在想

1722
00:00:25,079 --> 00:00:28,280
確實就是會有很多人去產生那些高質量的內容

1723
00:00:00,000 --> 00:00:04,799
但是如果GPT去把這些人的創作動機給取代了

1724
00:00:04,799 --> 00:00:06,759
那這些人就不會產生了 對吧

1725
00:00:06,759 --> 00:00:08,960
那確實就是你剛剛說的這個問題

1726
00:00:08,960 --> 00:00:10,119
但是我後來在想

1727
00:00:10,119 --> 00:00:12,119
就是說或者說之前聽了一個播客

1728
00:00:12,119 --> 00:00:14,400
是那個清華的劉嘉老師

1729
00:00:14,400 --> 00:00:17,160
我很推薦在小宇宙上叫劉嘉

1730
00:00:17,160 --> 00:00:18,320
就是那個嘉賓的嘉

1731
00:00:18,320 --> 00:00:19,679
劉嘉老師的播客

1732
00:00:19,679 --> 00:00:24,480
他就講說他是做這個認知科學的這些

1733
00:00:24,480 --> 00:00:26,039
然後心理學

1734
00:00:26,039 --> 00:00:28,039
然後他就說我們其實每個人都知道

1735
00:00:28,039 --> 00:00:28,879
素質教育重要

1736
00:00:00,000 --> 00:00:02,640
但是我們學校裡邊到現在都不教素質教育

1737
00:00:02,919 --> 00:00:03,439
為啥

1738
00:00:04,120 --> 00:00:05,080
因為高考不考

1739
00:00:05,559 --> 00:00:07,480
對 所以說為什麼高考不考

1740
00:00:07,480 --> 00:00:09,679
因為那些東西好考 那些東西容易量化

1741
00:00:09,679 --> 00:00:11,400
你的知識技能那些東西容易量化

1742
00:00:11,400 --> 00:00:12,880
你的素質是很難量化的

1743
00:00:13,160 --> 00:00:15,480
批判性思維是很難量化的 對吧

1744
00:00:15,720 --> 00:00:17,679
我們跟一個人聊三天天也不一定知道

1745
00:00:17,679 --> 00:00:18,559
他有沒有批判性思維

1746
00:00:18,559 --> 00:00:19,839
而在輔助別人觀點

1747
00:00:20,039 --> 00:00:24,879
所以說當你的那些知識這些東西沒有用了以後

1748
00:00:24,879 --> 00:00:26,879
人們如果是要去改變

1749
00:00:26,879 --> 00:00:28,719
人們是要再適應這個新環境

1750
00:00:00,000 --> 00:00:04,000
可能就是要去多注重批判性這些東西

1751
00:00:04,000 --> 00:00:07,000
那可能反而會促使那些

1752
00:00:07,000 --> 00:00:09,599
所謂的有原創性內容的人

1753
00:00:09,599 --> 00:00:11,000
他們變得更重要

1754
00:00:11,000 --> 00:00:15,000
和就是更多的人會變成像他們那樣的人吧

1755
00:00:15,000 --> 00:00:15,800
不猜

1756
00:00:15,800 --> 00:00:16,800
這是我的希望啊

1757
00:00:16,800 --> 00:00:19,000
就是還有可能是實施另一個發展

1758
00:00:19,000 --> 00:00:20,600
好的我可能還有兩個

1759
00:00:20,600 --> 00:00:22,000
就是可能沒那麼相關的問題

1760
00:00:22,000 --> 00:00:23,000
也想請教一下

1761
00:00:23,000 --> 00:00:26,000
就是說最近包括像百度啊

1762
00:00:26,000 --> 00:00:28,000
像阿里比如說百度的文青一言

1763
00:00:28,000 --> 00:00:29,600
然後阿里的同意千問

1764
00:00:00,000 --> 00:00:06,599
它其实都是基于这些可能大语言模型去得到的一些这样的产品

1765
00:00:06,599 --> 00:00:12,400
那么可能赞老师你看他们之间最目前来说他们之间的差距大概是什么样子

1766
00:00:12,400 --> 00:00:14,900
包括他们之间的一些合作差距是什么

1767
00:00:15,400 --> 00:00:18,500
我有一个视频专门说这个

1768
00:00:18,500 --> 00:00:23,300
然后我的那个就是主标题是国产大模大模线有希望吗

1769
00:00:23,500 --> 00:00:27,000
然后我的副标题是中国国足能进世界杯能拿世界杯吗

1770
00:00:00,000 --> 00:00:04,799
就是這樣就是就是你會看大家都是在踢球對吧

1771
00:00:04,799 --> 00:00:07,500
但是踢球的水平是差很大的

1772
00:00:07,500 --> 00:00:10,400
就是這種感覺就是大家都看上去在對話

1773
00:00:10,400 --> 00:00:15,000
但是背後的那個就是智慧程度差很大

1774
00:00:15,000 --> 00:00:19,800
嗯好那老師我可能有最後一個問題就是說包括像咱們就是說

1775
00:00:19,800 --> 00:00:22,399
China GPT 然後國內的這些大型模型

1776
00:00:22,399 --> 00:00:27,699
那麼其實會不會說這些產品他們所帶來的應用場景

1777
00:00:27,699 --> 00:00:29,500
也可以做一些差異化的一些東西

1778
00:00:00,000 --> 00:00:02,799
比如說GPT它可能更注重一些

1779
00:00:02,799 --> 00:00:05,200
可能它的某些能力更厲害

1780
00:00:05,200 --> 00:00:08,000
那麼它對應的一些場景

1781
00:00:08,000 --> 00:00:10,699
可能就不是做小紅書內容這種場景

1782
00:00:10,699 --> 00:00:13,000
那假如說像是這種通銀千問

1783
00:00:13,000 --> 00:00:16,699
它可能就是適合國內的這種中文的這種語言模型

1784
00:00:16,699 --> 00:00:19,300
它是不是會對這種小紅書的文案優化

1785
00:00:19,300 --> 00:00:21,399
然後甚至說一些這種商品

1786
00:00:21,399 --> 00:00:24,399
類似現在一些做外貿的商品詳細的優化

1787
00:00:24,399 --> 00:00:28,199
會不會就是說他們的一些應用場景有一些差異化呢

1788
00:00:00,000 --> 00:00:04,799
我在想要不要讲这个

1789
00:00:04,799 --> 00:00:07,799
我来这样通过打比方吧

1790
00:00:07,799 --> 00:00:12,000
就是不会

1791
00:00:12,000 --> 00:00:20,000
因为你找一个聪明高潜的同学干任何事情

1792
00:00:20,000 --> 00:00:24,600
他都会比一个智障干的好

1793
00:00:24,600 --> 00:00:27,800
无论他是做小红书还是做什么东西

1794
00:00:00,000 --> 00:00:03,879
我的观点可能就是说就是在于这种语言

1795
00:00:03,879 --> 00:00:06,320
就是比如说中文和英文这种没有区别

1796
00:00:06,320 --> 00:00:06,960
没有区别是吧

1797
00:00:06,960 --> 00:00:07,480
没有区别

1798
00:00:07,480 --> 00:00:09,640
就是我自己读博士的时候

1799
00:00:09,640 --> 00:00:13,400
我看中国问题是中国人写的文章

1800
00:00:13,400 --> 00:00:14,640
但是都是用英文看的

1801
00:00:15,000 --> 00:00:17,239
就是高学校论文都是用英文发表的

1802
00:00:17,280 --> 00:00:20,800
我的思维方式就是我在我在思考的时候

1803
00:00:20,800 --> 00:00:21,920
我仍然是在用中文思考

1804
00:00:21,920 --> 00:00:23,160
有的时候可能变成了英文思考

1805
00:00:23,160 --> 00:00:25,000
但大多数时间是用中文思考

1806
00:00:25,120 --> 00:00:26,480
可是我读的信息是英文

1807
00:00:27,000 --> 00:00:27,640
就一样的

1808
00:00:00,000 --> 00:00:02,799
就是你想去更好的理解中文

1809
00:00:02,799 --> 00:00:05,960
首先你要去把你的最底層的那個能力激活出來

1810
00:00:05,960 --> 00:00:09,080
就是這個就是你底層能力起來了以後

1811
00:00:09,080 --> 00:00:10,800
翻譯其實是一個簡單的事

1812
00:00:10,800 --> 00:00:12,519
包括文化理解也是一個簡單的事

1813
00:00:12,519 --> 00:00:14,960
我有一次就直接拿這個東西去問GPT

1814
00:00:14,960 --> 00:00:17,359
就是有六個領導

1815
00:00:17,359 --> 00:00:18,640
然後你有七個領導

1816
00:00:18,640 --> 00:00:19,920
你有六支煙怎麼分

1817
00:00:19,920 --> 00:00:22,280
然後第一次問他給的那個問題非常奇怪

1818
00:00:22,280 --> 00:00:23,879
就給的回答又很很那是什麼

1819
00:00:23,879 --> 00:00:24,519
讓地上淺

1820
00:00:24,519 --> 00:00:26,000
我覺得好像有這樣的回答

1821
00:00:26,000 --> 00:00:26,600
對

1822
00:00:26,600 --> 00:00:28,679
但是後來有這樣一個

1823
00:00:28,679 --> 00:00:29,879
就是我自己試的

1824
00:00:00,000 --> 00:00:03,600
就是你是一個中國文化專家

1825
00:00:03,960 --> 00:00:06,320
然後你現在遇到了這樣一個問題

1826
00:00:06,480 --> 00:00:09,119
請你告訴我應該怎麼做

1827
00:00:09,279 --> 00:00:11,640
他給了幾個答案

1828
00:00:11,839 --> 00:00:12,880
就是第一

1829
00:00:12,880 --> 00:00:17,039
你要先把煙給這裡邊資歷最深的領導

1830
00:00:17,640 --> 00:00:18,960
表達你的尊敬

1831
00:00:19,120 --> 00:00:22,199
然後接下來你要按照大家的資歷去一個一個排

1832
00:00:22,320 --> 00:00:23,079
到了第七個

1833
00:00:23,600 --> 00:00:26,800
你去主動提出來和他一起去買一些煙

1834
00:00:26,800 --> 00:00:29,839
在這個時候你既表達了對廠商人的尊敬

1835
00:00:00,000 --> 00:00:03,399
然後你又能有一個和他溝通的好的機會

1836
00:00:04,280 --> 00:00:05,879
我覺得這他媽的情商比我高多了

1837
00:00:05,879 --> 00:00:07,480
就是我是想不到這樣問題的

1838
00:00:07,839 --> 00:00:10,880
就所以說這已經是現在的GPT了

1839
00:00:10,880 --> 00:00:14,720
這是不是意味著就是以後比如說中文

1840
00:00:14,720 --> 00:00:15,919
英語各種各樣的語言

1841
00:00:15,919 --> 00:00:20,399
他們其實就是他們基於語言這個模型就已經統一了

1842
00:00:20,399 --> 00:00:22,079
就像就像人工智能

1843
00:00:22,079 --> 00:00:24,960
他已經發現了語言最下面的那個一致性

1844
00:00:25,679 --> 00:00:27,719
就語言最下面本來就是有一致性的

1845
00:00:27,719 --> 00:00:29,600
你的這樣說話的邏輯是什麼

1846
00:00:00,000 --> 00:00:01,399
你的語言的邏輯是什麼

1847
00:00:01,399 --> 00:00:02,799
然後你英文的邏輯是什麼

1848
00:00:02,839 --> 00:00:06,240
他可能是找到最下面的一層作為語言的一致性

1849
00:00:08,000 --> 00:00:08,839
好問題

1850
00:00:08,839 --> 00:00:10,279
就是語言的一致性

1851
00:00:10,279 --> 00:00:13,119
我猜90%以上可能是一致的

1852
00:00:13,599 --> 00:00:14,080
對吧

1853
00:00:14,560 --> 00:00:17,519
然後然後然後那些不一致的

1854
00:00:17,519 --> 00:00:19,359
我們也可以通過學外語來解決

1855
00:00:19,359 --> 00:00:21,559
其實沒有那麼多不同的

1856
00:00:21,760 --> 00:00:23,079
就是思維方式的

1857
00:00:23,320 --> 00:00:24,719
完全思維方式不同的語言

1858
00:00:24,879 --> 00:00:26,440
如果你說數學是門語言的話

1859
00:00:26,440 --> 00:00:28,719
那可能數學的思維方式是不一樣的

1860
00:00:00,000 --> 00:00:02,000
那你有沒有接觸過數學這個符號

1861
00:00:02,000 --> 00:00:05,000
可能你的思維方式是完全不一樣的對吧

1862
00:00:05,000 --> 00:00:07,799
但是你反正代碼可能又是另外一種語言

1863
00:00:07,799 --> 00:00:10,000
就是你接觸了代碼這個符號以後

1864
00:00:10,000 --> 00:00:11,500
你又帶來了代碼的思維方式

1865
00:00:11,500 --> 00:00:13,699
但GPT都已經學完了

1866
00:00:13,699 --> 00:00:17,500
所以說我覺得就是那個差距對他來說可能不太存在

1867
00:00:17,500 --> 00:00:21,800
他有沒有窮盡語言能帶來的所有知識我覺得遠遠不到

1868
00:00:21,800 --> 00:00:25,500
但是多語言對他來說是不是問題肯定不是問題

1869
00:00:25,500 --> 00:00:27,500
謝謝老師

1870
00:00:00,000 --> 00:00:11,500
我先介绍一下我自己,以及我为什么要问这样的问题。

1871
00:00:11,500 --> 00:00:15,500
我之前也是腾讯的,ShanMagic的,后来我去了阿里。

1872
00:00:15,500 --> 00:00:20,500
然后我做了很多年国内各个high tech的跟渠道的跟业的合作,

1873
00:00:20,500 --> 00:00:22,500
就是把它融合去刷一块电线。

1874
00:00:22,500 --> 00:00:26,000
然后你刚才有提到说你想做调酒师,其实我一点也不惊讶,

1875
00:00:26,000 --> 00:00:29,500
因为我自己也搞了一个服务业,我是7年的身心灵疗愈师,

1876
00:00:00,000 --> 00:00:03,259
然后把国内国外的很多的这个系统都学习了一遍

1877
00:00:03,259 --> 00:00:07,120
我觉得如果AI再发展的话也不可能取代意识和智慧吧

1878
00:00:07,120 --> 00:00:09,279
所以我觉得还挺有意思的

1879
00:00:09,279 --> 00:00:11,759
那我想问的问题就是像比如说

1880
00:00:11,759 --> 00:00:14,439
其实国内包括国外有很多的hack tech

1881
00:00:14,439 --> 00:00:19,640
比如之前有比如指纹制作 生物世界技术 大数据 实验室等等

1882
00:00:19,640 --> 00:00:21,719
其实我也做了很多落地的东西

1883
00:00:21,719 --> 00:00:23,519
有的时候就是眼见它起高楼

1884
00:00:23,519 --> 00:00:25,320
然后眼见它楼落地

1885
00:00:25,320 --> 00:00:26,719
我觉得有两点比较重要

1886
00:00:26,719 --> 00:00:29,079
一个就是技术本身它的精准性

1887
00:00:00,000 --> 00:00:05,400
就是第二个就是是不是有一个够聪明的人把它落地到一个可商业化的东西

1888
00:00:05,400 --> 00:00:11,240
因为我觉得任何事情想要长久的话,最后是归于到商业模式和财务模式上的

1889
00:00:11,240 --> 00:00:15,439
这样才能让这个科技公司更有动力去不断的去挖掘它

1890
00:00:15,439 --> 00:00:20,800
以及在C端用户的话,它是否有足够的感知去参与到其中,产生更大的市场价值

1891
00:00:20,800 --> 00:00:25,519
那其实Chadbow的我关注是,其实我是从商业角度,我完全不懂技术

1892
00:00:25,519 --> 00:00:28,120
但我其实更关注它未来会发展成什么样

1893
00:00:00,000 --> 00:00:10,500
就比如說像馬斯克做的火箭其實很貴,但是馬斯克想如果把火箭回收之後,當成本降低的時候,它就變成了一個普通人可以參與的東西。

1894
00:00:10,500 --> 00:00:23,000
所以我就和一些像跨境的公司的老闆去交流,我們想到一些場景,就比如說它是否能跟電商結合,我更關注的是它是否能成為一個新的私域流量的池子,

1895
00:00:00,000 --> 00:00:03,339
以及這個資源的池子最後會掌握在誰的手裡

1896
00:00:03,339 --> 00:00:05,759
以及用戶的標籤會儲存在哪裡

1897
00:00:05,759 --> 00:00:07,879
它是否會在某一個公司

1898
00:00:07,879 --> 00:00:10,480
還是說只能是在微軟發明就是微軟的

1899
00:00:10,480 --> 00:00:12,119
然後百度發明就是百度的

1900
00:00:12,119 --> 00:00:15,839
其實這一塊就是中間實現形式我沒有太想清楚

1901
00:00:15,839 --> 00:00:17,079
因為我不懂技術

1902
00:00:19,320 --> 00:00:21,079
然後第二個就是我想問一下

1903
00:00:21,079 --> 00:00:22,440
你個人有沒有想過

1904
00:00:22,440 --> 00:00:24,640
比如說除了我剛剛所說的電商產品之外

1905
00:00:24,640 --> 00:00:27,440
你覺得還有哪些可能2B 2C領域的

1906
00:00:00,000 --> 00:00:06,320
最后到呼吸的这种范行业的应用场景有哪些比较有价值的展现形式。

1907
00:00:06,320 --> 00:00:09,480
就比如说像比如说它如果变成了私域流量的话,

1908
00:00:09,480 --> 00:00:11,880
它可能会是一种新的流量变现的渠道,

1909
00:00:11,880 --> 00:00:13,560
因为我最近几年在做流量变现,

1910
00:00:13,560 --> 00:00:18,399
那实际上传统的SEO形式的这种或者竞价付费买量其实已经很off了,

1911
00:00:18,399 --> 00:00:19,800
而且成本非常非常的高,

1912
00:00:19,800 --> 00:00:23,839
所以现在很多人不论是大企业还是小企业还是客户人都在做私域流量,

1913
00:00:23,839 --> 00:00:27,760
那比较传统的方式就是你搞一个社群运营,

1914
00:00:00,000 --> 00:00:02,720
但其实是很耗费人力成本的

1915
00:00:02,720 --> 00:00:03,799
所以我又想到说

1916
00:00:03,799 --> 00:00:07,440
那拆透的试图可以代替这种比较好的人工客服

1917
00:00:07,440 --> 00:00:09,640
来取代这个传统的人工客服

1918
00:00:09,640 --> 00:00:11,720
而不仅仅单纯的是说你好

1919
00:00:11,720 --> 00:00:14,119
你要什么一些定制化的QA的回答

1920
00:00:14,119 --> 00:00:17,960
它会变成一个比较高智商的一个高级的一个客服的一个质量

1921
00:00:17,960 --> 00:00:20,719
来替代这种低质廉价的人工

1922
00:00:20,719 --> 00:00:22,519
我觉得这几个观众问题

1923
00:00:22,519 --> 00:00:23,480
我听懂了

1924
00:00:23,480 --> 00:00:28,160
然后本来你的后面那个问题我是想说我不是很关注

1925
00:00:00,000 --> 00:00:02,560
結果後來發現你問到了我的工作本身

1926
00:00:02,560 --> 00:00:04,320
我就不能說我不是很關注了

1927
00:00:04,320 --> 00:00:06,320
對我自己是做增長的嘛

1928
00:00:06,320 --> 00:00:07,879
我是給這是AEG的讀書會

1929
00:00:07,879 --> 00:00:10,400
我是給各位AEG的爸爸們做增長的

1930
00:00:10,400 --> 00:00:11,000
然後

1931
00:00:12,839 --> 00:00:15,279
我是覺得它在現有的情況下

1932
00:00:15,279 --> 00:00:16,960
包括你說的那個思域的運營

1933
00:00:16,960 --> 00:00:18,280
它會是很重要的點

1934
00:00:18,320 --> 00:00:22,120
因為我們過去的流量變成遊戲玩家

1935
00:00:22,120 --> 00:00:22,399
對吧

1936
00:00:22,399 --> 00:00:24,359
你看到了一個市面上任何一個

1937
00:00:25,120 --> 00:00:26,600
你可以坐下不用站

1938
00:00:26,640 --> 00:00:28,480
對就是我們看到任何一個流量

1939
00:00:00,000 --> 00:00:02,000
我们想把它变成一个你的客户

1940
00:00:02,000 --> 00:00:05,599
确实是主要是通过推荐和转化的逻辑

1941
00:00:05,599 --> 00:00:09,599
我觉得XGPT可以让这件事情变成一个销售的逻辑

1942
00:00:09,599 --> 00:00:10,800
就是你不是给它看一遍

1943
00:00:10,800 --> 00:00:12,599
而是有一个更好的

1944
00:00:12,599 --> 00:00:14,199
不管是通过对话吧

1945
00:00:14,199 --> 00:00:15,400
还是通过理解

1946
00:00:15,400 --> 00:00:20,199
总之它会有一个更销售向的去提高转化率的方式

1947
00:00:20,199 --> 00:00:22,600
以及它的这个所谓的社群运营

1948
00:00:22,600 --> 00:00:24,399
就是它未必是现在的一个形式

1949
00:00:24,399 --> 00:00:28,000
但是我们想知道这个老游戏它的那个

1950
00:00:00,000 --> 00:00:03,680
很多活跃都是来自于你可能产生了一些内容事件

1951
00:00:03,680 --> 00:00:04,599
或者各种事件

1952
00:00:04,599 --> 00:00:05,759
然后就来了很多

1953
00:00:05,759 --> 00:00:07,799
就是乡村派对等等

1954
00:00:07,799 --> 00:00:09,080
就都有这样的例子

1955
00:00:09,080 --> 00:00:12,720
在过去我们人是没有办法控制这些东西的

1956
00:00:12,720 --> 00:00:14,480
因为我没有那个内容生产能力

1957
00:00:14,480 --> 00:00:19,440
或者说是去理解发生所有事情的这些这样的方法

1958
00:00:19,440 --> 00:00:20,640
但是现在可能有了

1959
00:00:20,640 --> 00:00:23,359
它可能就是一个比较大的增长机会

1960
00:00:23,359 --> 00:00:27,199
但是你如果你的问题是落在今天的Chai GPT

1961
00:00:27,199 --> 00:00:29,839
怎么样子用在我今天的业务场景下

1962
00:00:00,000 --> 00:00:03,200
怎麼樣子快速的落地和快速的幫我賺錢

1963
00:00:03,200 --> 00:00:04,280
我沒有答案

1964
00:00:04,280 --> 00:00:07,000
這個我覺得創業者們會去figure out的

1965
00:00:07,000 --> 00:00:09,839
就是我也聽說很多創業者在做這樣的東西

1966
00:00:09,839 --> 00:00:12,320
比如說你的那個視頻

1967
00:00:12,320 --> 00:00:15,679
你電視上的那些視頻怎麼樣子把它做得更好一點

1968
00:00:15,679 --> 00:00:17,480
對我沒有答案

1969
00:00:17,480 --> 00:00:20,079
我也不打算照這個方向想

1970
00:00:20,079 --> 00:00:22,800
就是回到這個的第二個延伸

1971
00:00:22,800 --> 00:00:26,600
就是我覺得現有的場景用XJPG去做增效

1972
00:00:26,600 --> 00:00:29,440
是30%到300%的機會了不起了

1973
00:00:00,000 --> 00:00:03,319
但是真正的我說那個長期影響

1974
00:00:03,319 --> 00:00:04,679
就是那個大的長期影響

1975
00:00:04,679 --> 00:00:06,759
那個3000%到30,000%的東西

1976
00:00:06,759 --> 00:00:09,320
是在現有根本就沒有解決的問題裡面的

1977
00:00:09,320 --> 00:00:12,439
請問現在技術接口是怎麼開通的嗎?

1978
00:00:12,439 --> 00:00:14,400
好,剛剛還有第二個問題

1979
00:00:14,400 --> 00:00:15,679
就是它是怎麼開通的

1980
00:00:15,679 --> 00:00:17,039
數據是怎麼儲存的

1981
00:00:17,039 --> 00:00:20,160
我覺得這個我還想多聊一下這一點

1982
00:00:20,160 --> 00:00:22,559
就是Chairpt是OpenAI做的

1983
00:00:22,559 --> 00:00:24,120
不是微軟做的

1984
00:00:24,120 --> 00:00:25,519
然後OpenAI

1985
00:00:25,519 --> 00:00:28,280
就微軟是OpenAI的一個很重要的投資人

1986
00:00:00,000 --> 00:00:02,040
但是他們這個投資的方式

1987
00:00:02,040 --> 00:00:04,540
其實和市面上存在的

1988
00:00:04,540 --> 00:00:06,839
投資方式都很不一樣

1989
00:00:06,839 --> 00:00:08,140
OpenAI的組織架構

1990
00:00:08,140 --> 00:00:09,519
是它有一個非盈利的架構

1991
00:00:09,519 --> 00:00:10,779
然後這個非盈利的架構

1992
00:00:10,779 --> 00:00:12,619
控制一個盈利的架構

1993
00:00:12,619 --> 00:00:13,679
但是這個盈利的架構

1994
00:00:13,679 --> 00:00:15,720
它的這個盈利是有上限的

1995
00:00:15,720 --> 00:00:18,320
它叫一個capitalism

1996
00:00:18,320 --> 00:00:21,019
就是它是一個有上限的資本主義

1997
00:00:21,019 --> 00:00:23,399
所以說這個盈利的架構

1998
00:00:23,399 --> 00:00:25,500
賺夠錢了以後

1999
00:00:25,500 --> 00:00:28,600
它就所有東西都回歸到這個非盈利

2000
00:00:00,000 --> 00:00:02,200
並且這個非盈利對這個盈利的決定

2001
00:00:02,200 --> 00:00:04,400
就是日常經營的決策權

2002
00:00:04,400 --> 00:00:05,960
是有絕對決策權的

2003
00:00:05,960 --> 00:00:08,500
微軟投的和其他投資人投的是這個

2004
00:00:08,500 --> 00:00:10,140
CAPT盈利機構

2005
00:00:10,140 --> 00:00:11,339
它是有上限的

2006
00:00:11,339 --> 00:00:14,179
所以微軟在這裡邊它有很多這個

2007
00:00:14,179 --> 00:00:15,439
收益權

2008
00:00:15,439 --> 00:00:18,019
但是第一它不能控制你到底做什麼

2009
00:00:18,019 --> 00:00:19,839
第二它的收益有上限

2010
00:00:19,839 --> 00:00:21,640
在這個架構之下

2011
00:00:21,640 --> 00:00:24,679
就是我覺得它費了這麼大的心思

2012
00:00:24,679 --> 00:00:26,179
去設置這個架構

2013
00:00:26,179 --> 00:00:27,260
如果它不設置這個架構

2014
00:00:27,260 --> 00:00:28,559
它今天融資會比今天

2015
00:00:00,000 --> 00:00:02,339
它歷史就GPT出了以後

2016
00:00:02,339 --> 00:00:04,339
所有人都想給它掏錢了

2017
00:00:04,339 --> 00:00:05,719
但是在GPT出之前

2018
00:00:05,719 --> 00:00:07,059
他們融資是很艱難的

2019
00:00:07,059 --> 00:00:08,640
就是因為一個很重要的原因

2020
00:00:08,640 --> 00:00:10,099
就是因為這個組織架構

2021
00:00:10,099 --> 00:00:11,480
所以說他們費了這麼大心思

2022
00:00:11,480 --> 00:00:13,679
去搞了一個這麼處理不討好的組織架構

2023
00:00:13,679 --> 00:00:16,359
我還是相信他們的很多這種

2024
00:00:16,359 --> 00:00:19,019
為了全人類的這種願景吧

2025
00:00:19,019 --> 00:00:20,559
這是一就是我覺得他們動機

2026
00:00:20,559 --> 00:00:22,059
展現出來的是好的

2027
00:00:22,059 --> 00:00:24,019
第二就是具體怎麼開放

2028
00:00:24,019 --> 00:00:27,039
今天我們如果去看那個GPT API的

2029
00:00:27,039 --> 00:00:28,859
這個Turbo Agreement就發現

2030
00:00:00,000 --> 00:00:02,359
它其實對數據的使用是很嚴格的

2031
00:00:02,359 --> 00:00:04,639
就是它沒有要去讀你那麼多東西

2032
00:00:04,639 --> 00:00:09,439
它嚴格的保證了它的數據是用在去改進產品體驗上

2033
00:00:09,439 --> 00:00:11,720
而不是去為那個模型上

2034
00:00:11,720 --> 00:00:14,720
以及我猜未來第一

2035
00:00:14,720 --> 00:00:16,320
它有沒有可能私有化部署不知道

2036
00:00:16,320 --> 00:00:20,120
但是它應該可以有一個更容易的尊重隱私

2037
00:00:20,120 --> 00:00:24,120
就讓你的數據更有安全感的這樣一個措施

2038
00:00:24,120 --> 00:00:27,879
第二我自己還覺得GPT的數據使用方式

2039
00:00:00,000 --> 00:00:03,000
你應該可以跟GPT約定一個加密算法

2040
00:00:03,000 --> 00:00:05,700
然後通過這個加密算法的方式回傳過去

2041
00:00:05,700 --> 00:00:07,700
然後他自己不需要去

2042
00:00:07,700 --> 00:00:10,500
像人類那樣去理解他給你算出來

2043
00:00:10,500 --> 00:00:13,000
然後其中是保證你數據是安全的

2044
00:00:13,000 --> 00:00:15,500
就是我覺得數據安全不是一個很重要的問題

2045
00:00:15,500 --> 00:00:18,000
因為第一他們是好人

2046
00:00:18,000 --> 00:00:20,500
第二這個東西是可以被解決的

2047
00:00:20,500 --> 00:00:22,500
中國政府在意這個問題啊

2048
00:00:22,500 --> 00:00:24,500
我又 這我

2049
00:00:24,500 --> 00:00:26,500
能說什麼呢

2050
00:00:26,500 --> 00:00:28,500
中國政府還在意

2051
00:00:00,000 --> 00:00:04,000
所以算了,很多問題,我也沒辦法

2052
00:00:00,000 --> 00:00:03,500
人类是有自由的意志,是有自己的思维

2053
00:00:03,500 --> 00:00:07,500
然后他从古希腊的这种哲学到后面的数学

2054
00:00:07,500 --> 00:00:10,500
到后面的整个科学技术的发展

2055
00:00:10,500 --> 00:00:13,500
那其实在我的认识当中

2056
00:00:13,500 --> 00:00:16,500
就是说一个非常智能的机器人也罢

2057
00:00:16,500 --> 00:00:19,000
或者说我们这种AI也罢

2058
00:00:19,000 --> 00:00:21,500
它能够模仿人的这种思维

2059
00:00:21,500 --> 00:00:23,500
那我的问题就是说

2060
00:00:23,500 --> 00:00:27,500
在过往的研究经历当中

2061
00:00:00,000 --> 00:00:05,500
目前的研究案例中,相關的科學家有沒有做過類似的,

2062
00:00:05,500 --> 00:00:14,000
能夠在數學領域,能夠讓CVT,或者大圓模型,

2063
00:00:14,000 --> 00:00:20,000
能夠做一些具有創造性的類似於數學,

2064
00:00:00,000 --> 00:00:08,500
或者這種的 就是說這種發明或者說定理的推導 公式的推導等等

2065
00:00:08,500 --> 00:00:15,099
就是說有沒有這種類似的 就是說能夠顛覆 能夠跟人類這種思維一樣的這種

2066
00:00:15,099 --> 00:00:21,100
能夠顛覆這種人類文明的這種功力的推導 有沒有過這種的

2067
00:00:21,100 --> 00:00:28,500
好問題 沒有 因為這個對人都是很稀有的技能

2068
00:00:00,000 --> 00:00:02,660
但是他有沒有創作

2069
00:00:02,660 --> 00:00:03,779
就是你問了兩個問題

2070
00:00:03,779 --> 00:00:06,780
就是第一個是有沒有讓他去做有創造力的工作

2071
00:00:06,780 --> 00:00:09,419
我們現在看到了很多AIGC的畫

2072
00:00:09,419 --> 00:00:11,699
那都不是什麼新的東西

2073
00:00:11,699 --> 00:00:12,859
但是大家都覺得

2074
00:00:12,859 --> 00:00:14,259
這好像是挺有創造力的

2075
00:00:14,259 --> 00:00:14,820
沒見過

2076
00:00:14,820 --> 00:00:16,059
然後畫得挺好的

2077
00:00:16,059 --> 00:00:17,699
所以說創造力這個詞

2078
00:00:17,699 --> 00:00:19,500
我覺得也挺難定義的

2079
00:00:19,500 --> 00:00:22,980
就是我們應該日常的很多創意型的工作

2080
00:00:22,980 --> 00:00:25,500
大多數都只是智力的搬磚而已

2081
00:00:25,500 --> 00:00:27,699
我們沒有真的去創造任何東西

2082
00:00:27,699 --> 00:00:28,219
對

2083
00:00:00,000 --> 00:00:01,679
所以說這方面的工作

2084
00:00:01,679 --> 00:00:03,399
XGPT能做得很好

2085
00:00:03,399 --> 00:00:07,120
包括陶哲軒他是重度XGPT使用者

2086
00:00:07,120 --> 00:00:09,160
然後他發了好幾個推特

2087
00:00:09,160 --> 00:00:11,919
就說XGPT是怎麼樣子

2088
00:00:11,919 --> 00:00:15,279
怎麼樣子讓我在這種非常理論

2089
00:00:15,279 --> 00:00:17,280
非常高級的數學的工作中

2090
00:00:17,280 --> 00:00:19,480
得到切切實實的增效的

2091
00:00:19,480 --> 00:00:22,519
就是包括XGPT給他提供的很多理論

2092
00:00:22,519 --> 00:00:26,320
他覺得這個推導的過程雖然是錯的

2093
00:00:26,320 --> 00:00:27,800
但是給了他很多靈感

2094
00:00:27,800 --> 00:00:29,120
也給了他很多思路

2095
00:00:00,000 --> 00:00:02,560
而且記得這是個Demo

2096
00:00:02,560 --> 00:00:04,799
有沒有辦法讓數位家具去把它訓練得更好

2097
00:00:04,799 --> 00:00:05,480
讓它變得更好用

2098
00:00:05,480 --> 00:00:07,799
我覺得是肯定會比今天做得好

2099
00:00:07,799 --> 00:00:09,119
能做得多好我不知道

2100
00:00:09,119 --> 00:00:11,039
但是另外一個就是我為什麼說不能呢

2101
00:00:11,039 --> 00:00:14,119
就是這是我其實仔細想的一件事

2102
00:00:14,119 --> 00:00:16,359
就是Eureka這個詞

2103
00:00:16,359 --> 00:00:18,600
就是埃及米德在發明伏利定律的時候

2104
00:00:18,600 --> 00:00:21,399
他就我發現了是吧跳出浴缸

2105
00:00:21,399 --> 00:00:25,239
他這個詞就是他當時說的就是這個Eureka

2106
00:00:25,239 --> 00:00:27,239
Eureka其實有兩個步驟

2107
00:00:27,239 --> 00:00:29,359
第一個步驟就是他發現了一個

2108
00:00:00,000 --> 00:00:01,700
人類都沒有發現過的東西

2109
00:00:02,279 --> 00:00:05,259
就是世界上所有的人都

2110
00:00:05,280 --> 00:00:08,619
之前都不是所有人都在想

2111
00:00:08,640 --> 00:00:10,820
但是總之世界上之前所有的人

2112
00:00:10,839 --> 00:00:12,099
都沒有想到那個弗利定律

2113
00:00:12,119 --> 00:00:14,300
說明它是一個離現有人類知識

2114
00:00:14,320 --> 00:00:15,380
非常遠的一個東西

2115
00:00:15,400 --> 00:00:16,420
很難想到對吧

2116
00:00:16,440 --> 00:00:17,620
但是他想到了

2117
00:00:17,839 --> 00:00:19,460
第二個是他馬上發現了

2118
00:00:19,480 --> 00:00:20,940
這件事情是多麼重要

2119
00:00:21,679 --> 00:00:23,140
他想到的瞬間他就知道了

2120
00:00:23,160 --> 00:00:24,500
這是一個非常重要的事情

2121
00:00:24,839 --> 00:00:26,160
我覺得Tragedy

2122
00:00:26,239 --> 00:00:29,239
以他不斷的去蹦下一個詞的機制

2123
00:00:00,000 --> 00:00:01,879
他应该是很难做到第一点的

2124
00:00:02,080 --> 00:00:04,320
但是他有没有可能做到第一点我不知道

2125
00:00:04,400 --> 00:00:06,879
可是他应该超级难做到第二点

2126
00:00:06,879 --> 00:00:10,359
因为他没有办法判断什么东西是对人有用的

2127
00:00:10,359 --> 00:00:12,720
他需要人去告诉他什么东西对人有用

2128
00:00:13,400 --> 00:00:17,039
所以就是就是为什么我觉得他能不能取代我

2129
00:00:17,039 --> 00:00:18,000
我觉得很有可能

2130
00:00:18,000 --> 00:00:19,719
但是能不能取代牛顿我觉得不太可能

2131
00:00:20,399 --> 00:00:23,120
那那我接下来就是还有一个问题

2132
00:00:23,120 --> 00:00:27,039
就是刚才讲讲到我们CATCPD现在是一个demo

2133
00:00:27,120 --> 00:00:28,920
那刚才也有好多同学的话

2134
00:00:00,000 --> 00:00:02,000
讲到就是说它的一个商业化

2135
00:00:02,000 --> 00:00:03,000
然后呢

2136
00:00:03,000 --> 00:00:05,000
其实我不太想

2137
00:00:05,000 --> 00:00:08,000
就是说讨论就是说它具体的一个商业化的应用模式

2138
00:00:08,000 --> 00:00:13,000
但是我想请教他就是说他以后的一个未来的一个发展

2139
00:00:13,000 --> 00:00:14,000
发展形态

2140
00:00:14,000 --> 00:00:16,000
他可能就是说应用在不同的领域

2141
00:00:16,000 --> 00:00:17,000
比如说举个例子

2142
00:00:17,000 --> 00:00:18,000
这种客服呀

2143
00:00:18,000 --> 00:00:19,000
或者怎样子

2144
00:00:19,000 --> 00:00:21,000
就是说非常智能的一个客服

2145
00:00:21,000 --> 00:00:25,000
它是第一个是应用在某个领域

2146
00:00:25,000 --> 00:00:28,000
或者说它可能会应用在

2147
00:00:00,000 --> 00:00:03,000
對某個人這種非常個性化的

2148
00:00:03,000 --> 00:00:05,000
包括您剛才講到的就是說

2149
00:00:05,000 --> 00:00:07,000
您那個就是說要去調酒

2150
00:00:07,000 --> 00:00:10,000
那當這個AI機器人來幫著教育小孩

2151
00:00:10,000 --> 00:00:12,000
那好了那這個AI機器人

2152
00:00:12,000 --> 00:00:13,000
他說的不是我說的

2153
00:00:13,000 --> 00:00:14,000
我沒有幹這種事情啊

2154
00:00:14,000 --> 00:00:16,000
這個我們知道重要的是

2155
00:00:16,000 --> 00:00:18,000
就是說這個AI機器人

2156
00:00:18,000 --> 00:00:19,000
他是屬於那個

2157
00:00:19,000 --> 00:00:21,000
他應該是屬於一個個人

2158
00:00:21,000 --> 00:00:22,000
對吧personal的

2159
00:00:22,000 --> 00:00:23,000
不是說一個就是說

2160
00:00:23,000 --> 00:00:26,000
他的思維已經就是說

2161
00:00:26,000 --> 00:00:29,000
是屬於或者說這個機器人

2162
00:00:00,000 --> 00:00:02,200
它是屬於一個個人的產品了對吧

2163
00:00:02,200 --> 00:00:05,400
不是不是不是

2164
00:00:05,400 --> 00:00:07,900
應該絕大多數的機器人還是一個託用的

2165
00:00:07,900 --> 00:00:10,900
就是可能GPT我們會發現它已經能解決絕大多數問題了

2166
00:00:10,900 --> 00:00:13,000
你不需要一個個人的東西來繼續

2167
00:00:13,000 --> 00:00:14,900
站在之上去幫你解決什麼問題

2168
00:00:14,900 --> 00:00:17,000
就比如說我今天想編程是吧

2169
00:00:17,000 --> 00:00:19,600
GPT-4或者說它再改進一下

2170
00:00:19,600 --> 00:00:21,600
它可能出了一個編程版

2171
00:00:21,600 --> 00:00:23,399
就是它編程能力更強了

2172
00:00:23,399 --> 00:00:25,000
那它就可以幫我編程了

2173
00:00:25,000 --> 00:00:27,199
跟我沒有任何關係

2174
00:00:27,199 --> 00:00:29,800
OK那這樣表態下去的話

2175
00:00:00,000 --> 00:00:03,200
您的意思就是说他OpenAI或者说文青一眼

2176
00:00:03,200 --> 00:00:05,719
他只是他在以后的一个发展过程中

2177
00:00:05,719 --> 00:00:11,119
他只能就是说是一个这种比较common的一个东西

2178
00:00:11,119 --> 00:00:12,720
就不会进行一个个性化

2179
00:00:12,720 --> 00:00:15,720
比如说他就是一个全能的专家

2180
00:00:15,720 --> 00:00:20,239
或者就是说一个比较在会分层不同领域的这种专家

2181
00:00:20,239 --> 00:00:21,559
您的意思是这样的吗

2182
00:00:21,719 --> 00:00:23,920
我这只能都是猜想

2183
00:00:23,920 --> 00:00:26,679
就是真正的是看他们怎么去开放

2184
00:00:26,679 --> 00:00:28,359
我的猜想就是第一

2185
00:00:00,000 --> 00:00:02,240
它的通用型可以解決絕大多數的問題

2186
00:00:02,240 --> 00:00:03,759
就好像這個鋼鐵俠的盔甲

2187
00:00:03,759 --> 00:00:07,240
他一個人已經可以打敗世界上所有的壞人了

2188
00:00:07,240 --> 00:00:10,000
他不需要在這職場上去做什麼東西

2189
00:00:10,000 --> 00:00:13,240
但是你看這裡邊就是他們每個用不同的那個鎧甲對吧

2190
00:00:13,240 --> 00:00:14,759
他有專精的東西

2191
00:00:14,759 --> 00:00:19,399
舉個例子就是通用型的GPT可能在醫療這件事情上

2192
00:00:19,399 --> 00:00:21,320
他做得不夠好

2193
00:00:21,320 --> 00:00:23,160
我們需要他做得更好

2194
00:00:23,160 --> 00:00:25,640
那他可能就要去多讀這方面的文獻

2195
00:00:25,640 --> 00:00:27,800
然後他甚至在那個

2196
00:00:27,800 --> 00:00:29,399
就是人類給他feedback的時候

2197
00:00:00,000 --> 00:00:02,399
他多用这方面的数据去给他feedback

2198
00:00:02,680 --> 00:00:05,559
那他可能就是一个专精医疗专家GPT

2199
00:00:05,559 --> 00:00:07,000
他有医疗方面的知识

2200
00:00:07,040 --> 00:00:09,839
以及这些知识里边所提炼出来的一些能力

2201
00:00:10,279 --> 00:00:13,320
他可能是这个是专业的GPT

2202
00:00:13,679 --> 00:00:15,839
那在那之上就有一些非共识的东西

2203
00:00:16,199 --> 00:00:17,800
比如说今天一个营销方案

2204
00:00:18,199 --> 00:00:19,760
基本的质量我们是可以有的

2205
00:00:19,760 --> 00:00:21,760
但是谁的营销方案到底更有用

2206
00:00:21,760 --> 00:00:23,199
那其实不一样

2207
00:00:23,199 --> 00:00:25,760
就是我们看到最牛逼的一些广告专家们

2208
00:00:26,079 --> 00:00:29,039
就是他们出的那些东西不是一个共识的东西

2209
00:00:00,000 --> 00:00:02,000
很多人都會覺得 哇 你這出了個什麼鬼

2210
00:00:02,000 --> 00:00:03,500
結果發現效果就很好

2211
00:00:03,500 --> 00:00:07,500
那這個東西我覺得也不太可能存在於人類現有知識裡面

2212
00:00:07,500 --> 00:00:09,000
因為它完全是個非共識

2213
00:00:09,000 --> 00:00:11,000
你也不可能通過邏輯去推導出來

2214
00:00:11,000 --> 00:00:15,500
那這個東西可能是那個定制的那一派

2215
00:00:15,500 --> 00:00:20,000
這個定制的話 那就是會出現各種比如說不同的公司

2216
00:00:20,000 --> 00:00:23,500
它會就是說再採到了就是說

2217
00:00:23,500 --> 00:00:25,500
像JPT或者說文信業之後

2218
00:00:25,500 --> 00:00:27,000
它再去自己去訓練

2219
00:00:00,000 --> 00:00:02,000
然後屬於自己的那個模型

2220
00:00:02,000 --> 00:00:05,500
或者說屬於自己的產品是會有這種

2221
00:00:05,500 --> 00:00:07,000
我不知道它會怎麼樣

2222
00:00:07,000 --> 00:00:10,000
但是我覺得合理的方式仍然是

2223
00:00:10,000 --> 00:00:14,000
就是我做一下未來的推斷吧

2224
00:00:14,000 --> 00:00:17,500
但是這個推斷是基於一些我也不確定的事情

2225
00:00:17,500 --> 00:00:20,000
比如說它這個模型門檻有多高

2226
00:00:20,000 --> 00:00:21,500
它能不能被快速複製

2227
00:00:21,500 --> 00:00:24,000
假設它的模型就SAM自己的推斷呢

2228
00:00:24,000 --> 00:00:26,000
就是兩三年之後

2229
00:00:26,000 --> 00:00:28,000
是讓出來幾百個大模型

2230
00:00:28,000 --> 00:00:29,000
不同的大模型

2231
00:00:00,000 --> 00:00:02,560
就是那个OpenAI的CEO

2232
00:00:02,560 --> 00:00:05,679
他访谈里面说的是以后会有很多个大模型

2233
00:00:05,679 --> 00:00:07,679
那些每个大模型它的能力是不一样的

2234
00:00:07,679 --> 00:00:08,640
适配的东西不一样

2235
00:00:08,640 --> 00:00:09,519
专心的是不一样的

2236
00:00:09,519 --> 00:00:12,199
所以说就是像你说的那种情况

2237
00:00:12,199 --> 00:00:16,839
我自己推断是世界上可能未来重要的只有OpenAI一家

2238
00:00:16,839 --> 00:00:19,320
然后重要的只有GPT一个模型

2239
00:00:19,320 --> 00:00:20,760
然后这个GPT的模型

2240
00:00:20,760 --> 00:00:22,199
你不是去给他

2241
00:00:22,199 --> 00:00:25,079
他可能会把这个feedback这一步开放给大家

2242
00:00:25,079 --> 00:00:29,000
然后你在feedback这一步去把你的知识和你的

2243
00:00:00,000 --> 00:00:02,200
一些想要的東西反饋給他

2244
00:00:02,200 --> 00:00:03,960
然後去適配你的工作

2245
00:00:04,440 --> 00:00:05,719
然後的話那我就

2246
00:00:05,960 --> 00:00:06,960
之後可能這樣子的話

2247
00:00:06,960 --> 00:00:08,919
我可能就表達一下我自己的擔憂

2248
00:00:08,919 --> 00:00:10,560
我覺得科技的話是

2249
00:00:10,759 --> 00:00:12,880
給大家更好的一個生活

2250
00:00:13,039 --> 00:00:14,720
如果說這種如果

2251
00:00:15,000 --> 00:00:17,039
只是一個比較共同的模型的話

2252
00:00:17,039 --> 00:00:18,320
那對於我來講的話

2253
00:00:18,320 --> 00:00:19,480
我可能不會跟他

2254
00:00:19,719 --> 00:00:22,039
講我心裡的一些比較

2255
00:00:22,280 --> 00:00:24,679
嗯比較個人隱私的一些東西

2256
00:00:24,679 --> 00:00:25,600
你今天有沒有

2257
00:00:25,879 --> 00:00:28,480
你今天有沒有用微信去講你的個人隱私

2258
00:00:00,000 --> 00:00:04,540
我不會講特別的那種的意思

2259
00:00:04,540 --> 00:00:09,939
就是涉及到一些宗教政治或者說自己人類內心的一些東西

2260
00:00:09,939 --> 00:00:12,419
那其實我想再說每個人如果是這樣子的話

2261
00:00:12,419 --> 00:00:14,339
每個人可能都會對它有所保留

2262
00:00:14,339 --> 00:00:16,300
那我的意思就是說

2263
00:00:16,300 --> 00:00:18,579
你內心那塊東西可能完全不拿出來

2264
00:00:18,579 --> 00:00:22,219
但是你可能對科技的接受程度超過了你的想像

2265
00:00:22,219 --> 00:00:24,460
蘋果是一家壟斷公司

2266
00:00:24,460 --> 00:00:26,260
微信是一個壟斷APP

2267
00:00:26,260 --> 00:00:27,100
不能說這句話

2268
00:00:27,100 --> 00:00:28,460
微信是一個好用的

2269
00:00:00,000 --> 00:00:02,000
大家都去主動使用他的

2270
00:00:02,960 --> 00:00:06,080
我們很多這種事情都是在這種地方發生的

2271
00:00:06,080 --> 00:00:08,759
所以說壟斷這件事我不覺得對人真的有那麼重要

2272
00:00:09,359 --> 00:00:10,599
比如說那個

2273
00:00:10,599 --> 00:00:12,320
他作為一個大語言模型

2274
00:00:12,320 --> 00:00:15,199
就是說現在那個就是說需要更多的這種

2275
00:00:15,679 --> 00:00:16,600
什麼

2276
00:00:17,239 --> 00:00:18,519
就是說提詞工程師

2277
00:00:18,559 --> 00:00:21,480
然後其實就是說如果說每個人就是說會給他

2278
00:00:21,679 --> 00:00:23,760
更多的這種私有化這種問題的話

2279
00:00:23,760 --> 00:00:26,879
其實對他這個語言模型的訓練對他自己也是有

2280
00:00:26,879 --> 00:00:28,120
他不用他不用

2281
00:00:00,000 --> 00:00:02,879
它不用你去跟它對話的東西去訓練那個模型

2282
00:00:03,759 --> 00:00:06,839
它只用這些東西去改進你的使用體驗

2283
00:00:07,320 --> 00:00:11,960
它的那個背後所GPT-4所調教出來的能力

2284
00:00:12,240 --> 00:00:15,720
其實是基於人類積累的高質量信息

2285
00:00:15,919 --> 00:00:16,960
你現在去跟它說一堆話

2286
00:00:16,960 --> 00:00:18,359
它不覺得這是高質量信息

2287
00:00:20,239 --> 00:00:23,359
這是大模型和那個

2288
00:00:23,359 --> 00:00:24,719
就是這種類型的大模型

2289
00:00:24,719 --> 00:00:26,280
和過去模型的一個很重要的區別

2290
00:00:26,280 --> 00:00:28,519
就是過去的模型會非常注重

2291
00:00:00,000 --> 00:00:01,800
你跟他对话的这个点

2292
00:00:01,800 --> 00:00:05,360
因为他需要不断的去专精这个模型是吧

2293
00:00:05,360 --> 00:00:07,799
更好的去适配你和他的对话

2294
00:00:07,799 --> 00:00:11,640
你和他的对话才是这里边最真实的那个使用场景

2295
00:00:11,640 --> 00:00:14,759
所以说他必须要拿你的对话数据去训练这个模型

2296
00:00:14,759 --> 00:00:16,359
才能把这个模型做得更好

2297
00:00:16,359 --> 00:00:19,440
但大模型是首先他要通过高质量数据

2298
00:00:19,440 --> 00:00:21,039
把这个能力给体验出来

2299
00:00:21,039 --> 00:00:24,839
然后再通过反馈去和你的喜好对齐

2300
00:00:24,839 --> 00:00:27,359
所以说他最多最多也就是到反馈这一步

2301
00:00:27,359 --> 00:00:29,160
他没有必要到顶上那一步

2302
00:00:00,000 --> 00:00:00,560
好的

2303
00:00:00,560 --> 00:00:00,840
谢谢

2304
00:00:08,359 --> 00:00:09,640
苏老师你好

2305
00:00:09,640 --> 00:00:11,439
我本身是你的一个粉丝

2306
00:00:11,439 --> 00:00:11,880
看了你的节目

2307
00:00:11,880 --> 00:00:12,720
谢谢

2308
00:00:12,720 --> 00:00:13,199
对

2309
00:00:13,199 --> 00:00:14,800
然后我的问题还比较多

2310
00:00:14,800 --> 00:00:17,839
然后第一个是刚才说到这个垄断的问题

2311
00:00:17,839 --> 00:00:19,679
然后我其实有点疑惑

2312
00:00:19,679 --> 00:00:21,239
因为这也是我第一个想问的问题

2313
00:00:21,239 --> 00:00:24,519
就是所谓现在说的我们的定义中的垄断

2314
00:00:24,519 --> 00:00:25,800
应该是指商业垄断

2315
00:00:25,800 --> 00:00:26,239
对吧

2316
00:00:27,760 --> 00:00:29,480
他只有这一家可以做出来

2317
00:00:00,000 --> 00:00:01,919
我觉得就是技术垄断你也可以这么说

2318
00:00:01,919 --> 00:00:03,200
对对对技术垄断也OK

2319
00:00:03,439 --> 00:00:07,320
但我不太担心所谓的商业垄断或者技术垄断

2320
00:00:07,320 --> 00:00:08,279
这一点跟您说的一样

2321
00:00:08,279 --> 00:00:11,400
但我担心的如果它是一个意识垄断

2322
00:00:11,400 --> 00:00:13,039
或者是一个信息垄断

2323
00:00:13,160 --> 00:00:16,960
我们怎么作为普通人怎么来判断大公司是否作恶

2324
00:00:17,000 --> 00:00:21,640
或者传达给我们的比如说意识形态是不是是正确的

2325
00:00:22,920 --> 00:00:24,280
你今天能判断吗

2326
00:00:25,000 --> 00:00:27,280
就是我在那个文章里边有一个截图

2327
00:00:00,000 --> 00:00:05,259
就是說一個某中國專家說評價股市的東西

2328
00:00:05,259 --> 00:00:07,099
然後我們去問Chai GPT

2329
00:00:07,099 --> 00:00:08,839
他這樣說是不是在偷換概念

2330
00:00:08,839 --> 00:00:09,880
然後Chai GPT說對

2331
00:00:09,880 --> 00:00:11,339
他只是偷換概念一二三

2332
00:00:11,339 --> 00:00:14,539
就是我們今天的輿論已經被污染到了一個

2333
00:00:14,539 --> 00:00:15,919
就是為什麼你會care

2334
00:00:15,919 --> 00:00:17,920
一個工具是否

2335
00:00:17,920 --> 00:00:20,219
就是這個工具會讓這件事情惡化嗎

2336
00:00:20,219 --> 00:00:23,019
我覺得它反而會把很多理性給帶回來

2337
00:00:24,019 --> 00:00:24,620
不知道

2338
00:00:24,620 --> 00:00:25,420
這是一個討論

2339
00:00:25,420 --> 00:00:28,920
就是你為什麼會擔心它壟斷你的意識形態

2340
00:00:00,000 --> 00:00:05,000
而不是在擔心你的意識形態已經被污染到一個程度了

2341
00:00:05,000 --> 00:00:09,800
對 就是都擔心 其實只是我會擔心更加劇

2342
00:00:09,800 --> 00:00:13,300
我會覺得因為這個依賴一旦形成

2343
00:00:13,300 --> 00:00:15,300
現在其實已經有信息解放了

2344
00:00:15,300 --> 00:00:18,800
就是我們看到的抖音一定是自己本身就在看的

2345
00:00:18,800 --> 00:00:20,399
好 我知道這個東西的答案

2346
00:00:20,399 --> 00:00:23,300
就是 開發者自己發了一個博客

2347
00:00:00,000 --> 00:00:02,000
他就是说他怎么样子去

2348
00:00:02,000 --> 00:00:04,480
怎么样子去就是

2349
00:00:05,360 --> 00:00:07,480
就是处理你这个问题

2350
00:00:07,480 --> 00:00:08,960
就是你这个问题就是

2351
00:00:11,199 --> 00:00:12,519
哪怕在美国是吧

2352
00:00:12,560 --> 00:00:14,199
他有一个主流的意识形态

2353
00:00:14,240 --> 00:00:16,120
然后尤其OpenAI这个公司在

2354
00:00:16,120 --> 00:00:17,160
在舊金山

2355
00:00:17,359 --> 00:00:19,079
他是有这样的一个意识形态

2356
00:00:19,079 --> 00:00:21,079
且大家对在这个意识形态下

2357
00:00:21,079 --> 00:00:22,399
会认为一些东西是对的

2358
00:00:22,399 --> 00:00:23,679
另外一些东西是错的

2359
00:00:23,839 --> 00:00:25,359
然后但是OpenAI说

2360
00:00:25,480 --> 00:00:27,440
我给大家开放的这个产品

2361
00:00:00,000 --> 00:00:02,879
我会遵守一定程度的意识形态

2362
00:00:02,879 --> 00:00:05,320
但是我回头给大家开放的能力

2363
00:00:05,320 --> 00:00:07,280
这些东西是可调的

2364
00:00:07,280 --> 00:00:09,439
它要遵守最基本的原则

2365
00:00:09,439 --> 00:00:12,640
但是它这些东西是希望让大家可以自由去定制

2366
00:00:12,640 --> 00:00:14,199
明白 感谢

2367
00:00:14,199 --> 00:00:16,239
然后第二个问题是

2368
00:00:16,239 --> 00:00:18,559
因为刚才其实前面也提到的是

2369
00:00:18,559 --> 00:00:21,320
GP情况下的一个教育问题

2370
00:00:21,320 --> 00:00:25,600
因为和以前的硬是比如说我们学东西是为了考试这样

2371
00:00:25,600 --> 00:00:29,120
现在比如我在想在新的小朋友教育

2372
00:00:00,000 --> 00:00:04,599
包括我之前应该是看过另外他们一个工程师和和老黄

2373
00:00:04,620 --> 00:00:07,400
就是黄仁勋的一个对谈里面也提到就这个

2374
00:00:07,400 --> 00:00:10,320
就是未来要怎么去传递信息

2375
00:00:10,320 --> 00:00:12,800
或者是未来的人应该学习什么

2376
00:00:12,800 --> 00:00:14,160
这个您是怎么看的

2377
00:00:15,599 --> 00:00:16,640
没法回答

2378
00:00:16,660 --> 00:00:18,600
但是就是我应该我刚笑了一下

2379
00:00:18,600 --> 00:00:21,120
就是我那个我看我想到了一个梗图

2380
00:00:21,120 --> 00:00:23,839
那个梗图是一个人说要找工作

2381
00:00:23,859 --> 00:00:26,120
然后用GPT生成了一堆疫苗

2382
00:00:26,120 --> 00:00:28,280
然后另外一个人收到那个疫苗以后

2383
00:00:00,000 --> 00:00:04,320
用GPT總結 最後就是我要找工作和這個人想要這個工作兩句話

2384
00:00:04,320 --> 00:00:06,120
然後中間一大堆廢話

2385
00:00:06,120 --> 00:00:08,960
對 就是怎麼樣子去

2386
00:00:08,960 --> 00:00:13,759
就是就是當我們的很多東西都被GPT取代和使用的時候

2387
00:00:13,759 --> 00:00:15,400
就是我們如果只看第一步

2388
00:00:15,400 --> 00:00:16,039
我們會發現

2389
00:00:16,039 --> 00:00:16,359
哦

2390
00:00:16,359 --> 00:00:18,160
我的寫作不需要了

2391
00:00:18,160 --> 00:00:19,960
只看第二步我的理解不需要了

2392
00:00:19,960 --> 00:00:20,879
然後第三步發現

2393
00:00:20,879 --> 00:00:21,039
哦

2394
00:00:21,039 --> 00:00:24,000
這個溝通過程其實已經被GPT完全取代的情況下

2395
00:00:24,000 --> 00:00:26,480
那我們到底還剩下什麼

2396
00:00:26,480 --> 00:00:27,879
我我我真的沒法回答

2397
00:00:00,000 --> 00:00:01,919
我只能覺得就是

2398
00:00:01,919 --> 00:00:03,560
所以說為什麼我會提那個第五問

2399
00:00:03,560 --> 00:00:05,280
就是人和GPT的區別是什麼

2400
00:00:05,280 --> 00:00:08,240
那我覺得你既然能識別到一些區別

2401
00:00:08,240 --> 00:00:11,000
然後去增強你的區別應該是沒錯的吧

2402
00:00:11,000 --> 00:00:13,160
那就是批判性思維的判斷力了

2403
00:00:13,160 --> 00:00:15,119
或者說就是批判性思維吧

2404
00:00:15,119 --> 00:00:16,879
這也是那個劉嘉老師的觀點啊

2405
00:00:16,879 --> 00:00:20,000
我就是就是你剛剛你剛剛問這個問題

2406
00:00:20,000 --> 00:00:21,280
我又想到了一個

2407
00:00:21,280 --> 00:00:24,239
我那個時候應該是剛下

2408
00:00:24,239 --> 00:00:26,039
反正我在打車

2409
00:00:26,039 --> 00:00:27,800
週日的下午打車

2410
00:00:00,000 --> 00:00:04,040
然後就看到了好多中小學生穿著校服出來

2411
00:00:04,040 --> 00:00:05,519
我在想這發生了什麼

2412
00:00:05,519 --> 00:00:07,040
他們應該是去補習班吧

2413
00:00:07,040 --> 00:00:08,359
穿著校服去補習班

2414
00:00:08,359 --> 00:00:11,919
然後那時候正在聽劉嘉老師那個播客

2415
00:00:11,919 --> 00:00:13,880
劉嘉老師在說教育沒有意義了

2416
00:00:13,880 --> 00:00:17,960
就是未來一定是你要想方設法提高平安性思維

2417
00:00:17,960 --> 00:00:19,480
我當然在那聽著點頭點頭

2418
00:00:19,480 --> 00:00:21,679
然後看到了一堆出補習班的小學生

2419
00:00:21,679 --> 00:00:24,839
我就覺得趕緊不要去補習了

2420
00:00:24,839 --> 00:00:26,519
就是趕緊去幹點有用的事吧

2421
00:00:27,839 --> 00:00:28,800
好感謝

2422
00:00:00,000 --> 00:00:03,799
然後第三個問題就是其實和倫理相關

2423
00:00:04,000 --> 00:00:05,599
然後比如說

2424
00:00:05,799 --> 00:00:08,960
因為我已經看到有些判例在美國發生

2425
00:00:09,160 --> 00:00:12,880
其中一個是那個就比如說我先舉個例子吧

2426
00:00:12,880 --> 00:00:14,599
就比如說我們訓練那個AI

2427
00:00:14,800 --> 00:00:17,800
然後他作為律師或者是作為法官來判法

2428
00:00:17,800 --> 00:00:20,320
或者說幫我們進行醫療

2429
00:00:20,440 --> 00:00:22,199
如果他誤診的情況下

2430
00:00:22,440 --> 00:00:23,879
那這個怎麼算

2431
00:00:23,879 --> 00:00:25,320
好問題終於這個問題來了

2432
00:00:25,320 --> 00:00:26,359
我可以吐槽一下

2433
00:00:26,800 --> 00:00:28,719
我這條腿就是我現在動的時候

2434
00:00:28,719 --> 00:00:29,800
它都會響

2435
00:00:00,000 --> 00:00:03,140
就這個膝蓋會響為什麼我之前那個在美國踢球

2436
00:00:03,359 --> 00:00:07,000
然後就是呃崴了一下然後這腿巨疼

2437
00:00:07,259 --> 00:00:08,500
然後我就去看醫生

2438
00:00:08,699 --> 00:00:10,160
然後看的是一個普通的醫生

2439
00:00:10,160 --> 00:00:11,560
那個醫生說你去拍個X光片吧

2440
00:00:11,560 --> 00:00:12,960
看看有沒有骨頭有沒有問題

2441
00:00:12,960 --> 00:00:14,160
然後拍了以後說沒有問題

2442
00:00:14,160 --> 00:00:15,859
那你休息兩個兩個月

2443
00:00:16,059 --> 00:00:18,039
然後你就回去可以繼續踢球了

2444
00:00:18,100 --> 00:00:20,160
我休息兩個月回去踢球上場五分鐘

2445
00:00:20,500 --> 00:00:21,440
哗 又斷了

2446
00:00:21,559 --> 00:00:23,699
然後超級疼就動不了

2447
00:00:23,960 --> 00:00:26,839
然後我再去找找了另外一個醫生

2448
00:00:26,899 --> 00:00:27,760
那個醫生說

2449
00:00:00,000 --> 00:00:03,500
你這種傷必須要拍那個核磁共振

2450
00:00:03,500 --> 00:00:06,500
因為你的韌帶X光是拍不到的

2451
00:00:06,500 --> 00:00:07,799
然後拍了核磁共振

2452
00:00:07,799 --> 00:00:09,500
我的前韌帶已經完全斷掉了

2453
00:00:09,500 --> 00:00:10,900
就之前是斷了一點點

2454
00:00:10,900 --> 00:00:13,099
然後第二次就一下子全都斷了

2455
00:00:13,099 --> 00:00:14,000
對

2456
00:00:14,000 --> 00:00:16,300
然後我就做了這個膝蓋重建

2457
00:00:16,300 --> 00:00:17,800
然後就從這抽了一根筋

2458
00:00:17,800 --> 00:00:20,600
然後再把這個膝蓋全身端上去

2459
00:00:20,600 --> 00:00:23,600
再加上我的復健做的不是很那個有點偷懶啊

2460
00:00:23,600 --> 00:00:26,100
所以說總之我現在這動是會響的

2461
00:00:26,100 --> 00:00:28,899
那他媽的那第一個醫生誰去追責啊

2462
00:00:00,000 --> 00:00:01,919
我沒辦法追他子了

2463
00:00:01,919 --> 00:00:02,960
就是他給了我一個建議

2464
00:00:02,960 --> 00:00:03,759
然後遵守了

2465
00:00:03,759 --> 00:00:04,919
然後我腿廢了

2466
00:00:04,919 --> 00:00:05,679
這樣感覺

2467
00:00:05,679 --> 00:00:09,080
我之後就是不太能做那種橫向的球的運動

2468
00:00:09,080 --> 00:00:13,039
我覺得今天其實我們社會機制沒有很追

2469
00:00:13,039 --> 00:00:19,480
就是我絕對是有一半的醫生律師和教師是不夠格的

2470
00:00:19,839 --> 00:00:20,320
對吧

2471
00:00:20,320 --> 00:00:23,359
如果說你的夠格是有60%的水平線

2472
00:00:23,359 --> 00:00:25,239
那肯定一半以上是不夠格的

2473
00:00:25,239 --> 00:00:27,280
那這些不夠格的人他們仍然在做

2474
00:00:00,000 --> 00:00:04,280
我們如果讓GPT可以把這些人的能力提高60%的話

2475
00:00:04,719 --> 00:00:07,120
就是提到那個60%的這個合格獻賞的話

2476
00:00:07,120 --> 00:00:08,160
那我覺得是個好事

2477
00:00:08,759 --> 00:00:11,720
我相信就是一個醫療GPT

2478
00:00:11,720 --> 00:00:12,839
他訓練了一年

2479
00:00:12,839 --> 00:00:14,439
他不會讓我只拍個X光

2480
00:00:14,439 --> 00:00:16,719
他會讓我去拍下那個核磁共振的

2481
00:00:17,679 --> 00:00:18,079
明白

2482
00:00:18,079 --> 00:00:20,079
我就基於這個稍微衍生一下

2483
00:00:20,079 --> 00:00:23,879
就是因為比如說就極端的情況下

2484
00:00:23,879 --> 00:00:25,839
那社會也支持我說

2485
00:00:25,839 --> 00:00:29,079
比如說我去追這個責任或者保護我的權利

2486
00:00:00,000 --> 00:00:07,000
然后有一个医生误诊,然后呢,因为这里面有一个判例是用stable diffusion的人,

2487
00:00:07,000 --> 00:00:11,000
然后之前是有一个人用stable diffusion做了一幅画,

2488
00:00:11,000 --> 00:00:14,000
然后另一个人呢拿这幅画去做了一个商业用途,

2489
00:00:14,000 --> 00:00:17,000
然后另外一个人就假设,使用这个人叫B吧,

2490
00:00:17,000 --> 00:00:24,000
B他去那个,呃,申请,呃,那个,使用,商业化使用这幅画以后被A发现了,

2491
00:00:24,000 --> 00:00:28,000
A就说那这是我生成的一个逻辑,对,

2492
00:00:00,000 --> 00:00:02,600
然后美国的法院的判罚是

2493
00:00:02,600 --> 00:00:04,700
因为它是一个无主体的生产

2494
00:00:04,700 --> 00:00:07,099
这是AI生产的,它是一个无主体的

2495
00:00:07,099 --> 00:00:10,800
所以你也不能主张你的版权逻辑

2496
00:00:10,800 --> 00:00:12,400
你的版权权利

2497
00:00:12,400 --> 00:00:15,800
所以我会担心这后面像类似的

2498
00:00:15,800 --> 00:00:18,600
大量的由于我们使用了AI

2499
00:00:18,600 --> 00:00:21,600
或者说更广泛的在社会里面用以后

2500
00:00:21,600 --> 00:00:23,600
会出现大量无主体的事情

2501
00:00:23,600 --> 00:00:26,199
包括OpenAI我也看到它那个组织架构

2502
00:00:26,199 --> 00:00:28,300
就是它有NTO这一层

2503
00:00:00,000 --> 00:00:03,200
其實我覺得是一把雙刃劍

2504
00:00:03,200 --> 00:00:04,679
它既好又不好

2505
00:00:04,679 --> 00:00:09,080
那就變得我們沒有辦法去追溯這一個

2506
00:00:09,080 --> 00:00:11,240
和它對抗的一個過程了

2507
00:00:11,240 --> 00:00:12,560
對 如果它真的作惡了

2508
00:00:12,560 --> 00:00:17,719
我們就毫無任何的一個立場點

2509
00:00:17,719 --> 00:00:18,120
對

2510
00:00:18,120 --> 00:00:21,359
有 就是利益不是你追責的邏輯

2511
00:00:21,359 --> 00:00:22,280
它如果做了壞事

2512
00:00:22,280 --> 00:00:24,120
你是可以追到那個組織的責任的

2513
00:00:24,120 --> 00:00:26,679
包括那個Sam在Galaxy的那個

2514
00:00:26,679 --> 00:00:28,480
Podcast播放裡面

2515
00:00:00,000 --> 00:00:01,520
他也非常

2516
00:00:01,520 --> 00:00:04,160
我觉得就是非常英雄主义的去说

2517
00:00:04,160 --> 00:00:06,440
就是能力是neutral的

2518
00:00:06,440 --> 00:00:08,359
但是这个工具一定是有责任的

2519
00:00:08,359 --> 00:00:10,839
然后他觉得工具的责任都在

2520
00:00:10,839 --> 00:00:12,519
在OpenAI的所有人里边

2521
00:00:12,720 --> 00:00:14,880
他是认为OpenAI的人是有责任

2522
00:00:14,880 --> 00:00:16,320
去把这个工具用好

2523
00:00:16,320 --> 00:00:19,280
和把AGI的可能性给控制好的

2524
00:00:19,440 --> 00:00:21,960
所以说是有追责的可能性

2525
00:00:21,960 --> 00:00:22,760
可以追到他们

2526
00:00:22,760 --> 00:00:24,160
就是你不行你去骂他们

2527
00:00:24,160 --> 00:00:25,760
你去怎么样都行

2528
00:00:25,960 --> 00:00:27,199
是是有人的

2529
00:00:27,239 --> 00:00:28,559
但是你刚刚说的那个版权

2530
00:00:00,000 --> 00:00:03,799
我覺得版權法現在不是一個與時俱進的法律

2531
00:00:03,799 --> 00:00:06,080
它在現有的情況下已經造成了很多問題

2532
00:00:06,080 --> 00:00:06,559
對吧

2533
00:00:06,559 --> 00:00:09,240
就是會讓一些人拿著舊版權

2534
00:00:09,240 --> 00:00:12,279
然後可以到處去起訴別人去幹這種事件

2535
00:00:12,279 --> 00:00:16,160
那他就更沒有去應對OpenAI

2536
00:00:16,160 --> 00:00:19,039
就是他沒有在他更

2537
00:00:19,039 --> 00:00:20,440
對 所以我覺得就是

2538
00:00:20,760 --> 00:00:24,800
立法者去了解這個技術

2539
00:00:24,800 --> 00:00:28,160
然後去給出一個有原則的監管

2540
00:00:28,160 --> 00:00:29,640
我覺得這是很重要的

2541
00:00:00,000 --> 00:00:04,000
但是我们不能说现有的立法没跟上

2542
00:00:04,000 --> 00:00:05,799
然后就出现一个新技术

2543
00:00:06,599 --> 00:00:09,080
反正我觉得答案肯定是你要立法跟上

2544
00:00:09,080 --> 00:00:11,480
然后我最后一个问题

2545
00:00:11,480 --> 00:00:14,240
因为我本身是做游戏的

2546
00:00:14,240 --> 00:00:18,160
所以我对包括除了GP之外

2547
00:00:18,160 --> 00:00:20,800
对SD他们那些也都有一些应用

2548
00:00:20,800 --> 00:00:23,359
然后就有里面有一个话

2549
00:00:23,359 --> 00:00:24,719
其实刚才宋老师也提到

2550
00:00:24,719 --> 00:00:26,320
就是这个是智力的文法

2551
00:00:26,320 --> 00:00:28,719
然后我在理解其他SD的时候

2552
00:00:00,000 --> 00:00:02,319
我会理解这是一个生产力的分发

2553
00:00:02,319 --> 00:00:03,359
对

2554
00:00:03,359 --> 00:00:06,799
但是我的观点就是是不是生产力的分发

2555
00:00:06,799 --> 00:00:09,880
反而对腾讯这样的大公司或者对于IG是

2556
00:00:09,880 --> 00:00:11,480
其实不是一个好的事情

2557
00:00:11,480 --> 00:00:12,960
因为在做游戏以前

2558
00:00:12,960 --> 00:00:16,280
我们会认为美术我们是我们的护城河或者壁垒

2559
00:00:16,280 --> 00:00:18,359
那现在被分发之后

2560
00:00:18,359 --> 00:00:19,239
那其实呢

2561
00:00:19,239 --> 00:00:21,480
大家真的就是拼创意了

2562
00:00:21,480 --> 00:00:24,440
对这个不知道您是怎么看行业的呢

2563
00:00:25,920 --> 00:00:26,359
没说

2564
00:00:27,839 --> 00:00:29,000
我的文章里面有说

2565
00:00:00,000 --> 00:00:04,419
其实就是他对大公司可能是件好事

2566
00:00:04,419 --> 00:00:06,139
但是大公司没有把牌打好

2567
00:00:06,580 --> 00:00:07,860
他的好事是什么呢

2568
00:00:07,860 --> 00:00:09,179
大公司有现成的用户

2569
00:00:09,179 --> 00:00:10,060
现成的场景

2570
00:00:10,539 --> 00:00:12,140
然后这些比如说游戏

2571
00:00:12,140 --> 00:00:14,419
Chad GPT他不能取代游戏

2572
00:00:14,460 --> 00:00:17,059
暂时不能取代游戏的这个内容本身对吧

2573
00:00:17,260 --> 00:00:19,420
所以说你有现成的游戏用户

2574
00:00:19,420 --> 00:00:21,379
你有现成的这个场景的情况下

2575
00:00:21,539 --> 00:00:23,579
你能不能用Chad GPT去增强你

2576
00:00:23,859 --> 00:00:25,179
我觉得是可以的

2577
00:00:25,420 --> 00:00:27,899
尤其像企业微信同学文档

2578
00:00:27,899 --> 00:00:29,579
这些微信这些东西

2579
00:00:00,000 --> 00:00:02,680
它其实是可以被拆GPT非常好的增强的

2580
00:00:02,680 --> 00:00:05,240
那你如果能增强的话这是一个加分项

2581
00:00:05,240 --> 00:00:07,160
然后第二个呢就是拆GPT

2582
00:00:07,160 --> 00:00:08,080
不好意思大家

2583
00:00:09,080 --> 00:00:11,000
就不是站在资本家的立场上

2584
00:00:11,000 --> 00:00:12,279
但是这是一个事实

2585
00:00:12,279 --> 00:00:15,000
就是它会极大的降低管理成本

2586
00:00:17,120 --> 00:00:18,079
就这句话吧

2587
00:00:18,079 --> 00:00:19,440
就是极大降低管理成本

2588
00:00:19,440 --> 00:00:21,000
那最终受益的应该

2589
00:00:21,000 --> 00:00:22,679
最大的受益方应该是大公司

2590
00:00:23,039 --> 00:00:24,800
这是两个加分项

2591
00:00:24,800 --> 00:00:29,359
但是对于AEG来说确实就是我们相对其他的游戏大厂的优势

2592
00:00:00,000 --> 00:00:02,879
是在于我们的工业化生产的能力对吧

2593
00:00:02,879 --> 00:00:04,919
我们有一堆人可以去做这件事

2594
00:00:04,919 --> 00:00:07,719
那它是不是会被极大的磨平

2595
00:00:07,719 --> 00:00:09,679
我其实在那个文档里边有一个

2596
00:00:09,679 --> 00:00:11,480
一上来不是列了很多点吗

2597
00:00:11,480 --> 00:00:12,679
然后一个灰色点

2598
00:00:12,679 --> 00:00:14,759
我不知道大家一般灰色大家会看不见

2599
00:00:14,759 --> 00:00:17,079
但你回去看的话那个灰色点是

2600
00:00:17,079 --> 00:00:18,719
一个小团队

2601
00:00:18,719 --> 00:00:20,839
我觉得两年内大概率会发生的是

2602
00:00:20,839 --> 00:00:24,160
一个小团队半年就可以做出一个3A级别的游戏

2603
00:00:25,079 --> 00:00:26,839
然后他卖5块钱就可以赚钱

2604
00:00:00,000 --> 00:00:03,399
這個對我們騰訊的業務邏輯其實是個很大的顛覆

2605
00:00:03,399 --> 00:00:05,400
明白 感謝感謝

2606
00:00:05,400 --> 00:00:07,400
你好老師

2607
00:00:07,400 --> 00:00:09,400
其實我是學法律的

2608
00:00:09,400 --> 00:00:11,400
然後前面您說的我讓我吃了八斗

2609
00:00:11,400 --> 00:00:13,400
然後反省一下自己能力夠不夠

2610
00:00:13,400 --> 00:00:15,400
就涉及到第一個反壟斷

2611
00:00:15,400 --> 00:00:17,399
和包括內容安全一系列的

2612
00:00:17,399 --> 00:00:19,399
包括生存是人工智能這些所有要求

2613
00:00:19,399 --> 00:00:21,399
只是說目前國內外一直探討這些事情

2614
00:00:21,399 --> 00:00:23,399
大家還沒有明確的一些定論

2615
00:00:23,399 --> 00:00:25,399
大多從很公開的倫理上來說的話

2616
00:00:25,399 --> 00:00:27,399
這個問題還不少

2617
00:00:27,399 --> 00:00:29,399
然後我想問兩個問題

2618
00:00:00,000 --> 00:00:22,000
我问两个问题,第一就是问一下您关于GPT其实让人思考人和以为人的事情,因为我大概是从2013年左右当时发生AlphaGo的事情,包括那个深度学习网络从2006年有突破性进展,2013年,包括2018年左右,当时GPT逐渐去衍生,其实已经关掉这个了,

2619
00:00:00,000 --> 00:00:06,200
从我个人角度,因为这个法律人律师包草之后,其实在学英语的时候,当时就介绍了说

2620
00:00:06,200 --> 00:00:13,800
DeepMind它的模型已经让一个机器很快地理解语言,为什么我们学英语还要去背

2621
00:00:13,800 --> 00:00:23,000
后来继续上学,我逐渐意识到说为什么很多东西看似好像我是理解了,但是我无法明确我自己的意识,或者我怎么理解它

2622
00:00:00,000 --> 00:00:12,000
然后后来涉及到这个TPT的事情,我感觉说,就是我们现在在从应用层面去学它表面的功夫,表面一切从模型框架到应用,但它只是比相一小。

