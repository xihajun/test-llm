1
00:00:00,000 --> 00:00:02,040
特斯拉就现在的硬件

2
00:00:02,040 --> 00:00:03,960
我觉得它是不可能达到IOS的

3
00:00:04,339 --> 00:00:06,299
你选择使用特斯拉的就是你的责任

4
00:00:06,740 --> 00:00:09,339
我觉得科技进步不是太快的而是太慢的

5
00:00:09,560 --> 00:00:11,500
忙吗?忙还是算忙吧

6
00:00:11,599 --> 00:00:12,939
正常的startup的忙

7
00:00:13,000 --> 00:00:14,500
介绍一下你的startup

8
00:00:14,599 --> 00:00:16,699
但本身是做无人卡车

9
00:00:17,000 --> 00:00:19,199
对我们路上有没有无人卡车的

10
00:00:19,500 --> 00:00:20,539
你说我们公司的

11
00:00:21,039 --> 00:00:22,640
就是in general

12
00:00:22,800 --> 00:00:24,960
美国高速公路上有没有无人卡车

13
00:00:24,960 --> 00:00:25,000
真正无人卡车

14
00:00:25,000 --> 00:00:26,000
真正无人的没有

15
00:00:26,000 --> 00:00:28,000
有几个公司在路侧

16
00:00:28,000 --> 00:00:30,000
但是应该都还是有安全员的

17
00:00:30,000 --> 00:00:31,000
没有完全无人

18
00:00:31,000 --> 00:00:34,000
你觉得还离这个真正无人差多远

19
00:00:34,000 --> 00:00:37,000
第一这是一个整个产业的问题

20
00:00:37,000 --> 00:00:38,000
比如说我们公司

21
00:00:38,000 --> 00:00:40,000
甚至大部分做无人卡车的公司

22
00:00:40,000 --> 00:00:41,000
我们是不生产这个卡车的

23
00:00:41,000 --> 00:00:44,000
卡车还是卡车OEM

24
00:00:44,000 --> 00:00:46,159
就是厂商去生产所以他们生产这个卡车的卡车还是卡特OEM就是厂商去生产的

25
00:00:46,159 --> 00:00:47,600
所以他们生产的卡车

26
00:00:47,600 --> 00:00:51,719
得达到能够无人的安全标准

27
00:00:51,719 --> 00:00:52,679
举个例子就是

28
00:00:52,679 --> 00:00:54,320
它必须要有一套

29
00:00:54,320 --> 00:00:56,439
冗余的控制系统

30
00:00:56,439 --> 00:00:57,320
当你的主要的

31
00:00:57,320 --> 00:01:00,240
有相当于是有电脑控制的

32
00:01:00,240 --> 00:01:01,280
这个系统失效了以后

33
00:01:01,280 --> 00:01:03,920
你还要能够来控制它

34
00:01:03,920 --> 00:01:06,439
这个是达到安全的一个必须的

35
00:01:06,439 --> 00:01:08,480
但是现在大部分就是没有哪一家

36
00:01:08,480 --> 00:01:10,480
因为这东西太新了

37
00:01:10,480 --> 00:01:11,560
这些厂商没有

38
00:01:11,560 --> 00:01:13,599
他没有需求来做这个事

39
00:01:13,599 --> 00:01:15,439
所以这个东西还能达不到

40
00:01:15,439 --> 00:01:17,040
所以只有当他们

41
00:01:17,040 --> 00:01:18,439
换句话说

42
00:01:18,439 --> 00:01:19,359
或者说简单一点说

43
00:01:19,359 --> 00:01:20,959
只有当硬件达到那个时候

44
00:01:21,920 --> 00:01:24,319
才有可能真正的有无人车

45
00:01:24,319 --> 00:01:26,000
所以特斯拉也不能满足这个标准

46
00:01:26,000 --> 00:01:27,439
因为它也没有龙玉的启动

47
00:01:27,439 --> 00:01:30,760
对 然后我之前信息里我就说

48
00:01:30,760 --> 00:01:33,680
特斯拉就现在的硬件

49
00:01:33,680 --> 00:01:35,560
我觉得它是不可能达到L4的

50
00:01:35,560 --> 00:01:38,239
L4是在限定的某一个叫

51
00:01:38,239 --> 00:01:40,159
Operational Design Domain ODD里面

52
00:01:40,640 --> 00:01:42,560
能够完全的无人驾驶

53
00:01:43,400 --> 00:01:45,359
L3 L4 L5的区别是什么来着

54
00:01:45,359 --> 00:01:47,280
L3和L4最大区别就是

55
00:01:47,280 --> 00:01:48,640
L3还是人负责

56
00:01:48,640 --> 00:01:50,400
L4以上就是车负责

57
00:01:50,400 --> 00:01:52,799
那你觉得特斯拉线能达到L3吗

58
00:01:52,799 --> 00:01:58,239
L3是一个我其实对L3的完全定义

59
00:01:58,239 --> 00:02:00,239
我都不记得很清楚

60
00:02:00,239 --> 00:02:01,840
你可以说达到也可以说能达到

61
00:02:01,840 --> 00:02:03,359
但我不记得L3具体定义

62
00:02:03,359 --> 00:02:05,439
但是其实对我来说最大的区别就是说

63
00:02:05,439 --> 00:02:08,639
出了事或者是这个车到底是人在最后在负责

64
00:02:08,639 --> 00:02:11,199
还是有这个机器的这个情况

65
00:02:11,199 --> 00:02:13,759
为什么我说是个伦理或者法律问题呢

66
00:02:13,759 --> 00:02:17,120
就第一如果车来负责法律归谁

67
00:02:17,120 --> 00:02:18,560
对肯定是个法律问题

68
00:02:18,560 --> 00:02:21,360
所以这个产业很大一部分的

69
00:02:21,360 --> 00:02:22,400
也不是很大

70
00:02:22,400 --> 00:02:23,680
有一部分的effort也是说

71
00:02:23,680 --> 00:02:25,599
怎么样去跟policy maker

72
00:02:25,599 --> 00:02:29,500
跟各个地区的infrastructure去配合起来

73
00:02:29,500 --> 00:02:32,300
但是先抛开法律问题不太

74
00:02:32,300 --> 00:02:33,400
可能这有两个问题

75
00:02:33,400 --> 00:02:35,900
第一个就是谁会做出更好的决定

76
00:02:35,900 --> 00:02:39,099
还有可能L4它意味着

77
00:02:39,099 --> 00:02:41,300
条件的成熟的一个必要条件就是

78
00:02:41,300 --> 00:02:45,120
机器在大多数情况下能做出比人更好的决定

79
00:02:46,960 --> 00:02:49,680
但是我觉得这个时候现在就有了就是我其实我有的时候坐lift uber

80
00:02:49,680 --> 00:02:51,840
我觉得司机开的瞎开就是很可怕

81
00:02:52,280 --> 00:02:52,639
对吧

82
00:02:52,879 --> 00:02:56,719
我觉得一个vimo可能比司机开的好

83
00:02:57,080 --> 00:02:59,879
但是不意味着大家在观念上

84
00:02:59,879 --> 00:03:01,560
绝大多数人的观念上可以接受

85
00:03:02,000 --> 00:03:04,919
他更相信这个机器而不是相信uber司机

86
00:03:05,000 --> 00:03:05,900
对吧

87
00:03:06,199 --> 00:03:09,500
所以说第一条件什么时候可以成熟到

88
00:03:09,500 --> 00:03:14,099
大多数时候车比人的水平好

89
00:03:14,099 --> 00:03:14,800
我觉得这个

90
00:03:16,000 --> 00:03:18,400
起码从那个uber司机的角度来看的话

91
00:03:18,400 --> 00:03:19,300
已经比他好了

92
00:03:19,500 --> 00:03:21,000
自动驾驶最后是一个产品的话

93
00:03:21,000 --> 00:03:22,000
它不光是技术

94
00:03:22,000 --> 00:03:24,900
还有怎么样让产品赢得市场

95
00:03:24,900 --> 00:03:25,000
不光是这个产品本身对吧有很多术还有怎么样让产品赢得市场

96
00:03:25,000 --> 00:03:26,199
不光是产品本身

97
00:03:26,199 --> 00:03:27,680
有很多其他的因素

98
00:03:27,680 --> 00:03:28,960
这个产品怎么样去推广

99
00:03:28,960 --> 00:03:31,680
从自动驾驶本身这个产品来说

100
00:03:31,680 --> 00:03:33,560
它要很大一份是信任

101
00:03:33,560 --> 00:03:38,439
怎么样要让乘客去信任这个车是安全的

102
00:03:38,439 --> 00:03:40,360
我们今天就谈技术问题

103
00:03:40,360 --> 00:03:41,639
OK谈技术问题

104
00:03:41,639 --> 00:03:43,039
来给我们科普一下

105
00:03:43,039 --> 00:03:45,439
在你看来技术有什么大问题

106
00:03:45,439 --> 00:03:48,479
最大的问题应该是所谓的厂委问题

107
00:03:48,479 --> 00:03:51,680
怎么样你能让你这个车能够去解决

108
00:03:51,680 --> 00:03:57,280
因为至少有一部分无人车系统是用机械系的方法来作为它的一部分

109
00:03:57,280 --> 00:03:59,199
或者是大部分的一个component

110
00:03:59,199 --> 00:04:05,240
所以你怎么样去验证机�学系统在遇到常委问题

111
00:04:05,240 --> 00:04:08,199
就是说他的训练书籍很少见到的情况下的时候

112
00:04:08,639 --> 00:04:10,800
他还能够做出正确的决定

113
00:04:10,800 --> 00:04:14,879
这个决定不一定说他做他机器学系系统做出了正确的判断

114
00:04:14,879 --> 00:04:19,439
而是机器学系统比较难的一点是他怎么样让他在他不知道这个时候

115
00:04:19,800 --> 00:04:21,959
很confident的说我不知道这个是什么

116
00:04:21,959 --> 00:04:23,199
我需要停下来

117
00:04:23,199 --> 00:04:26,560
因为大部分的系统是你designer给他一个task

118
00:04:26,560 --> 00:04:28,399
他要去做出一个判断

119
00:04:28,399 --> 00:04:30,839
就让我想起来了特斯拉

120
00:04:30,839 --> 00:04:34,439
他最近的一个FSD的update

121
00:04:34,439 --> 00:04:36,160
就是他把一个deterministic的

122
00:04:36,160 --> 00:04:38,720
这种if-else变成了一个

123
00:04:39,680 --> 00:04:41,720
supposedly neural network

124
00:04:41,720 --> 00:04:43,959
我不知道他最后这个东西

125
00:04:43,959 --> 00:04:48,439
他是希望就是让这个机器真的去自主学习呢

126
00:04:48,439 --> 00:04:52,740
还是人在人的指导之下去学习

127
00:04:52,740 --> 00:04:56,579
就是我们要把人的先验知识带到这个problem space里面吗

128
00:04:56,579 --> 00:04:59,459
还是我们人在这里边就说

129
00:04:59,459 --> 00:05:00,660
This is a problem

130
00:05:00,660 --> 00:05:03,660
我给你define好你的parameter和你的last function

131
00:05:03,660 --> 00:05:06,939
我最多再给你调节一下数据的权重

132
00:05:06,939 --> 00:05:08,699
比如说那个三百万分之一的东西

133
00:05:08,699 --> 00:05:11,899
我把它调成三千分之一去学学

134
00:05:11,899 --> 00:05:14,500
学完了以后好了这个结果不管了

135
00:05:14,500 --> 00:05:17,939
我觉得第一你说有没有人的先例

136
00:05:17,939 --> 00:05:18,980
肯定是有对吧

137
00:05:18,980 --> 00:05:20,939
就是比如说在他这个系统上线之前

138
00:05:20,939 --> 00:05:24,480
他怎么去验证肯定是他有这个以前

139
00:05:24,480 --> 00:05:25,000
也有说shadow mode对吧就是要么你的这个软件在车上跑在这个系统上线之前它怎么去验证肯定是它有这个以前

140
00:05:25,000 --> 00:05:26,000
也有说叫shadow mode

141
00:05:26,000 --> 00:05:28,000
就是相当于你的这个软件在车上跑

142
00:05:28,000 --> 00:05:31,000
但它不实际操纵的时候

143
00:05:31,000 --> 00:05:33,000
然后把这个人开的这个

144
00:05:33,000 --> 00:05:34,000
像这个路线和这个

145
00:05:34,000 --> 00:05:36,000
所谓的这个方向盘

146
00:05:36,000 --> 00:05:39,000
或者刹车的这个控制的

147
00:05:39,000 --> 00:05:43,000
跟这个它的模型预测的那些结果去做比较

148
00:05:43,000 --> 00:05:44,000
实际上这个里面就已经有

149
00:05:44,000 --> 00:05:47,199
至少即使说它这个模型训练的过程中

150
00:05:47,199 --> 00:05:48,639
没有用到人的知识

151
00:05:48,639 --> 00:05:50,120
但是在验证的过程中也用到了

152
00:05:50,120 --> 00:05:50,959
这是第一个

153
00:05:50,959 --> 00:05:52,560
第二个就是所有

154
00:05:52,560 --> 00:05:56,199
就是跟开车跟driving相关的所有的知识

155
00:05:56,199 --> 00:05:58,199
里面也用到了很多人的知识

156
00:05:58,199 --> 00:05:58,439
对吧

157
00:05:58,439 --> 00:05:59,720
就是所有的交通规则

158
00:05:59,720 --> 00:06:01,120
所有的交通信号

159
00:06:01,120 --> 00:06:02,519
这都是人制定的规则

160
00:06:02,519 --> 00:06:03,120
他也要

161
00:06:03,120 --> 00:06:04,959
你也要通过某一种方式

162
00:06:04,959 --> 00:06:06,199
告诉这个模型去学到这些东西

163
00:06:06,199 --> 00:06:07,600
那既然聊到这儿了

164
00:06:07,600 --> 00:06:09,199
我就把他这个再聊深一点

165
00:06:09,199 --> 00:06:11,399
就是我不知道你看没看过

166
00:06:11,399 --> 00:06:13,399
我写那个就是鹦鹉乌鸦

167
00:06:13,399 --> 00:06:14,399
朱松春

168
00:06:14,399 --> 00:06:15,800
鹦鹉什么

169
00:06:15,800 --> 00:06:18,199
鹦鹉模式和乌鸦模式

170
00:06:18,199 --> 00:06:20,399
鹦鹉就是过去的Machine Learning

171
00:06:20,399 --> 00:06:21,600
寻找Correspondence

172
00:06:21,600 --> 00:06:23,399
鹦鹉学舌的方式

173
00:06:23,399 --> 00:06:27,100
乌鸦看起来有Inference能力

174
00:06:27,100 --> 00:06:28,399
which reasoning

175
00:06:28,399 --> 00:06:29,500
就是它

176
00:06:30,399 --> 00:06:34,100
例子就是说乌鸦在一个日本

177
00:06:34,100 --> 00:06:35,600
就是它有Documentary

178
00:06:35,600 --> 00:06:38,100
它可以 它想打开它的坚果

179
00:06:38,100 --> 00:06:39,199
但是它不知道怎么打

180
00:06:39,199 --> 00:06:40,000
就是它打不开

181
00:06:40,000 --> 00:06:41,399
所以说它就去

182
00:06:41,399 --> 00:06:44,300
它进一步发现车可以压碎坚果

183
00:06:44,300 --> 00:06:46,660
对 然后但是车会撞死它然后它进一步发现车可以压碎坚果然后当时车会撞死他

184
00:06:46,660 --> 00:06:48,699
然后他进一步发现红绿灯可以stop车

185
00:06:48,699 --> 00:06:51,000
于是他就在红灯的时候把坚果扔下去

186
00:06:51,000 --> 00:06:52,540
然后绿灯开过去

187
00:06:52,540 --> 00:06:53,819
然后红灯的时候再捡起来

188
00:06:53,819 --> 00:06:55,360
这个东西他不能失败

189
00:06:55,360 --> 00:06:56,379
他失败了就死掉了

190
00:06:56,379 --> 00:07:00,480
所以说他完全是在自己脑子里边理解了看似

191
00:07:00,480 --> 00:07:03,040
我们觉得是理解了他理解了这个机制

192
00:07:03,040 --> 00:07:04,319
然后去做了这么一个事情

193
00:07:04,319 --> 00:07:06,339
这是两个范式

194
00:07:06,339 --> 00:07:09,680
会说我在里边是说看似大模型拥有了一个无压能力

195
00:07:09,680 --> 00:07:11,779
不一定 但是我觉得可能有

196
00:07:11,779 --> 00:07:14,120
然后我最近有一些新的想法

197
00:07:14,120 --> 00:07:15,680
就是这个无压能力到底是怎么来的

198
00:07:15,680 --> 00:07:19,680
有可能是shortest path of understanding prior knowledge

199
00:07:19,680 --> 00:07:20,920
这先不展开

200
00:07:20,920 --> 00:07:26,000
我们还是回过来聊一些大家可能非常直接感兴趣的话题

201
00:07:26,000 --> 00:07:27,800
比如说特斯拉

202
00:07:27,800 --> 00:07:29,600
你看起来是不太看好的特斯拉

203
00:07:29,600 --> 00:07:32,399
不太看好这个说的太

204
00:07:32,399 --> 00:07:34,800
首先你很讨厌FSD的命名对吧

205
00:07:34,800 --> 00:07:36,800
对因为它并不是

206
00:07:36,800 --> 00:07:38,199
你不就是名不副其实吗

207
00:07:38,199 --> 00:07:39,000
然后这是第一

208
00:07:39,000 --> 00:07:43,199
第二因为这个名字我觉得是造成

209
00:07:43,199 --> 00:07:44,800
特斯拉也有一些事故

210
00:07:44,800 --> 00:07:48,959
我觉得有一部分是因为这个名字造成误导

211
00:07:48,959 --> 00:07:51,759
这就说到我刚刚提到产品的问题

212
00:07:51,759 --> 00:07:53,060
相当于他叫这个名字以后

213
00:07:53,060 --> 00:07:57,160
让人以为它是一个完全的自动驾驶的产品

214
00:07:57,160 --> 00:08:00,860
所以有人会把它当做一个完全自动驾驶产品用

215
00:08:00,860 --> 00:08:03,759
就是像你开的时候完全人丝巨不复

216
00:08:03,759 --> 00:08:05,399
我觉得不是FSD的过

217
00:08:05,399 --> 00:08:06,000
怎么说呢

218
00:08:06,000 --> 00:08:07,199
这特别是一个更多的是个

219
00:08:07,199 --> 00:08:08,000
marketing的角度

220
00:08:08,000 --> 00:08:09,600
不是一个技术的角度

221
00:08:09,600 --> 00:08:11,600
但是我觉得marketing这种角度

222
00:08:11,600 --> 00:08:13,000
很难说就是

223
00:08:13,000 --> 00:08:14,600
没有特斯拉的话

224
00:08:14,600 --> 00:08:16,600
电车肯定不是今天这样

225
00:08:16,600 --> 00:08:17,000
对

226
00:08:17,000 --> 00:08:19,800
所以我所以你刚一开始问我是不是

227
00:08:19,800 --> 00:08:20,800
不喜欢特斯拉

228
00:08:20,800 --> 00:08:21,600
我觉得这是要

229
00:08:21,600 --> 00:08:23,399
因为特斯拉有很多方面对吧

230
00:08:23,399 --> 00:08:24,800
所以我不会说是一个二轮数

231
00:08:24,800 --> 00:08:25,000
我不喜欢特斯拉对像你说的特斯拉在这个电动吧所以我不会说是一个二轮数我不喜欢特斯拉

232
00:08:25,000 --> 00:08:26,000
对像你说的

233
00:08:26,000 --> 00:08:28,000
特斯拉在电动车的推广方面

234
00:08:28,000 --> 00:08:30,000
做了很大的贡献

235
00:08:30,000 --> 00:08:32,000
但是从无人驾驶这个角度

236
00:08:32,000 --> 00:08:34,000
我觉得是做了更多的害处吧

237
00:08:34,000 --> 00:08:36,000
至少从比如说我们要说产品的角度

238
00:08:36,000 --> 00:08:38,000
它作为一个

239
00:08:38,000 --> 00:08:39,000
首先它是一个

240
00:08:39,000 --> 00:08:41,000
说清楚它是一个辅助驾驶的产品

241
00:08:41,000 --> 00:08:43,000
FSD是一个辅助驾驶的产品

242
00:08:43,000 --> 00:08:44,000
至少目前为止

243
00:08:44,000 --> 00:08:46,639
它没有达到自动驾驶的能完成自助驾驶的产品FSD是一个辅助驾驶的产品至少目前为止它没有达到自动驾驶的

244
00:08:46,639 --> 00:08:48,879
这个能完成自动驾驶的能力

245
00:08:49,240 --> 00:08:50,559
但是它由它的命名

246
00:08:50,559 --> 00:08:52,399
以及它的这种迭代的方式吧

247
00:08:52,399 --> 00:08:54,080
从最早期它基本上就是

248
00:08:54,879 --> 00:08:56,120
至少我认为它是把

249
00:08:56,679 --> 00:08:58,879
特斯拉的车主当做

250
00:08:59,360 --> 00:09:02,440
用特斯拉的车主来测试它的产品

251
00:09:02,799 --> 00:09:04,080
我觉得这是至少

252
00:09:04,559 --> 00:09:06,679
对这样一种产品来说

253
00:09:06,679 --> 00:09:08,639
是一个不是很负责任的行为

254
00:09:08,639 --> 00:09:11,279
因为这是一个安全的产品

255
00:09:11,279 --> 00:09:16,320
好像我之前看一个是每年因为车祸会死300万人

256
00:09:17,080 --> 00:09:18,960
然后我就想那些刚学车的那些人

257
00:09:18,960 --> 00:09:21,039
大家说的就是吐槽的那些司机

258
00:09:21,039 --> 00:09:22,360
对吧乱开车的司机

259
00:09:22,960 --> 00:09:25,159
转向不打灈下高速隨便下

260
00:09:25,600 --> 00:09:26,480
這些人我相信

261
00:09:26,480 --> 00:09:29,080
每天殺死的人比特斯拉多很多

262
00:09:29,600 --> 00:09:30,960
假設我們今天所有人

263
00:09:30,960 --> 00:09:33,279
今天全都使用FSD

264
00:09:33,279 --> 00:09:36,200
我相信車禍會變少而不是變多

265
00:09:37,360 --> 00:09:39,559
我們確實FSD

266
00:09:39,559 --> 00:09:41,399
直接歸因可以歸因到

267
00:09:41,399 --> 00:09:43,519
他這個事情好像怎麼樣導致的問題

268
00:09:43,519 --> 00:09:44,840
那個事情導致的問題

269
00:09:45,200 --> 00:09:47,799
但是他的alternative也有很多问题

270
00:09:48,360 --> 00:09:50,840
然后我觉得科技进步不是太快了而是太慢了

271
00:09:51,000 --> 00:09:51,799
就是这样

272
00:09:51,799 --> 00:09:56,759
那个factor是不是说我们用一个更谨慎的方式

273
00:09:56,759 --> 00:09:59,440
同样快的速度去发展自动驾驶

274
00:09:59,799 --> 00:10:02,840
而是更谨慎的速度可能发展的速度是现在1 1十分

275
00:10:03,360 --> 00:10:05,159
那你是希望用一个更aggressive的方式速度可能发展的速度是现在1 1 十分那你是希望用一个更

276
00:10:07,919 --> 00:10:13,399
aggressive的方式更快的发展还是对但是现实是你再aggressive也不可能是所有人都开特斯拉

277
00:10:13,399 --> 00:10:15,399
或者所有人都有s fsd

278
00:10:15,399 --> 00:10:17,279
因为不能所有人都使用

279
00:10:17,279 --> 00:10:19,399
对不可能所有人都同时使用上这个技术

280
00:10:19,399 --> 00:10:21,080
这现实上是不可能的对吧

281
00:10:21,440 --> 00:10:24,000
然后我对你

282
00:10:24,000 --> 00:10:26,000
就你刚才说如果所有人都用FSD

283
00:10:26,000 --> 00:10:27,000
或者不用所有人吧

284
00:10:27,000 --> 00:10:29,000
就是the more people you FSD

285
00:10:29,000 --> 00:10:31,000
the more people will benefit

286
00:10:31,000 --> 00:10:35,000
有了FSD这个技术减少了一些事故

287
00:10:35,000 --> 00:10:37,000
就能justify它导致那些事故

288
00:10:37,000 --> 00:10:38,000
那不能

289
00:10:38,000 --> 00:10:41,000
对但是这就涉及到

290
00:10:41,000 --> 00:10:43,000
我们一开始说这个到底是人负责任

291
00:10:43,000 --> 00:10:45,200
人的责任还是机器的责任人的责任

292
00:10:45,200 --> 00:10:46,700
在我看来就是人的责任

293
00:10:46,700 --> 00:10:48,899
你选择使用特斯拉的就是你的责任

294
00:10:48,899 --> 00:10:51,700
但是特斯拉的责任是他没有

295
00:10:51,700 --> 00:10:54,200
他提供的技术没有

296
00:10:54,200 --> 00:10:57,700
就是你开车撞死人是谁的责任

297
00:10:57,700 --> 00:11:00,700
对 但你说你是因为你说你是FSD了

298
00:11:00,700 --> 00:11:02,700
你说你是Full Self Driving

299
00:11:02,700 --> 00:11:05,200
所以为什么我开车还是我的责任呢

300
00:11:06,080 --> 00:11:07,440
我撞死人还是我的责任呢

301
00:11:07,440 --> 00:11:09,759
这个是我认为他误导人的地方

302
00:11:09,759 --> 00:11:12,799
就是不是所有人在开一个

303
00:11:12,919 --> 00:11:15,000
或者在运用使用FSD的时候

304
00:11:15,000 --> 00:11:16,440
都有这个清晰的认识说

305
00:11:16,879 --> 00:11:19,240
我是是我在掌控这个最后的车

306
00:11:19,240 --> 00:11:20,240
是我是我的责任

307
00:11:20,240 --> 00:11:21,759
而是像你说的

308
00:11:21,759 --> 00:11:23,759
完全相信了这个机器

309
00:11:23,759 --> 00:11:26,299
那但这个相信的有一部分原因就是因为这个

310
00:11:26,299 --> 00:11:29,000
命名和他这个marketing导致

311
00:11:29,000 --> 00:11:33,000
所以我认为这是一个他有很大责任的地方

312
00:11:33,000 --> 00:11:36,500
就是在我看来技术进步大于很多其他的东西

313
00:11:36,500 --> 00:11:39,200
因为我的目标是这个full self-driving

314
00:11:39,200 --> 00:11:40,600
对你的目标是full self-driving

315
00:11:40,600 --> 00:11:44,200
但当你有了full self-driving这个capability的时候

316
00:11:44,200 --> 00:11:46,200
再去release这样一个product

317
00:11:46,200 --> 00:11:48,200
我现在是一个beta版的Full Self-Driving

318
00:11:48,200 --> 00:11:51,200
就是当大家不使用FSD

319
00:11:51,200 --> 00:11:53,200
你可能会觉得有两个原因

320
00:11:53,200 --> 00:11:55,700
第一个原因就是这件事情没有价值

321
00:11:55,700 --> 00:11:56,700
大家不用

322
00:11:56,700 --> 00:11:59,200
第二个就是三个原因吧

323
00:11:59,200 --> 00:12:01,700
第一个是大家就是fundamentally没有价值

324
00:12:01,700 --> 00:12:06,639
第二个是大家就是没有习惯它

325
00:12:06,639 --> 00:12:09,840
所以不知道它的存在

326
00:12:09,840 --> 00:12:13,840
第三个就是fundamentally是有价值的

327
00:12:13,840 --> 00:12:14,639
但是你没做好

328
00:12:14,639 --> 00:12:17,440
他现在不知道他是在三个里面哪一个

329
00:12:17,440 --> 00:12:21,679
最差的情况是现在fundamentally没有价值

330
00:12:21,679 --> 00:12:24,080
是我觉得有可能发生的事情

331
00:12:24,080 --> 00:12:27,639
Robotaxi出现了以后

332
00:12:27,639 --> 00:12:30,279
也许Robotaxi是有价值的

333
00:12:30,279 --> 00:12:32,000
但是那也是个问号

334
00:12:32,000 --> 00:12:33,559
就是Robotaxi在

335
00:12:34,840 --> 00:12:37,360
就假设Robotaxi真的做好了

336
00:12:37,360 --> 00:12:39,000
它对人没有价值

337
00:12:39,000 --> 00:12:39,879
为什么没有

338
00:12:39,879 --> 00:12:40,679
你说没有价值

339
00:12:40,679 --> 00:12:41,759
还是你有可能没有价值

340
00:12:41,759 --> 00:12:43,080
为什么呢

341
00:12:43,080 --> 00:12:44,919
就是我有一辆车可以开

342
00:12:44,919 --> 00:12:46,500
我为什么一定要不开它

343
00:12:46,600 --> 00:12:48,200
为什么买一辆不开的车

344
00:12:48,600 --> 00:12:49,399
哦 robotaxi

345
00:12:49,899 --> 00:12:51,399
等一下 robotaxi 是说

346
00:12:51,500 --> 00:12:53,200
我不需要有这个 car ownership

347
00:12:53,500 --> 00:12:55,000
我可以就像我打 uber 一样

348
00:12:55,000 --> 00:12:55,799
但是只是把

349
00:12:56,100 --> 00:12:57,799
uber 的成本降低了很多

350
00:12:57,799 --> 00:12:59,000
同时也减少了

351
00:12:59,700 --> 00:13:01,500
呃人力的需求

352
00:13:01,600 --> 00:13:02,600
这是我理解的 robotaxi

353
00:13:02,600 --> 00:13:03,700
而不是说我 own 一个车

354
00:13:03,700 --> 00:13:06,919
然后他去当 robotaxi那我觉得确实没有什么意义

355
00:13:06,919 --> 00:13:08,320
我干嘛要own一个Taxi呢

356
00:13:08,320 --> 00:13:08,919
对吧

357
00:13:08,919 --> 00:13:09,879
特别是对美国来说

358
00:13:09,879 --> 00:13:10,600
对吧

359
00:13:10,600 --> 00:13:13,600
这个因为人力成本比较高

360
00:13:13,600 --> 00:13:14,200
同时

361
00:13:15,480 --> 00:13:16,600
人的生活习惯

362
00:13:16,600 --> 00:13:17,799
很多做在Sandburg

363
00:13:17,799 --> 00:13:19,200
所以需要有一个车

364
00:13:19,200 --> 00:13:19,559
对

365
00:13:19,559 --> 00:13:20,399
但是当你

366
00:13:21,799 --> 00:13:24,759
同时这个对整个城市的规划来说

367
00:13:24,759 --> 00:13:27,519
他需要花很多的建立去考虑停车场

368
00:13:27,519 --> 00:13:28,480
这种方面

369
00:13:28,480 --> 00:13:32,559
当你有一个车是可以自动的开的时候

370
00:13:32,559 --> 00:13:34,840
这个所有的这一切都会发生一些改变

371
00:13:34,840 --> 00:13:36,799
你知道上一个完全可以类比的

372
00:13:36,799 --> 00:13:38,360
Argument是什么产品吗

373
00:13:38,360 --> 00:13:38,879
什么

374
00:13:38,879 --> 00:13:40,279
云游戏

375
00:13:40,279 --> 00:13:40,840
什么东西

376
00:13:40,840 --> 00:13:41,519
云游戏

377
00:13:41,519 --> 00:13:42,200
什么叫云游戏

378
00:13:42,200 --> 00:13:43,399
Cloud Gaming

379
00:13:43,399 --> 00:13:43,799
我不知道

380
00:13:43,799 --> 00:13:45,279
Google Stadia

381
00:13:46,120 --> 00:13:47,759
OK

382
00:13:49,080 --> 00:13:49,919
你为什么觉得这是一个雷比

383
00:13:51,480 --> 00:13:53,480
就我为什么要买一个主机我为什么买一个such a powerful PC

384
00:13:53,480 --> 00:13:54,679
Xbox PSC

385
00:13:54,679 --> 00:13:56,000
有那么贵对吧

386
00:13:56,000 --> 00:13:57,440
然后那么好的硬件

387
00:13:57,440 --> 00:14:00,759
放在家里99.99%的时间都不会打开它

388
00:14:00,759 --> 00:14:02,519
我只是在玩的时候去玩一下

389
00:14:03,279 --> 00:14:04,960
为什么我不Cloud

390
00:14:04,960 --> 00:14:05,120
然后Stream但是他没有办法compete过Xbox为什么都不会打开它我只是在玩的时候去玩一下为什么我不cloud

391
00:14:05,120 --> 00:14:05,879
然后stream呢

392
00:14:07,000 --> 00:14:08,960
但是他没有办法compete过Xbox

393
00:14:08,960 --> 00:14:09,759
为什么

394
00:14:09,759 --> 00:14:12,679
因为有这个需求的人已经买了一个Xbox了

395
00:14:12,679 --> 00:14:14,039
特斯拉大家很多时候说

396
00:14:14,039 --> 00:14:17,159
他有一个最大的优势就是他collect data是世界第一

397
00:14:17,159 --> 00:14:19,000
或者这个行业的发展

398
00:14:19,000 --> 00:14:20,919
对你个人的影响其实很小

399
00:14:20,919 --> 00:14:24,720
但是我还是希望世界上多一些这样的人

400
00:14:24,720 --> 00:14:27,600
技术是由市场才能被培育起来的

401
00:14:27,600 --> 00:14:28,399
对 可以这么说

